{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdWeWQdHI5m9",
        "outputId": "3884c600-574d-49c9-bfba-6d6c7b72036b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/units_large_portfolio\n",
            "Cloning into 'uni2ts'...\n",
            "remote: Enumerating objects: 980, done.\u001b[K\n",
            "remote: Counting objects: 100% (494/494), done.\u001b[K\n",
            "remote: Compressing objects: 100% (222/222), done.\u001b[K\n",
            "remote: Total 980 (delta 343), reused 273 (delta 271), pack-reused 486 (from 1)\u001b[K\n",
            "Receiving objects: 100% (980/980), 8.29 MiB | 10.34 MiB/s, done.\n",
            "Resolving deltas: 100% (473/473), done.\n",
            "Updating files: 100% (252/252), done.\n",
            "/content/drive/MyDrive/units_large_portfolio/uni2ts\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Collecting gluonts\n",
            "  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pandas<3,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gluonts) (2.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.11/dist-packages (from gluonts) (2.11.7)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.11/dist-packages (from gluonts) (0.12.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.12.14)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.0->gluonts) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.0->gluonts) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.0->gluonts) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.0->gluonts) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.2-py3-none-any.whl (821 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.0-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.0-py3-none-any.whl (981 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, hydra-core, nvidia-cusolver-cu12, gluonts, torchmetrics, pytorch-lightning, lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gluonts-0.16.2 hydra-core-1.3.2 jaxtyping-0.3.2 lightning-2.5.2 lightning-utilities-0.15.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.2 torchmetrics-1.8.0 wadler-lindig-0.1.7\n",
            "CUDA is available: True\n",
            "Current CUDA device: 0\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Units Large Portfolio Backtesting - Google Colab T4 GPU\n",
        "# ============================================================================\n",
        "\n",
        "# Mount Google Drive and set up environment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/units_large_portfolio\n",
        "\n",
        "%cd /content/drive/MyDrive/units_large_portfolio\n",
        "\n",
        "!git clone https://github.com/SalesforceAIResearch/uni2ts\n",
        "%cd uni2ts\n",
        "\n",
        "%pip install torch transformers scikit-learn tqdm joblib gluonts lightning pytorch-lightning jaxtyping hydra-core\n",
        "\n",
        "import torch\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current CUDA device:\", torch.cuda.current_device())\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2rnKuNSI5m-",
        "outputId": "0a087002-7fb6-4d3d-e65f-85fb3428a229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "Using device: cuda\n",
            "Model: Salesforce/moirai-1.1-R-large\n",
            "Prediction length: 1\n",
            "Data loaded successfully!\n",
            "T4 GPU optimized batch size configuration for Units Large:\n",
            "  Window 5: batch size = 1024\n",
            "  Window 21: batch size = 512\n",
            "  Window 252: batch size = 256\n",
            "  Window 512: batch size = 128\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from gluonts.dataset.common import ListDataset\n",
        "\n",
        "# Add local path for importing modules from src\n",
        "sys.path.append(\"src\")\n",
        "\n",
        "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
        "import random\n",
        "import yfinance as yf\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import f as f_dist\n",
        "import matplotlib.dates as mdates\n",
        "from datetime import datetime\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "MODEL_NAME = \"Salesforce/moirai-1.1-R-large\"\n",
        "PRED_LEN = 1\n",
        "PATCH_SIZE = \"auto\"\n",
        "TRANSACTION_COST = 0.0015\n",
        "WINDOW_SIZES = [5, 21, 252, 512]\n",
        "START_YEAR = 2016\n",
        "NPZ_PATH = \"/content/drive/MyDrive/ERP Data/all_window_datasets_unscaled.npz\"\n",
        "\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Prediction length: {PRED_LEN}\")\n",
        "\n",
        "data_path = NPZ_PATH\n",
        "if os.path.exists(data_path):\n",
        "    data = np.load(data_path, allow_pickle=True)\n",
        "    print(\"Data loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Data file not found: {data_path}\")\n",
        "    print(\"Please ensure all_window_datasets.npz is uploaded to Google Drive 'ERP Data' folder\")\n",
        "\n",
        "window_sizes = [5, 21, 252, 512]\n",
        "results = {}\n",
        "\n",
        "def get_batch_size(window_size):\n",
        "    \"\"\"\n",
        "    Batch size configuration optimized for T4 GPU (16GB).\n",
        "    \"\"\"\n",
        "    if window_size <= 5:\n",
        "        return 1024\n",
        "    elif window_size <= 21:\n",
        "        return 512\n",
        "    elif window_size <= 252:\n",
        "        return 256\n",
        "    elif window_size <= 512:\n",
        "        return 128\n",
        "    else:\n",
        "        return 4\n",
        "\n",
        "print(\"T4 GPU optimized batch size configuration for Units Large:\")\n",
        "for ws in WINDOW_SIZES:\n",
        "    batch_size = get_batch_size(ws)\n",
        "    print(f\"  Window {ws}: batch size = {batch_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1dud1NGw4RL",
        "outputId": "3b815e59-22e5-4d1c-cb02-effaef48666e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-486884232.py:15: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  px = yf.download(\"^GSPC\", start=\"2016-01-01\", end=\"2024-12-31\")[\"Close\"]\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] S&P500 Excess Sharpe (2016–24) = 0.652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-486884232.py:17: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  rf_align = rf_series.reindex(sp_ret.index).fillna(method=\"ffill\")\n"
          ]
        }
      ],
      "source": [
        "def annual_sharpe(rets, freq=252):\n",
        "    mu = float(np.mean(rets)) * freq\n",
        "    sd = float(np.std(rets, ddof=1)) * np.sqrt(freq)\n",
        "    return mu / sd if sd > 0 else 0\n",
        "\n",
        "# Load risk-free rate and calculate S&P500 Excess Sharpe\n",
        "\n",
        "rf_file = \"/content/drive/MyDrive/ERP Data/CRSP_2016_2024_top50_with_exret.csv\"\n",
        "try:\n",
        "    rf_df = pd.read_csv(rf_file, usecols=[\"date\", \"rf\"])\n",
        "    rf_df[\"date\"] = pd.to_datetime(rf_df[\"date\"])\n",
        "    rf_df = rf_df.drop_duplicates(\"date\").set_index(\"date\").sort_index()\n",
        "    rf_series = rf_df[\"rf\"].astype(float)\n",
        "\n",
        "    px = yf.download(\"^GSPC\", start=\"2016-01-01\", end=\"2024-12-31\")[\"Close\"]\n",
        "    sp_ret = px.pct_change().dropna()\n",
        "    rf_align = rf_series.reindex(sp_ret.index).fillna(method=\"ffill\")\n",
        "    sp_excess = sp_ret.values - rf_align.values\n",
        "\n",
        "    SR_MKT_EX = annual_sharpe(sp_excess)\n",
        "    print(f\"[INFO] S&P500 Excess Sharpe (2016–24) = {SR_MKT_EX:.3f}\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not load risk-free rate data: {e}\")\n",
        "    SR_MKT_EX = 0.5  # Use default value\n",
        "\n",
        "def delta_sharpe(r2_zero: float, sr_base: float):\n",
        "    \"\"\"\n",
        "    If r2_zero <= 0   → ΔSharpe = 0, Sharpe* = sr_base\n",
        "    If r2_zero >= 1   → ΔSharpe = 0, Sharpe* = sr_base (extreme case fallback)\n",
        "    Otherwise, calculate by the original formula\n",
        "    \"\"\"\n",
        "    if (r2_zero <= 0) or (r2_zero >= 1):\n",
        "        return 0.0, sr_base\n",
        "    sr_star = np.sqrt(sr_base ** 2 + r2_zero) / np.sqrt(1 - r2_zero)\n",
        "    return sr_star - sr_base, sr_star\n",
        "\n",
        "def r2_zero(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate zero-based R² (baseline is 0)\n",
        "    y_true: actual values array (N,)\n",
        "    y_pred: predicted values array (N,)\n",
        "    \"\"\"\n",
        "    rss = np.sum((y_true - y_pred)**2)\n",
        "    tss = np.sum(y_true**2)\n",
        "    return 1 - rss / tss\n",
        "\n",
        "def calc_ic_daily(df, method='spearman'):\n",
        "    \"\"\"\n",
        "    Calculate daily cross-sectional RankIC\n",
        "    df: must contain ['signal_date','y_true','y_pred']\n",
        "    \"\"\"\n",
        "    ics = (df.groupby('signal_date')\n",
        "             .apply(lambda g: g['y_pred'].corr(g['y_true'], method=method))\n",
        "             .dropna())\n",
        "    mean_ic = ics.mean()\n",
        "    std_ic  = ics.std(ddof=1)\n",
        "    t_ic    = mean_ic / (std_ic / np.sqrt(len(ics))) if std_ic > 0 else np.nan\n",
        "    pos_ratio = (ics > 0).mean()\n",
        "    return mean_ic, t_ic, pos_ratio, ics\n",
        "\n",
        "def calc_directional_metrics(y_true, y_pred, permnos=None):\n",
        "    \"\"\"\n",
        "    Improved version:\n",
        "    - Sample-level sign prediction\n",
        "    - If grouped by stock, calculate Overall, Up, Down for each stock and then average\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "\n",
        "    if permnos is None:\n",
        "        s_true = np.sign(y_true)\n",
        "        s_pred = np.sign(y_pred)\n",
        "        mask = s_true != 0\n",
        "        s_true = s_true[mask]\n",
        "        s_pred = s_pred[mask]\n",
        "\n",
        "        overall_acc = np.mean(s_true == s_pred)\n",
        "\n",
        "        up_mask = s_true > 0\n",
        "        down_mask = s_true < 0\n",
        "        up_acc = np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else 0\n",
        "        down_acc = np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else 0\n",
        "\n",
        "    else:\n",
        "        df = pd.DataFrame({\"permno\": permnos, \"yt\": y_true, \"yp\": y_pred})\n",
        "        overall_accs = []\n",
        "        up_accs = []\n",
        "        down_accs = []\n",
        "\n",
        "        for _, g in df.groupby(\"permno\"):\n",
        "            s_true = np.sign(g[\"yt\"].values)\n",
        "            s_pred = np.sign(g[\"yp\"].values)\n",
        "            mask = s_true != 0\n",
        "            s_true = s_true[mask]\n",
        "            s_pred = s_pred[mask]\n",
        "            if len(s_true) == 0:\n",
        "                continue\n",
        "            overall_accs.append(np.mean(s_true == s_pred))\n",
        "\n",
        "            up_mask = s_true > 0\n",
        "            down_mask = s_true < 0\n",
        "            up_accs.append(np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else np.nan)\n",
        "            down_accs.append(np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else np.nan)\n",
        "\n",
        "        overall_acc = np.nanmean(overall_accs)\n",
        "        up_acc = np.nanmean(up_accs)\n",
        "        down_acc = np.nanmean(down_accs)\n",
        "\n",
        "    return overall_acc, up_acc, down_acc\n",
        "\n",
        "def regression_metrics(y_true, y_pred, k, meta=None, permnos=None):\n",
        "    \"\"\"\n",
        "    Includes:\n",
        "    - Regression metrics\n",
        "    - Pointwise directional accuracy\n",
        "    - Market cap group metrics\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    n = len(y_true)\n",
        "\n",
        "    r2 = r2_zero(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "    dir_acc, up_acc, down_acc = calc_directional_metrics(y_true, y_pred, permnos)\n",
        "\n",
        "    metrics = {\n",
        "        \"R²_zero\": r2,\n",
        "        \"RMSE\": rmse,\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"Directional Accuracy\": dir_acc,\n",
        "        \"Up_Directional_Acc\": up_acc,\n",
        "        \"Down_Directional_Acc\": down_acc\n",
        "    }\n",
        "\n",
        "    if meta is not None and \"MKTCAP_PERCENTILE\" in meta:\n",
        "        top_mask = meta[\"MKTCAP_PERCENTILE\"] >= 0.75\n",
        "        bottom_mask = meta[\"MKTCAP_PERCENTILE\"] <= 0.25\n",
        "\n",
        "        if np.any(top_mask):\n",
        "            yt_top = y_true[top_mask]\n",
        "            yp_top = y_pred[top_mask]\n",
        "            perm_top = permnos[top_mask] if permnos is not None else None\n",
        "            r2_top = r2_zero(yt_top, yp_top)\n",
        "            rmse_top = np.sqrt(mean_squared_error(yt_top, yp_top))\n",
        "            mae_top = mean_absolute_error(yt_top, yp_top)\n",
        "            mse_top = mean_squared_error(yt_top, yp_top)\n",
        "            dir_top, up_top, down_top = calc_directional_metrics(yt_top, yp_top, perm_top)\n",
        "            metrics.update({\n",
        "                \"Top25_R2_zero\": r2_top,\n",
        "                \"Top25_RMSE\": rmse_top,\n",
        "                \"Top25_MAE\": mae_top,\n",
        "                \"Top25_MSE\": mse_top,\n",
        "                \"Top25_Dir_Acc\": dir_top,\n",
        "                \"Top25_Up_Acc\": up_top,\n",
        "                \"Top25_Down_Acc\": down_top\n",
        "            })\n",
        "\n",
        "        if np.any(bottom_mask):\n",
        "            yt_bot = y_true[bottom_mask]\n",
        "            yp_bot = y_pred[bottom_mask]\n",
        "            perm_bot = permnos[bottom_mask] if permnos is not None else None\n",
        "            r2_bot = r2_zero(yt_bot, yp_bot)\n",
        "            rmse_bot = np.sqrt(mean_squared_error(yt_bot, yp_bot))\n",
        "            mae_bot = mean_absolute_error(yt_bot, yp_bot)\n",
        "            mse_bot = mean_squared_error(yt_bot, yp_bot)\n",
        "            dir_bot, up_bot, down_bot = calc_directional_metrics(yt_bot, yp_bot, perm_bot)\n",
        "            metrics.update({\n",
        "                \"Bottom25_R2_zero\": r2_bot,\n",
        "                \"Bottom25_RMSE\": rmse_bot,\n",
        "                \"Bottom25_MAE\": mae_bot,\n",
        "                \"Bottom25_MSE\": mse_bot,\n",
        "                \"Bottom25_Dir_Acc\": dir_bot,\n",
        "                \"Bottom25_Up_Acc\": up_bot,\n",
        "                \"Bottom25_Down_Acc\": down_bot\n",
        "            })\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def f_statistic(y_true, y_pred, k):\n",
        "    \"\"\"Return F statistic and corresponding p-value\"\"\"\n",
        "    n   = len(y_true)\n",
        "    rss = np.sum((y_true - y_pred) ** 2)\n",
        "    tss = np.sum(y_true ** 2)\n",
        "    r2  = 1 - rss / tss\n",
        "    if (r2 <= 0) or (n <= k):\n",
        "        return 0.0, 1.0\n",
        "    F = (r2 / k) / ((1 - r2) / (n - k))\n",
        "    p = f_dist.sf(F, k, n - k)\n",
        "    return F, p\n",
        "\n",
        "def overall_interval_metrics_method1(y_all, yhat_all, k, permnos_all=None, meta_all=None):\n",
        "    \"\"\"\n",
        "    Method 1: Calculate metrics for the entire interval at once (concatenate all samples from 2016-2024)\n",
        "    Returns: a dict, can be directly used for save_metrics()\n",
        "    \"\"\"\n",
        "    base = regression_metrics(\n",
        "        y_true=y_all,\n",
        "        y_pred=yhat_all,\n",
        "        k=k,\n",
        "        meta=meta_all,\n",
        "        permnos=permnos_all\n",
        "    )\n",
        "    F, p = f_statistic(y_all, yhat_all, k)\n",
        "    base[\"F_stat\"]     = F\n",
        "    base[\"F_pvalue\"]   = p\n",
        "    base[\"N_obs\"] = len(y_all)\n",
        "\n",
        "    delta_cash, sr_star_cash = delta_sharpe(base[\"R²_zero\"], sr_base=0)\n",
        "    base[\"ΔSharpe_cash\"]      = delta_cash\n",
        "    base[\"Sharpe*_cash\"]      = sr_star_cash\n",
        "\n",
        "    delta_mkt , sr_star_mkt  = delta_sharpe(base[\"R²_zero\"], sr_base=SR_MKT_EX)\n",
        "    base[\"ΔSharpe_mkt\"]       = delta_mkt\n",
        "    base[\"Sharpe*_mkt\"]       = sr_star_mkt\n",
        "\n",
        "    return base\n",
        "\n",
        "def sortino_ratio(rets, freq=252):\n",
        "    \"\"\"Calculate Sortino Ratio\"\"\"\n",
        "    downside = rets[rets < 0]\n",
        "    if len(downside) == 0:\n",
        "        return np.inf\n",
        "    mu = rets.mean() * freq\n",
        "    sigma = np.sqrt((downside ** 2).mean()) * np.sqrt(freq)\n",
        "    return mu / sigma\n",
        "\n",
        "def cvar(rets, alpha=0.95):\n",
        "    \"\"\"Calculate CVaR\"\"\"\n",
        "    q = np.quantile(rets, 1 - alpha)\n",
        "    return rets[rets <= q].mean()\n",
        "\n",
        "def save_metrics(metrics_dict, name, window, path=\"portfolio_metrics.csv\"):\n",
        "    \"\"\"Save metrics to CSV file\"\"\"\n",
        "    row = {'Model': name, 'Window': window}\n",
        "    row.update(metrics_dict)\n",
        "\n",
        "    if os.path.exists(path):\n",
        "        df = pd.read_csv(path)\n",
        "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "    else:\n",
        "        df = pd.DataFrame([row])\n",
        "\n",
        "    df.to_csv(path, index=False)\n",
        "    print(f\"Metrics saved for {name}_w{window} to {path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEMAAdJPbx14"
      },
      "outputs": [],
      "source": [
        "# Portfolio core class\n",
        "# Transaction cost settings\n",
        "TC_GRID = [0.0005, 0.001, 0.002, 0.003, 0.004]  # 5, 10, 20, 30, 40 bps\n",
        "TC_TAG  = {\n",
        "    0.0005: \"tc5\",\n",
        "    0.001:  \"tc10\",\n",
        "    0.002:  \"tc20\",\n",
        "    0.003:  \"tc30\",\n",
        "    0.004:  \"tc40\"\n",
        "}\n",
        "\n",
        "class PortfolioBacktester:\n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "\n",
        "    def calc_turnover(self, w_t, r_t, w_tp1):\n",
        "        \"\"\"Calculate turnover using the standard formula provided by the user\"\"\"\n",
        "        if w_t is None:\n",
        "            return np.sum(np.abs(w_tp1))\n",
        "\n",
        "        gross_ret = np.sum(w_t * r_t)\n",
        "        if abs(1 + gross_ret) < 1e-8:\n",
        "            return np.sum(np.abs(w_tp1))\n",
        "\n",
        "        passive_weight = w_t * (1 + r_t) / (1 + gross_ret)\n",
        "        turnover = np.sum(np.abs(w_tp1 - passive_weight))\n",
        "        return turnover\n",
        "\n",
        "    def create_portfolios_with_permno_tracking(self, signals, market_caps, permnos, top_pct=0.1, bottom_pct=0.1, weight_scheme=\"VW\"):\n",
        "        \"\"\"\n",
        "        Create portfolio weights based on signals, strictly tracking permno alignment.\n",
        "        weight_scheme: 'VW' for value-weighted, 'EW' for equal-weighted\n",
        "        \"\"\"\n",
        "        n_stocks = len(signals)\n",
        "        top_n    = max(1, int(round(n_stocks * top_pct)))\n",
        "        bottom_n = max(1, int(round(n_stocks * bottom_pct)))\n",
        "\n",
        "        sorted_idx = np.argsort(signals)[::-1]\n",
        "\n",
        "        top_idx = sorted_idx[:top_n]\n",
        "        bottom_idx = sorted_idx[-bottom_n:]\n",
        "\n",
        "        portfolio_data = {}\n",
        "\n",
        "        # Long-only portfolio (Top 10%)\n",
        "        long_weights = np.zeros(n_stocks)\n",
        "        if len(top_idx) > 0:\n",
        "            if weight_scheme == \"VW\":\n",
        "                top_market_caps = market_caps[top_idx]\n",
        "                if np.sum(top_market_caps) > 0:\n",
        "                    long_weights[top_idx] = top_market_caps / np.sum(top_market_caps)\n",
        "            else:\n",
        "                long_weights[top_idx] = 1.0 / len(top_idx)\n",
        "\n",
        "        portfolio_data['long_only'] = {\n",
        "            'weights': long_weights,\n",
        "            'permnos': permnos.copy(),\n",
        "            'selected_permnos': permnos[top_idx] if len(top_idx) > 0 else np.array([])\n",
        "        }\n",
        "\n",
        "        # Short-only portfolio (Bottom 10%)\n",
        "        short_weights = np.zeros(n_stocks)\n",
        "        if len(bottom_idx) > 0:\n",
        "            if weight_scheme == \"VW\":\n",
        "                bottom_market_caps = market_caps[bottom_idx]\n",
        "                if np.sum(bottom_market_caps) > 0:\n",
        "                    short_weights[bottom_idx] = -bottom_market_caps / np.sum(bottom_market_caps)\n",
        "            else:\n",
        "                short_weights[bottom_idx] = -1.0 / len(bottom_idx)\n",
        "\n",
        "        portfolio_data['short_only'] = {\n",
        "            'weights': short_weights,\n",
        "            'permnos': permnos.copy(),\n",
        "            'selected_permnos': permnos[bottom_idx] if len(bottom_idx) > 0 else np.array([])\n",
        "        }\n",
        "\n",
        "        # Long-Short portfolio (Top long + Bottom short)\n",
        "        ls_raw = long_weights + short_weights\n",
        "\n",
        "        gross_target = 2.0\n",
        "        current_gross = np.sum(np.abs(long_weights)) + np.sum(np.abs(short_weights))\n",
        "        scale = gross_target / current_gross if current_gross > 1e-8 else 0.0\n",
        "        ls_weights = scale * ls_raw\n",
        "\n",
        "        ls_selected_permnos = np.concatenate([\n",
        "            permnos[top_idx] if len(top_idx) > 0 else np.array([]),\n",
        "            permnos[bottom_idx] if len(bottom_idx) > 0 else np.array([])\n",
        "        ])\n",
        "\n",
        "        portfolio_data['long_short'] = {\n",
        "            'weights': ls_weights,\n",
        "            'permnos': permnos.copy(),\n",
        "            'selected_permnos': ls_selected_permnos\n",
        "        }\n",
        "\n",
        "        return portfolio_data\n",
        "\n",
        "    def calculate_aligned_portfolio_return(self, portfolio_weights, portfolio_permnos, actual_returns, actual_permnos):\n",
        "        \"\"\"Calculate portfolio return strictly aligned by permno\"\"\"\n",
        "        aligned_returns = np.zeros(len(portfolio_permnos))\n",
        "\n",
        "        return_dict = dict(zip(actual_permnos, actual_returns))\n",
        "\n",
        "        for i, permno in enumerate(portfolio_permnos):\n",
        "            if permno in return_dict:\n",
        "                aligned_returns[i] = return_dict[permno]\n",
        "\n",
        "        portfolio_return = np.sum(portfolio_weights * aligned_returns)\n",
        "        return portfolio_return, aligned_returns\n",
        "\n",
        "    def calculate_metrics(self, returns, turnover_series=None):\n",
        "        \"\"\"Calculate portfolio metrics - only returns summary metrics, not full series\"\"\"\n",
        "        returns = np.array(returns)\n",
        "\n",
        "        annual_return = np.mean(returns) * 252\n",
        "        annual_vol = np.std(returns, ddof=1) * np.sqrt(252)\n",
        "        sharpe = annual_return / annual_vol if annual_vol > 0 else 0\n",
        "\n",
        "        log_cum = np.cumsum(np.log1p(returns))\n",
        "        peak_log = np.maximum.accumulate(log_cum)\n",
        "        dd_log = peak_log - log_cum\n",
        "        max_drawdown = 1 - np.exp(-dd_log.max())\n",
        "        max_1d_loss = np.min(returns)\n",
        "\n",
        "        avg_turnover = np.mean(turnover_series) if turnover_series is not None else 0\n",
        "\n",
        "        sortino = sortino_ratio(returns)\n",
        "        cvar95  = cvar(returns, alpha=0.95)\n",
        "\n",
        "        result = {\n",
        "            'annual_return': annual_return,\n",
        "            'annual_vol': annual_vol,\n",
        "            'sharpe': sharpe,\n",
        "            'max_drawdown': max_drawdown,\n",
        "            'max_1d_loss': max_1d_loss,\n",
        "            'avg_turnover': avg_turnover,\n",
        "            'sortino': sortino,\n",
        "            'cvar95': cvar95\n",
        "        }\n",
        "\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "082Zj46Cbx15",
        "outputId": "285eac90-f326-44cb-928d-0d83482fba18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading portfolio datasets...\n",
            "Available datasets:\n",
            "  X_test_21: (110850, 21)\n",
            "  X_test_252: (110850, 252)\n",
            "  X_test_5: (110850, 5)\n",
            "  X_test_512: (110850, 512)\n",
            "  X_train_21: (196120, 21)\n",
            "  X_train_252: (184570, 252)\n",
            "  X_train_5: (196920, 5)\n",
            "  X_train_512: (171570, 512)\n",
            "  market_caps_test_21: (110850,)\n",
            "  market_caps_test_252: (110850,)\n",
            "  market_caps_test_5: (110850,)\n",
            "  market_caps_test_512: (110850,)\n",
            "  market_caps_train_21: (196120,)\n",
            "  market_caps_train_252: (184570,)\n",
            "  market_caps_train_5: (196920,)\n",
            "  market_caps_train_512: (171570,)\n",
            "  meta_test_21: ()\n",
            "  meta_test_252: ()\n",
            "  meta_test_5: ()\n",
            "  meta_test_512: ()\n",
            "  meta_train_21: ()\n",
            "  meta_train_252: ()\n",
            "  meta_train_5: ()\n",
            "  meta_train_512: ()\n",
            "  y_test_21: (110850,)\n",
            "  y_test_252: (110850,)\n",
            "  y_test_5: (110850,)\n",
            "  y_test_512: (110850,)\n",
            "  y_train_21: (196120,)\n",
            "  y_train_252: (184570,)\n",
            "  y_train_5: (196920,)\n",
            "  y_train_512: (171570,)\n",
            "\n",
            "Datasets loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# ========== Data Loading and Preparation ==========\n",
        "\n",
        "print(\"Loading portfolio datasets...\")\n",
        "\n",
        "def load_datasets(npz_path):\n",
        "    \"\"\"Load dataset\"\"\"\n",
        "    data = np.load(npz_path, allow_pickle=True)\n",
        "    datasets = {}\n",
        "    for key in data.files:\n",
        "        datasets[key] = data[key]\n",
        "    return datasets\n",
        "\n",
        "datasets = load_datasets(NPZ_PATH)\n",
        "\n",
        "print(\"Available datasets:\")\n",
        "for key in sorted(datasets.keys()):\n",
        "    if hasattr(datasets[key], 'shape'):\n",
        "        print(f\"  {key}: {datasets[key].shape}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {type(datasets[key])}\")\n",
        "\n",
        "print(\"\\nDatasets loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEWW33zvbx15",
        "outputId": "f2ef3d12-b8fb-4563-da82-30500f2c4a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uni2TS prediction functions defined successfully\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def batch_predict_uni2ts(X_data, predictor, batch_size):\n",
        "    n_samples = len(X_data)\n",
        "    predictions = np.zeros(n_samples)\n",
        "\n",
        "    for i in tqdm(range(0, n_samples, batch_size), desc=\"Predicting\"):\n",
        "        end_idx = min(i + batch_size, n_samples)\n",
        "        batch_data = X_data[i:end_idx]\n",
        "\n",
        "        batch_datasets = []\n",
        "        for j in range(len(batch_data)):\n",
        "            dataset = {\"target\": batch_data[j], \"start\": \"2020-01-01\"}\n",
        "            batch_datasets.append(dataset)\n",
        "\n",
        "        dataset = ListDataset(batch_datasets, freq=\"D\")\n",
        "\n",
        "        forecasts = list(predictor.predict(dataset))\n",
        "        for j, f in enumerate(forecasts):\n",
        "            # If SampleForecast: use median of samples\n",
        "            if hasattr(f, \"samples\") and f.samples is not None:\n",
        "                predictions[i + j] = float(np.median(f.samples[:, 0]))\n",
        "            else:\n",
        "                # Otherwise, use p50 quantile from DistributionForecast\n",
        "                predictions[i + j] = float(f.quantile(0.5)[0])\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def uni2ts_rolling_prediction(window_size, X_data, batch_size=256, prediction_length=1):\n",
        "    \"\"\"\n",
        "    Uni2TS rolling window prediction.\n",
        "    Args:\n",
        "        window_size: context window size\n",
        "        X_data: input features (n_samples, window_size)\n",
        "        batch_size: batch size\n",
        "        prediction_length: prediction length\n",
        "    Returns:\n",
        "        predictions: prediction results (n_samples,)\n",
        "    \"\"\"\n",
        "    n_samples = len(X_data)\n",
        "    predictions = np.zeros(n_samples)\n",
        "\n",
        "    print(f\"Running Uni2TS prediction on {n_samples} samples with batch size {batch_size}\")\n",
        "\n",
        "    print(\"Initializing Uni2TS model...\")\n",
        "    model = MoiraiForecast(\n",
        "        module=MoiraiModule.from_pretrained(MODEL_NAME),\n",
        "        prediction_length=prediction_length,\n",
        "        context_length=window_size,\n",
        "        patch_size=PATCH_SIZE,\n",
        "        num_samples=100,\n",
        "        target_dim=1,\n",
        "        feat_dynamic_real_dim=0,\n",
        "        past_feat_dynamic_real_dim=0,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        model = model.to(device)\n",
        "        print(f\"Model loaded on: {device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load on {device}, using CPU: {str(e)}\")\n",
        "        model = model.to(\"cpu\")\n",
        "        current_device = \"cpu\"\n",
        "\n",
        "    predictor = model.create_predictor(batch_size=batch_size)\n",
        "\n",
        "    predictions = batch_predict_uni2ts(X_data, predictor, batch_size)\n",
        "\n",
        "    try:\n",
        "        del model, predictor\n",
        "        if device == \"mps\":\n",
        "            torch.mps.empty_cache()\n",
        "        elif device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Memory cleanup failed: {str(e)}\")\n",
        "\n",
        "    return predictions\n",
        "\n",
        "print(\"Uni2TS prediction functions defined successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmj2KL_zbx15"
      },
      "outputs": [],
      "source": [
        "# ========== Main function for daily prediction and next-day rebalancing portfolio simulation ==========\n",
        "\n",
        "def run_uni2ts_portfolio_backtest(start_year=2016, end_year=2024, window_sizes=None, model_names=None,\n",
        "                                           npz_path=\"/content/drive/MyDrive/ERP Data/all_window_datasets_unscaled.npz\"):\n",
        "    \"\"\"\n",
        "Portfolio simulation (daily prediction and next-day rebalancing):\n",
        "    1. Use Units Large model for zero-shot prediction\n",
        "    2. Daily prediction → daily signal\n",
        "    3. Daily portfolio construction (T+1 rebalancing, strict permno alignment)\n",
        "    4. Separate summary metrics and time series data\n",
        "    \"\"\"\n",
        "    if window_sizes is None:\n",
        "        window_sizes = [5, 21, 252, 512]\n",
        "    if model_names is None:\n",
        "        model_names = [\"units large\"]\n",
        "\n",
        "    print(f\"Starting daily rebalance portfolio backtesting simulation ({start_year}-{end_year})\")\n",
        "\n",
        "    backtester = PortfolioBacktester()\n",
        "\n",
        "    datasets = load_datasets(npz_path)\n",
        "\n",
        "    summary_results = []\n",
        "    daily_series_data = []\n",
        "    pred_rows = []\n",
        "\n",
        "    WEIGHT_SCHEMES = [\"VW\", \"EW\"]\n",
        "\n",
        "    for window in window_sizes:\n",
        "        print(f\"Processing window size: {window}\")\n",
        "\n",
        "        X_test = datasets[f\"X_test_{window}\"]\n",
        "        y_test = datasets[f\"y_test_{window}\"]\n",
        "        meta_test_dict = datasets[f\"meta_test_{window}\"].item()\n",
        "        meta_test = pd.DataFrame.from_dict(meta_test_dict)\n",
        "\n",
        "        permnos_test = meta_test[\"PERMNO\"].values\n",
        "        meta_test[\"signal_date\"]  = pd.to_datetime(meta_test[\"date\"])\n",
        "        meta_test[\"ret_date\"]     = pd.to_datetime(meta_test[\"ret_date\"])\n",
        "        market_caps = meta_test.get(\"MKTCAP\", np.ones(len(permnos_test)))\n",
        "\n",
        "        meta_test['date'] = pd.to_datetime(meta_test[\"date\"])\n",
        "        dates_test = meta_test['signal_date']\n",
        "\n",
        "        for model_name in model_names:\n",
        "            for scheme in WEIGHT_SCHEMES:\n",
        "                all_y_true   = []\n",
        "                all_y_pred   = []\n",
        "                all_permnos  = []\n",
        "                all_meta     = []\n",
        "                print(f\"  Model: {model_name}, Scheme: {scheme}\")\n",
        "\n",
        "                portfolio_daily_data = {\n",
        "                    'long_only': {'returns': [], 'turnovers': [], 'dates': []},\n",
        "                    'short_only': {'returns': [], 'turnovers': [], 'dates': []},\n",
        "                    'long_short': {'returns': [], 'turnovers': [], 'dates': []}\n",
        "                }\n",
        "\n",
        "                prev_portfolio_data = {'long_only': None, 'short_only': None, 'long_short': None}\n",
        "\n",
        "                signals_buf = {}\n",
        "\n",
        "                for year in range(start_year, min(end_year + 1, 2025)):\n",
        "                    print(f\"  Processing year: {year}\")\n",
        "\n",
        "                    year_mask = (dates_test.dt.year == year)\n",
        "                    if not np.any(year_mask):\n",
        "                        continue\n",
        "\n",
        "                    X_year = X_test[year_mask]\n",
        "                    y_year = y_test[year_mask]\n",
        "                    permnos_year = permnos_test[year_mask]\n",
        "                    market_caps_year = market_caps[year_mask]\n",
        "                    dates_year = dates_test[year_mask]\n",
        "                    ret_dates_year = meta_test.loc[year_mask, 'ret_date'].values\n",
        "\n",
        "                    batch_size = get_batch_size(window)\n",
        "                    predictions_year = uni2ts_rolling_prediction(\n",
        "                        window_size=window,\n",
        "                        X_data=X_year,\n",
        "                        batch_size=batch_size,\n",
        "                        prediction_length=1\n",
        "                    )\n",
        "\n",
        "                    df_quarter = pd.DataFrame({\n",
        "                        'signal_date': dates_year,\n",
        "                        'ret_date': ret_dates_year,\n",
        "                        'permno': permnos_year,\n",
        "                        'market_cap': market_caps_year,\n",
        "                        'actual_return': y_year,\n",
        "                        'prediction': predictions_year\n",
        "                    })\n",
        "\n",
        "                    if scheme == 'VW':\n",
        "                        df_q_save = df_quarter[['signal_date','ret_date','permno',\n",
        "                                                'actual_return','prediction','market_cap']].copy()\n",
        "                        df_q_save.rename(columns={'actual_return':'y_true',\n",
        "                                                  'prediction':'y_pred'}, inplace=True)\n",
        "                        df_q_save['model']  = model_name\n",
        "                        df_q_save['window'] = window\n",
        "                        pred_rows.append(df_q_save)\n",
        "\n",
        "                    all_y_true.append(df_quarter['actual_return'].values)\n",
        "                    all_y_pred.append(df_quarter['prediction'].values)\n",
        "                    all_permnos.append(df_quarter['permno'].values)\n",
        "                    all_meta.append(meta_test.loc[year_mask, :])\n",
        "\n",
        "                    for signal_date, sig_grp in df_quarter.groupby('signal_date'):\n",
        "\n",
        "                        daily_signals = (\n",
        "                            sig_grp.groupby('permno')['prediction'].mean()\n",
        "                                  .to_frame('prediction')\n",
        "                                  .join(sig_grp.groupby('permno')['market_cap'].mean())\n",
        "                        )\n",
        "                        signals_buf[signal_date] = daily_signals\n",
        "\n",
        "                        prev_date = signal_date - pd.tseries.offsets.BDay(1)\n",
        "                        if prev_date not in signals_buf:\n",
        "                            continue\n",
        "\n",
        "                        sigs = signals_buf.pop(prev_date)\n",
        "\n",
        "                        ret_grp = df_quarter[df_quarter['ret_date'] == signal_date]\n",
        "                        if len(ret_grp) == 0:\n",
        "                            continue\n",
        "\n",
        "                        daily_actual_returns = (\n",
        "                            ret_grp.groupby('permno')['actual_return']\n",
        "                                   .mean()\n",
        "                                   .reindex(sigs.index, fill_value=0)\n",
        "                                   .values\n",
        "                        )\n",
        "                        daily_permnos = sigs.index.values\n",
        "\n",
        "                        portfolios_data = backtester.create_portfolios_with_permno_tracking(\n",
        "                            signals      = sigs['prediction'].values,\n",
        "                            market_caps  = sigs['market_cap'].values,\n",
        "                            permnos      = daily_permnos,\n",
        "                            weight_scheme= scheme\n",
        "                        )\n",
        "\n",
        "                        for portfolio_type in ['long_only', 'short_only', 'long_short']:\n",
        "                            portfolio_info = portfolios_data[portfolio_type]\n",
        "\n",
        "                            portfolio_return, aligned_returns = backtester.calculate_aligned_portfolio_return(\n",
        "                                portfolio_weights=portfolio_info['weights'],\n",
        "                                portfolio_permnos=portfolio_info['permnos'],\n",
        "                                actual_returns=daily_actual_returns,\n",
        "                                actual_permnos=daily_permnos\n",
        "                            )\n",
        "\n",
        "                            if prev_portfolio_data[portfolio_type] is not None:\n",
        "                                prev_w_ser = pd.Series(\n",
        "                                    prev_portfolio_data[portfolio_type]['weights'],\n",
        "                                    index=prev_portfolio_data[portfolio_type]['permnos']\n",
        "                                )\n",
        "                                cur_w_ser = pd.Series(\n",
        "                                    portfolio_info['weights'],\n",
        "                                    index=portfolio_info['permnos']\n",
        "                                )\n",
        "\n",
        "                                prev_r_ser = pd.Series(\n",
        "                                    prev_portfolio_data[portfolio_type]['aligned_returns'],\n",
        "                                    index=prev_portfolio_data[portfolio_type]['permnos']\n",
        "                                )\n",
        "\n",
        "                                aligned_prev_w = prev_w_ser.reindex(cur_w_ser.index, fill_value=0).values\n",
        "                                aligned_prev_r = prev_r_ser.reindex(cur_w_ser.index, fill_value=0).values\n",
        "\n",
        "                                aligned_cur_w = cur_w_ser.values\n",
        "\n",
        "                                turnover = backtester.calc_turnover(\n",
        "                                    w_t  = aligned_prev_w,\n",
        "                                    r_t  = aligned_prev_r,\n",
        "                                    w_tp1= aligned_cur_w\n",
        "                                )\n",
        "                            else:\n",
        "                                turnover = np.sum(np.abs(portfolio_info['weights']))\n",
        "\n",
        "                            portfolio_daily_data[portfolio_type]['returns'].append(portfolio_return)\n",
        "                            portfolio_daily_data[portfolio_type]['turnovers'].append(turnover)\n",
        "                            portfolio_daily_data[portfolio_type]['dates'].append(signal_date)\n",
        "\n",
        "                            prev_portfolio_data[portfolio_type] = {\n",
        "                                'weights'        : portfolio_info['weights'],\n",
        "                                'permnos'        : portfolio_info['permnos'],\n",
        "                                'aligned_returns': aligned_returns\n",
        "                            }\n",
        "\n",
        "                for portfolio_type in ['long_only', 'short_only', 'long_short']:\n",
        "                    portfolio_data = portfolio_daily_data[portfolio_type]\n",
        "\n",
        "                    if len(portfolio_data['returns']) > 0:\n",
        "                        metrics = backtester.calculate_metrics(\n",
        "                            returns=portfolio_data['returns'],\n",
        "                            turnover_series=portfolio_data['turnovers']\n",
        "                        )\n",
        "\n",
        "                        rets = np.array(portfolio_data['returns'])\n",
        "                        tovs = np.array(portfolio_data['turnovers'])\n",
        "\n",
        "                        for tc in TC_GRID:\n",
        "                            tag = TC_TAG[tc]\n",
        "                            adj = rets - tovs * tc\n",
        "\n",
        "                            ann_ret = adj.mean() * 252\n",
        "                            ann_vol = adj.std(ddof=1) * np.sqrt(252)\n",
        "                            sharpe  = ann_ret / ann_vol if ann_vol > 0 else 0\n",
        "\n",
        "                            cum_adj = np.cumprod(1 + adj)\n",
        "                            mdd = ((cum_adj - np.maximum.accumulate(cum_adj)) /\n",
        "                                   np.maximum.accumulate(cum_adj)).min()\n",
        "\n",
        "                            metrics[f'{tag}_annual_return'] = ann_ret\n",
        "                            metrics[f'{tag}_annual_vol']    = ann_vol\n",
        "                            metrics[f'{tag}_sharpe']        = sharpe\n",
        "                            metrics[f'{tag}_max_drawdown']  = mdd\n",
        "\n",
        "                        summary_results.append({\n",
        "                            'scheme': scheme,\n",
        "                            'model': model_name,\n",
        "                            'window': window,\n",
        "                            'portfolio_type': portfolio_type,\n",
        "                            **metrics\n",
        "                        })\n",
        "\n",
        "                        rets_arr = np.array(portfolio_data['returns'])\n",
        "                        tovs_arr = np.array(portfolio_data['turnovers'])\n",
        "                        cum_no_tc = np.log1p(rets_arr).cumsum()\n",
        "\n",
        "                        tc_ret_dict = {}\n",
        "                        tc_cum_dict = {}\n",
        "                        for tc in TC_GRID:\n",
        "                            tag = TC_TAG[tc]\n",
        "                            r = rets_arr - tovs_arr * tc\n",
        "                            tc_ret_dict[tag] = r\n",
        "                            tc_cum_dict[tag] = np.log1p(r).cumsum()\n",
        "\n",
        "                        for i, date in enumerate(portfolio_data['dates']):\n",
        "                            row = {\n",
        "                                'scheme'        : scheme,\n",
        "                                'model'         : model_name,\n",
        "                                'window'        : window,\n",
        "                                'portfolio_type': portfolio_type,\n",
        "                                'date'          : str(date),\n",
        "                                'return'        : rets_arr[i],\n",
        "                                'turnover'      : tovs_arr[i],\n",
        "                                'cumulative'    : cum_no_tc[i],\n",
        "                            }\n",
        "                            for tag in TC_TAG.values():\n",
        "                                row[f'{tag}_return']     = tc_ret_dict[tag][i]\n",
        "                                row[f'{tag}_cumulative'] = tc_cum_dict[tag][i]\n",
        "\n",
        "                            daily_series_data.append(row)\n",
        "\n",
        "                if scheme == \"VW\" and len(all_y_true) > 0:\n",
        "                    y_all    = np.concatenate(all_y_true)\n",
        "                    yhat_all = np.concatenate(all_y_pred)\n",
        "                    perm_all = np.concatenate(all_permnos)\n",
        "                    meta_all = pd.concat(all_meta, ignore_index=True)\n",
        "\n",
        "                    k = X_test.shape[1]\n",
        "\n",
        "                    m1_metrics = overall_interval_metrics_method1(\n",
        "                        y_all, yhat_all, k,\n",
        "                        permnos_all=perm_all,\n",
        "                        meta_all=meta_all\n",
        "                    )\n",
        "\n",
        "                    full_pred_df = pd.concat(pred_rows, ignore_index=True)\n",
        "                    mean_ic, t_ic, pos_ic, _ = calc_ic_daily(full_pred_df, method='spearman')\n",
        "                    m1_metrics['RankIC_mean']  = mean_ic\n",
        "                    m1_metrics['RankIC_t']     = t_ic\n",
        "                    m1_metrics['RankIC_pos%']  = pos_ic\n",
        "\n",
        "                    save_metrics(m1_metrics, name=model_name, window=window,\n",
        "                        path=\"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_metrics.csv\")\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_results)\n",
        "    daily_df = pd.DataFrame(daily_series_data) if daily_series_data else pd.DataFrame()\n",
        "\n",
        "    tc_columns = [c for c in summary_df.columns if c.startswith('tc')]\n",
        "    summary_df[tc_columns] = summary_df[tc_columns].fillna(0.0)\n",
        "\n",
        "    def save_split_by_scheme(df, base_filename):\n",
        "        \"\"\"Helper function to save files split by scheme\"\"\"\n",
        "        if df.empty:\n",
        "            print(f\"Warning: DataFrame is empty, skipping save for {base_filename}\")\n",
        "            return None, None\n",
        "\n",
        "        vw_df = df[df['scheme'] == 'VW']\n",
        "        ew_df = df[df['scheme'] == 'EW']\n",
        "\n",
        "        vw_filename = f\"/content/drive/MyDrive/units_large_portfolio/units_results/{base_filename}_VW.csv\"\n",
        "        ew_filename = f\"/content/drive/MyDrive/units_large_portfolio/units_results/{base_filename}_EW.csv\"\n",
        "\n",
        "        vw_df.to_csv(vw_filename, index=False)\n",
        "        ew_df.to_csv(ew_filename, index=False)\n",
        "\n",
        "        print(f\"VW results saved to {vw_filename}\")\n",
        "        print(f\"EW results saved to {ew_filename}\")\n",
        "\n",
        "        return vw_filename, ew_filename\n",
        "\n",
        "    save_split_by_scheme(summary_df, \"portfolio_results_daily_rebalance\")\n",
        "\n",
        "    if not daily_df.empty:\n",
        "        save_split_by_scheme(daily_df, \"portfolio_daily_series\")\n",
        "\n",
        "    if pred_rows:\n",
        "        pred_df = pd.concat(pred_rows, ignore_index=True)\n",
        "        pred_df.to_csv(\"/content/drive/MyDrive/units_large_portfolio/units_results/predictions_daily.csv\", index=False)\n",
        "        print(f\"Saved {len(pred_df)} prediction rows to predictions_daily.csv\")\n",
        "\n",
        "    print(f\"Generated {len(summary_results)} portfolio summary records\")\n",
        "    print(f\"Generated {len(daily_series_data)} daily series records\")\n",
        "\n",
        "    return summary_df, daily_df, backtester\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULq1teB-w4RN"
      },
      "outputs": [],
      "source": [
        "# ========== Save Results ==========\n",
        "\n",
        "import os\n",
        "\n",
        "results_dir = \"/content/drive/MyDrive/units_large_portfolio/units_results\"\n",
        "figures_dir = \"/content/drive/MyDrive/units_large_portfolio/units_figures\"\n",
        "\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "os.makedirs(figures_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "84692ef90e6a4b3e96e65e5b29162dce",
            "00f48e444fbe4e6f85e975c32d118371",
            "5a662da1eeb94f34adf67dae086b4bfd",
            "cbc659f3a24d4fdfbd28d11681190c18",
            "63dbd040e4c64c61873eef68a33bdfb3",
            "7d43b179b3394c21a160d80a102f3c99",
            "3ae30049a5f64c28a0acb66941bfe985",
            "8e84298ce0424ddd8811a5d691331518",
            "1921249e30a2444a86b5da8567fff947",
            "eb7e921fc6e84854add58b1cc12340e3",
            "3c4f74d8cb654ae8998ca6597012a7d4",
            "5df0eda6f70648739350084e7692c0ab",
            "f8bbc8b5826447b48502e94d61907708",
            "2314ada6f10d4599b6d00ffde701b9e0",
            "c8efdee84a1440719566ce4447b85066",
            "eb9f71d0bc584755b8de5a9aaa2fcf26",
            "fca30a3fc4944fc8a8b7bf12ca4aa324",
            "95bd1b8e52294dfdab4eceea69ef796d",
            "1213aeea8e534a868e5ba269852815c2",
            "428ea18e769d4b049cf02959541c21f5",
            "ba7fb1d04d0747eb8511c69f5eed6047",
            "96b1c819196e4606af685be684505e62"
          ]
        },
        "id": "ityTZ5Ycbx16",
        "outputId": "910b1914-a2c7-4708-d78d-b5e757cf0a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Units Large Portfolio Backtesting...\n",
            "Starting Daily Rebalance Portfolio Backtesting Simulation (2016-2024)\n",
            "Processing window size: 5\n",
            "  Model: units large, Scheme: VW\n",
            "  Processing year: 2016\n",
            "Running Uni2TS prediction on 12475 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84692ef90e6a4b3e96e65e5b29162dce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5df0eda6f70648739350084e7692c0ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2017\n",
            "Running Uni2TS prediction on 12434 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2018\n",
            "Running Uni2TS prediction on 12326 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2019\n",
            "Running Uni2TS prediction on 12488 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:56<00:00,  4.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2020\n",
            "Running Uni2TS prediction on 11699 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 12/12 [00:52<00:00,  4.39s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2021\n",
            "Running Uni2TS prediction on 12447 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2022\n",
            "Running Uni2TS prediction on 12220 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 12/12 [00:54<00:00,  4.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2023\n",
            "Running Uni2TS prediction on 12367 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2024\n",
            "Running Uni2TS prediction on 12394 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.29s/it]\n",
            "/tmp/ipython-input-486884232.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: g['y_pred'].corr(g['y_true'], method=method))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics saved for units large_w5 to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_metrics.csv\n",
            "  Model: units large, Scheme: EW\n",
            "  Processing year: 2016\n",
            "Running Uni2TS prediction on 12475 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:56<00:00,  4.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2017\n",
            "Running Uni2TS prediction on 12434 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2018\n",
            "Running Uni2TS prediction on 12326 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2019\n",
            "Running Uni2TS prediction on 12488 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:56<00:00,  4.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2020\n",
            "Running Uni2TS prediction on 11699 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 12/12 [00:52<00:00,  4.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2021\n",
            "Running Uni2TS prediction on 12447 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2022\n",
            "Running Uni2TS prediction on 12220 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 12/12 [00:54<00:00,  4.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2023\n",
            "Running Uni2TS prediction on 12367 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2024\n",
            "Running Uni2TS prediction on 12394 samples with batch size 1024\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 13/13 [00:55<00:00,  4.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing window size: 21\n",
            "  Model: units large, Scheme: VW\n",
            "  Processing year: 2016\n",
            "Running Uni2TS prediction on 12475 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2017\n",
            "Running Uni2TS prediction on 12434 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2018\n",
            "Running Uni2TS prediction on 12326 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2019\n",
            "Running Uni2TS prediction on 12488 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2020\n",
            "Running Uni2TS prediction on 11699 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 23/23 [01:10<00:00,  3.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2021\n",
            "Running Uni2TS prediction on 12447 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2022\n",
            "Running Uni2TS prediction on 12220 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 24/24 [01:13<00:00,  3.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2023\n",
            "Running Uni2TS prediction on 12367 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2024\n",
            "Running Uni2TS prediction on 12394 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  3.00s/it]\n",
            "/tmp/ipython-input-486884232.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: g['y_pred'].corr(g['y_true'], method=method))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics saved for units large_w21 to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_metrics.csv\n",
            "  Model: units large, Scheme: EW\n",
            "  Processing year: 2016\n",
            "Running Uni2TS prediction on 12475 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:16<00:00,  3.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2017\n",
            "Running Uni2TS prediction on 12434 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  3.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2018\n",
            "Running Uni2TS prediction on 12326 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2019\n",
            "Running Uni2TS prediction on 12488 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:15<00:00,  3.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2020\n",
            "Running Uni2TS prediction on 11699 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 23/23 [01:10<00:00,  3.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2021\n",
            "Running Uni2TS prediction on 12447 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2022\n",
            "Running Uni2TS prediction on 12220 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 24/24 [01:13<00:00,  3.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2023\n",
            "Running Uni2TS prediction on 12367 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2024\n",
            "Running Uni2TS prediction on 12394 samples with batch size 512\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 25/25 [01:14<00:00,  2.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing window size: 252\n",
            "  Model: units large, Scheme: VW\n",
            "  Processing year: 2016\n",
            "Running Uni2TS prediction on 12475 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:06<00:00,  7.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2017\n",
            "Running Uni2TS prediction on 12434 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:05<00:00,  7.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2018\n",
            "Running Uni2TS prediction on 12326 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:02<00:00,  7.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2019\n",
            "Running Uni2TS prediction on 12488 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:07<00:00,  7.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2020\n",
            "Running Uni2TS prediction on 11699 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 46/46 [05:44<00:00,  7.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2021\n",
            "Running Uni2TS prediction on 12447 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:06<00:00,  7.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2022\n",
            "Running Uni2TS prediction on 12220 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 48/48 [05:59<00:00,  7.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2023\n",
            "Running Uni2TS prediction on 12367 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:04<00:00,  7.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2024\n",
            "Running Uni2TS prediction on 12394 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:04<00:00,  7.44s/it]\n",
            "/tmp/ipython-input-486884232.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: g['y_pred'].corr(g['y_true'], method=method))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics saved for units large_w252 to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_metrics.csv\n",
            "  Model: units large, Scheme: EW\n",
            "  Processing year: 2016\n",
            "Running Uni2TS prediction on 12475 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:06<00:00,  7.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2017\n",
            "Running Uni2TS prediction on 12434 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:05<00:00,  7.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2018\n",
            "Running Uni2TS prediction on 12326 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:02<00:00,  7.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2019\n",
            "Running Uni2TS prediction on 12488 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:06<00:00,  7.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2020\n",
            "Running Uni2TS prediction on 11699 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 46/46 [05:43<00:00,  7.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2021\n",
            "Running Uni2TS prediction on 12447 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:05<00:00,  7.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2022\n",
            "Running Uni2TS prediction on 12220 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 48/48 [05:59<00:00,  7.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2023\n",
            "Running Uni2TS prediction on 12367 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:03<00:00,  7.42s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2024\n",
            "Running Uni2TS prediction on 12394 samples with batch size 256\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 49/49 [06:04<00:00,  7.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing window size: 512\n",
            "  Model: units large, Scheme: VW\n",
            "  Processing year: 2016\n",
            "Running Uni2TS prediction on 12475 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 98/98 [12:21<00:00,  7.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2017\n",
            "Running Uni2TS prediction on 12434 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 98/98 [12:19<00:00,  7.54s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2018\n",
            "Running Uni2TS prediction on 12326 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 97/97 [12:13<00:00,  7.56s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2019\n",
            "Running Uni2TS prediction on 12488 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 98/98 [12:23<00:00,  7.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2020\n",
            "Running Uni2TS prediction on 11699 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 92/92 [11:36<00:00,  7.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2021\n",
            "Running Uni2TS prediction on 12447 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 98/98 [12:21<00:00,  7.56s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2022\n",
            "Running Uni2TS prediction on 12220 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 96/96 [12:06<00:00,  7.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2023\n",
            "Running Uni2TS prediction on 12367 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 97/97 [12:15<00:00,  7.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2024\n",
            "Running Uni2TS prediction on 12394 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 97/97 [12:16<00:00,  7.60s/it]\n",
            "/tmp/ipython-input-486884232.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: g['y_pred'].corr(g['y_true'], method=method))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics saved for units large_w512 to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_metrics.csv\n",
            "  Model: units large, Scheme: EW\n",
            "  Processing year: 2016\n",
            "Running Uni2TS prediction on 12475 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 98/98 [12:22<00:00,  7.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2017\n",
            "Running Uni2TS prediction on 12434 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 98/98 [12:20<00:00,  7.56s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2018\n",
            "Running Uni2TS prediction on 12326 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 97/97 [12:13<00:00,  7.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2019\n",
            "Running Uni2TS prediction on 12488 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 98/98 [12:23<00:00,  7.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2020\n",
            "Running Uni2TS prediction on 11699 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 92/92 [11:36<00:00,  7.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2021\n",
            "Running Uni2TS prediction on 12447 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 98/98 [12:21<00:00,  7.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2022\n",
            "Running Uni2TS prediction on 12220 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 96/96 [12:07<00:00,  7.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2023\n",
            "Running Uni2TS prediction on 12367 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 97/97 [12:16<00:00,  7.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing year: 2024\n",
            "Running Uni2TS prediction on 12394 samples with batch size 128\n",
            "Initializing Uni2TS model...\n",
            "Model loaded on: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 97/97 [12:17<00:00,  7.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VW results saved to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_results_daily_rebalance_VW.csv\n",
            "EW results saved to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_results_daily_rebalance_EW.csv\n",
            "VW results saved to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_VW.csv\n",
            "EW results saved to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_EW.csv\n",
            "Saved 443400 prediction rows to predictions_daily.csv\n",
            "Generated 24 portfolio summary records\n",
            "Generated 52272 daily series records\n",
            "\\n============================================================\n",
            "UNITS LARGE PORTFOLIO BACKTESTING RESULTS\n",
            "============================================================\n",
            "\\nSummary Results:\n",
            "   scheme        model  window portfolio_type  annual_return  annual_vol  \\\n",
            "0      VW  units large       5      long_only         0.1140      0.1964   \n",
            "1      VW  units large       5     short_only        -0.1959      0.2073   \n",
            "2      VW  units large       5     long_short        -0.0819      0.2213   \n",
            "3      EW  units large       5      long_only         0.1255      0.2028   \n",
            "4      EW  units large       5     short_only        -0.1359      0.2183   \n",
            "5      EW  units large       5     long_short        -0.0104      0.2183   \n",
            "6      VW  units large      21      long_only         0.1051      0.1930   \n",
            "7      VW  units large      21     short_only        -0.2267      0.2121   \n",
            "8      VW  units large      21     long_short        -0.1216      0.2195   \n",
            "9      EW  units large      21      long_only         0.0904      0.2021   \n",
            "10     EW  units large      21     short_only        -0.1763      0.2208   \n",
            "11     EW  units large      21     long_short        -0.0859      0.2166   \n",
            "12     VW  units large     252      long_only         0.0544      0.1959   \n",
            "13     VW  units large     252     short_only        -0.2274      0.2167   \n",
            "14     VW  units large     252     long_short        -0.1730      0.2270   \n",
            "15     EW  units large     252      long_only         0.0584      0.1990   \n",
            "16     EW  units large     252     short_only        -0.2185      0.2251   \n",
            "17     EW  units large     252     long_short        -0.1600      0.2082   \n",
            "18     VW  units large     512      long_only         0.0795      0.1905   \n",
            "19     VW  units large     512     short_only        -0.1500      0.2173   \n",
            "20     VW  units large     512     long_short        -0.0705      0.2191   \n",
            "21     EW  units large     512      long_only         0.0963      0.1987   \n",
            "22     EW  units large     512     short_only        -0.1738      0.2257   \n",
            "23     EW  units large     512     long_short        -0.0775      0.2141   \n",
            "\n",
            "    sharpe  max_drawdown  max_1d_loss  avg_turnover  ...  tc20_sharpe  \\\n",
            "0   0.5805        0.4505      -0.0733        1.7394  ...      -3.8735   \n",
            "1  -0.9453        0.8576      -0.0511        1.7674  ...      -5.2354   \n",
            "2  -0.3704        0.7166      -0.0745        3.5075  ...      -8.3484   \n",
            "3   0.6187        0.2903      -0.0730        1.5984  ...      -3.3592   \n",
            "4  -0.6224        0.7727      -0.0758        1.6315  ...      -4.3882   \n",
            "5  -0.0476        0.4816      -0.0675        3.2306  ...      -7.5119   \n",
            "6   0.5447        0.3520      -0.0456        1.6976  ...      -3.8892   \n",
            "7  -1.0689        0.8991      -0.0734        1.6818  ...      -5.0512   \n",
            "8  -0.5541        0.7805      -0.0734        3.3801  ...      -8.2976   \n",
            "9   0.4472        0.3339      -0.0568        1.5382  ...      -3.3915   \n",
            "10 -0.7985        0.8412      -0.0728        1.5261  ...      -4.2821   \n",
            "11 -0.3966        0.7166      -0.0764        3.0650  ...      -7.5391   \n",
            "12  0.2777        0.3043      -0.0489        1.6392  ...      -3.9424   \n",
            "13 -1.0493        0.8918      -0.0734        1.6812  ...      -4.9474   \n",
            "14 -0.7622        0.8277      -0.0720        3.3211  ...      -8.1672   \n",
            "15  0.2936        0.3497      -0.0442        1.5022  ...      -3.5198   \n",
            "16 -0.9705        0.8931      -0.0734        1.4955  ...      -4.3097   \n",
            "17 -0.7686        0.8148      -0.0734        2.9983  ...      -8.0256   \n",
            "18  0.4172        0.2933      -0.0489        1.6444  ...      -3.9254   \n",
            "19 -0.6902        0.8041      -0.0734        1.6848  ...      -4.5910   \n",
            "20 -0.3217        0.6759      -0.0633        3.3295  ...      -7.9535   \n",
            "21  0.4844        0.3587      -0.0469        1.5097  ...      -3.3434   \n",
            "22 -0.7702        0.8469      -0.0734        1.5231  ...      -4.1751   \n",
            "23 -0.3622        0.7211      -0.0734        3.0332  ...      -7.5121   \n",
            "\n",
            "    tc20_max_drawdown  tc30_annual_return  tc30_annual_vol  tc30_sharpe  \\\n",
            "0             -0.9989             -1.2010           0.1974      -6.0828   \n",
            "1             -0.9999             -1.5321           0.2080      -7.3664   \n",
            "2             -1.0000             -2.7336           0.2223     -12.2975   \n",
            "3             -0.9977             -1.0829           0.2025      -5.3470   \n",
            "4             -0.9998             -1.3693           0.2186      -6.2645   \n",
            "5             -1.0000             -2.4527           0.2185     -11.2243   \n",
            "6             -0.9987             -1.1783           0.1933      -6.0955   \n",
            "7             -0.9999             -1.4982           0.2133      -7.0225   \n",
            "8             -1.0000             -2.6770           0.2210     -12.1156   \n",
            "9             -0.9978             -1.0725           0.2021      -5.3063   \n",
            "10            -0.9998             -1.3300           0.2210      -6.0169   \n",
            "11            -1.0000             -2.4030           0.2166     -11.0932   \n",
            "12            -0.9989             -1.1848           0.1961      -6.0417   \n",
            "13            -0.9999             -1.4984           0.2178      -6.8796   \n",
            "14            -1.0000             -2.6837           0.2264     -11.8518   \n",
            "15            -0.9980             -1.0773           0.1985      -5.4264   \n",
            "16            -0.9998             -1.3490           0.2261      -5.9675   \n",
            "17            -1.0000             -2.4268           0.2087     -11.6255   \n",
            "18            -0.9987             -1.1637           0.1915      -6.0766   \n",
            "19            -0.9999             -1.4237           0.2181      -6.5264   \n",
            "20            -1.0000             -2.5876           0.2210     -11.7099   \n",
            "21            -0.9974             -1.0450           0.1990      -5.2506   \n",
            "22            -0.9998             -1.3253           0.2256      -5.8735   \n",
            "23            -1.0000             -2.3706           0.2142     -11.0680   \n",
            "\n",
            "    tc30_max_drawdown  tc40_annual_return  tc40_annual_vol  tc40_sharpe  \\\n",
            "0             -1.0000             -1.6393           0.1982      -8.2711   \n",
            "1             -1.0000             -1.9775           0.2086      -9.4808   \n",
            "2             -1.0000             -3.6175           0.2234     -16.1940   \n",
            "3             -0.9999             -1.4857           0.2027      -7.3280   \n",
            "4             -1.0000             -1.7804           0.2189      -8.1315   \n",
            "5             -1.0000             -3.2668           0.2192     -14.9019   \n",
            "6             -1.0000             -1.6061           0.1939      -8.2838   \n",
            "7             -1.0000             -1.9220           0.2142      -8.9721   \n",
            "8             -1.0000             -3.5287           0.2224     -15.8655   \n",
            "9             -0.9999             -1.4601           0.2025      -7.2121   \n",
            "10            -1.0000             -1.7146           0.2215      -7.7420   \n",
            "11            -1.0000             -3.1754           0.2173     -14.6143   \n",
            "12            -1.0000             -1.5979           0.1968      -8.1214   \n",
            "13            -1.0000             -1.9221           0.2186      -8.7931   \n",
            "14            -1.0000             -3.5206           0.2272     -15.4928   \n",
            "15            -0.9999             -1.4558           0.1987      -7.3268   \n",
            "16            -1.0000             -1.7259           0.2267      -7.6128   \n",
            "17            -1.0000             -3.1824           0.2096     -15.1834   \n",
            "18            -1.0000             -1.5781           0.1924      -8.2012   \n",
            "19            -1.0000             -1.8483           0.2189      -8.4437   \n",
            "20            -1.0000             -3.4266           0.2226     -15.3946   \n",
            "21            -0.9999             -1.4255           0.1994      -7.1472   \n",
            "22            -1.0000             -1.7091           0.2259      -7.5645   \n",
            "23            -1.0000             -3.1350           0.2149     -14.5893   \n",
            "\n",
            "    tc40_max_drawdown  \n",
            "0                -1.0  \n",
            "1                -1.0  \n",
            "2                -1.0  \n",
            "3                -1.0  \n",
            "4                -1.0  \n",
            "5                -1.0  \n",
            "6                -1.0  \n",
            "7                -1.0  \n",
            "8                -1.0  \n",
            "9                -1.0  \n",
            "10               -1.0  \n",
            "11               -1.0  \n",
            "12               -1.0  \n",
            "13               -1.0  \n",
            "14               -1.0  \n",
            "15               -1.0  \n",
            "16               -1.0  \n",
            "17               -1.0  \n",
            "18               -1.0  \n",
            "19               -1.0  \n",
            "20               -1.0  \n",
            "21               -1.0  \n",
            "22               -1.0  \n",
            "23               -1.0  \n",
            "\n",
            "[24 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Starting Units Large Portfolio Backtesting...\")\n",
        "\n",
        "summary_results, daily_series, backtester = run_uni2ts_portfolio_backtest(\n",
        "    start_year=START_YEAR,\n",
        "    end_year=2024,\n",
        "    window_sizes=WINDOW_SIZES\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"UNITS LARGE PORTFOLIO BACKTESTING RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nSummary Results:\")\n",
        "print(summary_results.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o21jn1Gbbx17",
        "outputId": "ad939863-b9df-45a9-f111-f8c5619ca6ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Saved] 5_factor_analysis_VW_gross.csv \n",
            "[Saved] 5_factor_analysis_VW_net.csv \n",
            "[Saved] 5_factor_analysis_EW_gross.csv \n",
            "[Saved] 5_factor_analysis_EW_net.csv \n"
          ]
        }
      ],
      "source": [
        "# ---------- Main function for 5-factor regression -----------\n",
        "def run_factor_regression(port_ret, factors, use_excess=True):\n",
        "    df = pd.concat([port_ret, factors], axis=1, join='inner').dropna()\n",
        "    df.columns = ['ret'] + list(factors.columns)\n",
        "\n",
        "    if use_excess:\n",
        "        y = df['ret'].values\n",
        "    else:\n",
        "        y = df['ret'].values - df['rf'].values\n",
        "\n",
        "    X = df[['mktrf','smb','hml','rmw','cma','umd']].values\n",
        "    X = sm.add_constant(X)\n",
        "\n",
        "    model = sm.OLS(y, X)\n",
        "    res = model.fit()\n",
        "    alpha = res.params[0]          \n",
        "    resid_std = res.resid.std(ddof=1)\n",
        "\n",
        "    ir_daily = alpha / resid_std          \n",
        "    ir_annual = ir_daily * np.sqrt(252)   \n",
        "\n",
        "    y_hat = np.asarray(res.fittedvalues)  \n",
        "\n",
        "    out = {\n",
        "        'N_obs'            : len(y),\n",
        "        'alpha_daily'      : alpha,\n",
        "        'alpha_annual'     : alpha*252,\n",
        "        't_alpha'          : res.tvalues[0],\n",
        "        'IR_daily'         : ir_daily,\n",
        "        'IR_annual'        : ir_annual,\n",
        "        'R2_zero'          : r2_zero(y, y_hat),\n",
        "    }\n",
        "\n",
        "    factor_names = ['MKT','SMB','HML','RMW','CMA','UMD']\n",
        "    for i, fac in enumerate(factor_names, start=1):\n",
        "        out[f'beta_{fac}'] = res.params[i]\n",
        "        out[f't_{fac}']    = res.tvalues[i]\n",
        "\n",
        "    return out\n",
        "\n",
        "# ---------- Batch run for EW/VW and three portfolio types ----------\n",
        "def batch_factor_analysis(\n",
        "    daily_df: pd.DataFrame,\n",
        "    factors_path: str,\n",
        "    scheme: str,\n",
        "    tc_levels=(0, 5, 10, 20, 40),\n",
        "    portfolio_types=('long_only','short_only','long_short'),\n",
        "    model_filter=None,\n",
        "    window_filter=None,\n",
        "    gross_only=False,            \n",
        "    out_dir='/content/drive/MyDrive/units_large_portfolio/units_results/factor_IR_results',\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate a CSV file containing IR results.\n",
        "    gross_only=True  → only tc=0; False → all tc_levels.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    fac = (pd.read_csv(factors_path, parse_dates=['date'])\n",
        "             .set_index('date')\n",
        "             .sort_index())\n",
        "\n",
        "    sub = daily_df[daily_df['scheme'] == scheme].copy()\n",
        "    if model_filter is not None:\n",
        "        sub = sub[sub['model'].isin(model_filter)]\n",
        "    if window_filter is not None:\n",
        "        sub = sub[sub['window'].isin(window_filter)]\n",
        "\n",
        "    tc_iter = (0,) if gross_only else tc_levels\n",
        "    results = []\n",
        "\n",
        "    for (model, win, ptype), g in sub.groupby(['model','window','portfolio_type']):\n",
        "        g = g.sort_values('date').set_index(pd.to_datetime(g['date']))\n",
        "\n",
        "        for tc in tc_iter:\n",
        "            col = 'return' if tc == 0 else f'tc{tc}_return'\n",
        "            if col not in g.columns:\n",
        "                continue  \n",
        "            port_ret = g[col]\n",
        "            stats = run_factor_regression(port_ret, fac, use_excess=True)\n",
        "            stats.update({\n",
        "                'scheme'        : scheme,\n",
        "                'model'         : model,\n",
        "                'window'        : win,\n",
        "                'portfolio_type': ptype,\n",
        "                'tc_bps'        : tc,\n",
        "            })\n",
        "            results.append(stats)\n",
        "\n",
        "    df_out = pd.DataFrame(results)[[\n",
        "        'scheme','model','window','portfolio_type','tc_bps','N_obs',\n",
        "        'alpha_daily','alpha_annual','t_alpha',\n",
        "        'IR_daily','IR_annual','R2_zero',\n",
        "        'beta_MKT','t_MKT','beta_SMB','t_SMB',\n",
        "        'beta_HML','t_HML','beta_RMW','t_RMW',\n",
        "        'beta_CMA','t_CMA','beta_UMD','t_UMD'\n",
        "    ]]\n",
        "\n",
        "    tag = 'gross' if gross_only else 'net'\n",
        "    fname = f'5_factor_analysis_{scheme}_{tag}.csv'\n",
        "    df_out.to_csv(os.path.join(out_dir, fname), index=False)\n",
        "    print(f'[Saved] {fname}')\n",
        "    return df_out\n",
        "\n",
        "\n",
        "\n",
        "def run_all_factor_tests(vw_csv=\"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_VW.csv\",\n",
        "                         ew_csv=\"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_EW.csv\",\n",
        "                         factor_csv=\"/content/drive/MyDrive/ERP Data/5_Factors_Plus_Momentum.csv\",\n",
        "                         save_dir=\"/content/drive/MyDrive/units_large_portfolio/units_results\",\n",
        "                         y_is_excess=True,\n",
        "                         hac_lags=5,\n",
        "                         save_txt=True):\n",
        "    vw_df = pd.read_csv(vw_csv)\n",
        "    ew_df = pd.read_csv(ew_csv)\n",
        "\n",
        "    vw_gross = batch_factor_analysis(\n",
        "        vw_df, factor_csv, scheme='VW', gross_only=True)    \n",
        "    vw_net   = batch_factor_analysis(\n",
        "        vw_df, factor_csv, scheme='VW', gross_only=False)   \n",
        "\n",
        "    ew_gross = batch_factor_analysis(\n",
        "        ew_df, factor_csv, scheme='EW', gross_only=True)\n",
        "    ew_net   = batch_factor_analysis(\n",
        "        ew_df, factor_csv, scheme='EW', gross_only=False)\n",
        "\n",
        "    return vw_gross, vw_net, ew_gross, ew_net\n",
        "\n",
        "\n",
        "vw_gross, vw_net, ew_gross, ew_net = run_all_factor_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgCdADcObx17",
        "outputId": "a762fb38-a689-4e2d-f1f3-f9421d4988fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3693239445.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  for _, group in df.groupby([\"scheme\", \"model\", \"window\", \"portfolio_type\"], sort=False):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finish: /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_VW_with_rf.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3693239445.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  for _, group in df.groupby([\"scheme\", \"model\", \"window\", \"portfolio_type\"], sort=False):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finish: /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_EW_with_rf.csv\n"
          ]
        }
      ],
      "source": [
        "# === File paths ===\n",
        "rf_file = \"/content/drive/MyDrive/ERP Data/CRSP_2016_2024_top50_with_exret.csv\"\n",
        "vw_file = \"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_VW.csv\"\n",
        "ew_file = \"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_EW.csv\"\n",
        "\n",
        "# === Load risk-free rate (rf) data ===\n",
        "\n",
        "rf_df = pd.read_csv(rf_file, usecols=[\"date\", \"rf\"])\n",
        "rf_df[\"date\"] = pd.to_datetime(rf_df[\"date\"])\n",
        "rf_dict = dict(zip(rf_df[\"date\"], rf_df[\"rf\"]))\n",
        "\n",
        "\n",
        "def adjust_returns_with_rf_grouped(file_path, output_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Parse date with mixed format or dayfirst=True to handle different date formats\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], format='mixed', dayfirst=True)\n",
        "\n",
        "    # Find all return columns (including tc5_return, tc10_return, etc.)\n",
        "    return_cols = [col for col in df.columns if \"return\" in col and \"cumul\" not in col]\n",
        "\n",
        "    # Enforce portfolio_type order to avoid groupby sorting issues\n",
        "    order = [\"long_only\", \"short_only\", \"long_short\"]\n",
        "    df[\"portfolio_type\"] = pd.Categorical(df[\"portfolio_type\"], categories=order, ordered=True)\n",
        "\n",
        "    df_list = []\n",
        "    # Group by scheme/model/window/portfolio_type, add rf and recalculate cumulative\n",
        "    for _, group in df.groupby([\"scheme\", \"model\", \"window\", \"portfolio_type\"], sort=False):\n",
        "        group = group.sort_values(\"date\").copy()\n",
        "        for col in return_cols:\n",
        "            group[col] = group.apply(lambda row: row[col] + rf_dict.get(row[\"date\"], 0), axis=1)\n",
        "            cum_col = col.replace(\"return\", \"cumulative\")\n",
        "            group[cum_col] = np.log1p(group[col]).cumsum()\n",
        "        df_list.append(group)\n",
        "\n",
        "    df_new = pd.concat(df_list).sort_values([\"scheme\", \"model\", \"window\", \"portfolio_type\", \"date\"])\n",
        "    df_new.to_csv(output_path, index=False)\n",
        "    print(f\"Finished: {output_path}\")\n",
        "\n",
        "# Process VW and EW files\n",
        "adjust_returns_with_rf_grouped(vw_file, \"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_VW_with_rf.csv\")\n",
        "adjust_returns_with_rf_grouped(ew_file, \"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_EW_with_rf.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_4agDTew4RO",
        "outputId": "95722c0a-3b80-450c-9e70-7ce02418044c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4244301681.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  sp500 = yf.download(\"^GSPC\", start=\"2016-01-01\", end=\"2024-12-31\")\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All figures have been generated and saved to: /content/drive/MyDrive/units_large_portfolio/units_figures/\n"
          ]
        }
      ],
      "source": [
        "# Download S&P500 (2016-2024)\n",
        "sp500 = yf.download(\"^GSPC\", start=\"2016-01-01\", end=\"2024-12-31\")\n",
        "price_col = \"Adj Close\" if \"Adj Close\" in sp500.columns else \"Close\"\n",
        "sp500[\"daily_return\"] = sp500[price_col].pct_change().fillna(0)\n",
        "# Cumulative log return\n",
        "sp500[\"cum_return\"] = np.cumsum(np.log1p(sp500[\"daily_return\"]))\n",
        "sp500 = sp500[[\"cum_return\"]]\n",
        "sp500.index = pd.to_datetime(sp500.index)\n",
        "\n",
        "# Configuration\n",
        "files = [\n",
        "    (\"VW\", \"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_VW_with_rf.csv\"),\n",
        "    (\"EW\", \"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_daily_series_EW_with_rf.csv\")\n",
        "]\n",
        "tc_levels = [0, 5, 10, 20, 40]      # Transaction cost (bps)\n",
        "windows = [5, 21, 252, 512]         # Window size\n",
        "strategies = [\"long_only\", \"short_only\", \"long_short\"]\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/units_large_portfolio/units_figures\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Major economic event periods (for shading)\n",
        "crisis_periods = [\n",
        "    (datetime(2018, 6, 1), datetime(2019, 1, 1), \"US-China Trade War\"),\n",
        "    (datetime(2020, 2, 1), datetime(2020, 7, 1), \"COVID-19\"),\n",
        "    (datetime(2022, 2, 1), datetime(2022, 6, 1), \"Russia-Ukraine War\"),\n",
        "    (datetime(2023, 1, 1), datetime(2023, 4, 1), \"US Bank Crisis\"),\n",
        "]\n",
        "\n",
        "def plot_comparison_styled(df, scheme, tc, window):\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    model_names = df[\"model\"].unique()\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(model_names)))\n",
        "\n",
        "    offset_step = 0.02\n",
        "\n",
        "    for i, strat in enumerate(strategies, 1):\n",
        "        ax = plt.subplot(3, 1, i)\n",
        "\n",
        "        # Plot S&P500 baseline\n",
        "        plt.plot(sp500.index, sp500[\"cum_return\"],\n",
        "                 color=\"black\", lw=2.5, label=\"S&P500 (Total Return)\", zorder=10)\n",
        "\n",
        "        for idx, model_name in enumerate(model_names):\n",
        "            sub = df[(df[\"window\"] == window) &\n",
        "                     (df[\"portfolio_type\"] == strat) &\n",
        "                     (df[\"model\"] == model_name)].sort_values(\"date\")\n",
        "            if sub.empty:\n",
        "                continue\n",
        "\n",
        "            # Select return column based on transaction cost\n",
        "            if tc == 0:\n",
        "                ret_col = \"return\"\n",
        "            else:\n",
        "                ret_col = f\"tc{tc}_return\"\n",
        "\n",
        "            if ret_col not in sub.columns:\n",
        "                continue\n",
        "\n",
        "            # Cumulative log return\n",
        "            log_cum = np.cumsum(np.log1p(sub[ret_col].values))\n",
        "\n",
        "            y_shift = idx * offset_step\n",
        "            plt.plot(sub[\"date\"], log_cum + y_shift,\n",
        "                     label=f\"{model_name} ({strat.replace('_',' ').title()})\",\n",
        "                     lw=2, color=colors[idx], alpha=0.9)\n",
        "\n",
        "        # Shade crisis periods\n",
        "        for start, end, label in crisis_periods:\n",
        "            ax.axvspan(start, end, color='grey', alpha=0.3)\n",
        "            ax.text(start + pd.Timedelta(days=10),\n",
        "                    ax.get_ylim()[1]*0.92, label, fontsize=8, color='grey')\n",
        "        ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "        ax.set_ylabel(\"Cumulative log return (start = 0)\")\n",
        "        ax.set_title(f\"{scheme} | Window={window} | Strategy={strat} | TC={tc} bps\")\n",
        "        ax.grid(alpha=0.3)\n",
        "        plt.xticks(rotation=30)\n",
        "        plt.legend(bbox_to_anchor=(1.04, 1), loc='upper left', fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fname = f\"{scheme}_window{window}_TC{tc}.png\"\n",
        "    plt.savefig(os.path.join(output_dir, fname), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# Main loop to generate all figures\n",
        "for scheme, file_path in files:\n",
        "    df = pd.read_csv(file_path)\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    for tc in tc_levels:\n",
        "        for window in windows:\n",
        "            plot_comparison_styled(df, scheme, tc, window)\n",
        "\n",
        "print(f\"All figures have been generated and saved to: {output_dir}/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJKjya1dw4RO",
        "outputId": "a2a8c72a-e00e-4f0c-c77f-7fc38686f68a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Update] ΔSharpe has been written to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_results_daily_rebalance_VW.csv\n",
            "[Update] ΔSharpe has been written to /content/drive/MyDrive/units_large_portfolio/units_results/portfolio_results_daily_rebalance_EW.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load R²_zero from portfolio_metrics.csv\n",
        "metrics_df = pd.read_csv(\"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_metrics.csv\")[[\"Model\", \"Window\", \"R²_zero\"]]\n",
        "metrics_df.rename(columns={\"Model\": \"model\", \"Window\": \"window\"}, inplace=True)\n",
        "\n",
        "# Process both VW and EW files\n",
        "for fname in [\"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_results_daily_rebalance_VW.csv\", \"/content/drive/MyDrive/units_large_portfolio/units_results/portfolio_results_daily_rebalance_EW.csv\"]:\n",
        "    df = pd.read_csv(fname)\n",
        "\n",
        "    # Merge R²_zero by model and window\n",
        "    df = df.merge(metrics_df, on=[\"model\", \"window\"], how=\"left\")\n",
        "\n",
        "    rows = []\n",
        "    for _, row in df.iterrows():\n",
        "        r2 = float(row[\"R²_zero\"]) if not pd.isna(row[\"R²_zero\"]) else 0.0\n",
        "        if row[\"portfolio_type\"] == \"long_only\":\n",
        "            d_sr, sr_star = delta_sharpe(r2, SR_MKT_EX)\n",
        "            row[\"ΔSharpe\"]  = d_sr\n",
        "            row[\"Sharpe*\"]  = sr_star\n",
        "            row[\"baseline\"] = f\"SPX_excess ({SR_MKT_EX:.2f})\"\n",
        "        else:\n",
        "            d_sr, sr_star = delta_sharpe(r2, 0)\n",
        "            row[\"ΔSharpe\"]  = d_sr\n",
        "            row[\"Sharpe*\"]  = sr_star\n",
        "            row[\"baseline\"] = \"cash (0)\"\n",
        "        rows.append(row)\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(fname, index=False)\n",
        "    print(f\"[Update] ΔSharpe has been written to {fname}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (UniTS)",
      "language": "python",
      "name": "uni2ts"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00f48e444fbe4e6f85e975c32d118371": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d43b179b3394c21a160d80a102f3c99",
            "placeholder": "​",
            "style": "IPY_MODEL_3ae30049a5f64c28a0acb66941bfe985",
            "value": "config.json: 100%"
          }
        },
        "1213aeea8e534a868e5ba269852815c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1921249e30a2444a86b5da8567fff947": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2314ada6f10d4599b6d00ffde701b9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1213aeea8e534a868e5ba269852815c2",
            "max": 1243917120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_428ea18e769d4b049cf02959541c21f5",
            "value": 1243917120
          }
        },
        "3ae30049a5f64c28a0acb66941bfe985": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c4f74d8cb654ae8998ca6597012a7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "428ea18e769d4b049cf02959541c21f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a662da1eeb94f34adf67dae086b4bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e84298ce0424ddd8811a5d691331518",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1921249e30a2444a86b5da8567fff947",
            "value": 684
          }
        },
        "5df0eda6f70648739350084e7692c0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8bbc8b5826447b48502e94d61907708",
              "IPY_MODEL_2314ada6f10d4599b6d00ffde701b9e0",
              "IPY_MODEL_c8efdee84a1440719566ce4447b85066"
            ],
            "layout": "IPY_MODEL_eb9f71d0bc584755b8de5a9aaa2fcf26"
          }
        },
        "63dbd040e4c64c61873eef68a33bdfb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d43b179b3394c21a160d80a102f3c99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84692ef90e6a4b3e96e65e5b29162dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00f48e444fbe4e6f85e975c32d118371",
              "IPY_MODEL_5a662da1eeb94f34adf67dae086b4bfd",
              "IPY_MODEL_cbc659f3a24d4fdfbd28d11681190c18"
            ],
            "layout": "IPY_MODEL_63dbd040e4c64c61873eef68a33bdfb3"
          }
        },
        "8e84298ce0424ddd8811a5d691331518": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95bd1b8e52294dfdab4eceea69ef796d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96b1c819196e4606af685be684505e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba7fb1d04d0747eb8511c69f5eed6047": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8efdee84a1440719566ce4447b85066": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba7fb1d04d0747eb8511c69f5eed6047",
            "placeholder": "​",
            "style": "IPY_MODEL_96b1c819196e4606af685be684505e62",
            "value": " 1.24G/1.24G [00:19&lt;00:00, 84.7MB/s]"
          }
        },
        "cbc659f3a24d4fdfbd28d11681190c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb7e921fc6e84854add58b1cc12340e3",
            "placeholder": "​",
            "style": "IPY_MODEL_3c4f74d8cb654ae8998ca6597012a7d4",
            "value": " 684/684 [00:00&lt;00:00, 35.0kB/s]"
          }
        },
        "eb7e921fc6e84854add58b1cc12340e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb9f71d0bc584755b8de5a9aaa2fcf26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8bbc8b5826447b48502e94d61907708": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fca30a3fc4944fc8a8b7bf12ca4aa324",
            "placeholder": "​",
            "style": "IPY_MODEL_95bd1b8e52294dfdab4eceea69ef796d",
            "value": "model.safetensors: 100%"
          }
        },
        "fca30a3fc4944fc8a8b7bf12ca4aa324": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
