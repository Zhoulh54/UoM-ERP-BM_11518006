{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders)\n"
     ]
    }
   ],
   "source": [
    "# ========== Basic Libraries ==========\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import warnings\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import joblib  # joblib for loading scaler\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== Evaluation Metrics ==========\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ========== Statistics ==========\n",
    "from scipy.stats import f as f_dist\n",
    "import yfinance as yf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ========== Hyperparameter Tuning ==========\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ========== Visualization ==========\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========== Global Configuration ==========\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# ========== MPS Acceleration Configuration ==========\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Metal Performance Shaders)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision('medium')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Data Loading ==========\n",
    "def load_datasets(npz_path=\"/Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/all_window_datasets_scaled.npz\"):\n",
    "    data = np.load(npz_path, allow_pickle=True) \n",
    "    datasets = {}\n",
    "    for key in data.files:\n",
    "        datasets[key] = data[key]\n",
    "    return datasets\n",
    "\n",
    "def prepare_sequences(X, y, lookback):\n",
    "    \"\"\"Prepare sequence data for N-BEATS training\"\"\"\n",
    "    if len(X) < lookback:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    X_seq, y_seq = [], []\n",
    "    \n",
    "    for i in range(lookback, len(X)):\n",
    "        X_seq.append(X[i])\n",
    "        if y is not None:\n",
    "            y_seq.append(y[i])\n",
    "    \n",
    "    if y is None:\n",
    "        return np.array(X_seq), np.array([])\n",
    "    return np.array(X_seq), np.array(y_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] S&P500 Excess Sharpe (2016–24) = 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== Core Function Definitions ==========\n",
    "def r2_zero(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute zero-based R² (baseline is zero).\n",
    "    y_true: true values (N,)\n",
    "    y_pred: predicted values (N,)\n",
    "    \"\"\"\n",
    "    rss = np.sum((y_true - y_pred)**2)  \n",
    "    tss = np.sum(y_true**2)            \n",
    "    return 1 - rss / tss\n",
    "\n",
    "def calc_ic_daily(df, method='spearman'):\n",
    "    \"\"\"\n",
    "    Calculate daily cross-sectional RankIC.\n",
    "    df: must contain ['signal_date','y_true','y_pred']\n",
    "    \"\"\"\n",
    "    ics = (df.groupby('signal_date')\n",
    "             .apply(lambda g: g['y_pred'].corr(g['y_true'], method=method))\n",
    "             .dropna())\n",
    "    mean_ic = ics.mean()\n",
    "    std_ic  = ics.std(ddof=1)\n",
    "    t_ic    = mean_ic / (std_ic / np.sqrt(len(ics))) if std_ic > 0 else np.nan\n",
    "    pos_ratio = (ics > 0).mean()\n",
    "    return mean_ic, t_ic, pos_ratio, ics\n",
    "\n",
    "def annual_sharpe(rets, freq=252):\n",
    "    mu = float(np.mean(rets)) * freq\n",
    "    sd = float(np.std(rets, ddof=1)) * np.sqrt(freq)\n",
    "    return mu / sd if sd > 0 else 0\n",
    "\n",
    "def delta_sharpe(r2_zero: float, sr_base: float):\n",
    "    \"\"\"\n",
    "    If r2_zero <= 0 or r2_zero >= 1, ΔSharpe = 0, Sharpe* = sr_base.\n",
    "    Otherwise, compute by the original formula.\n",
    "    \"\"\"\n",
    "    if (r2_zero <= 0) or (r2_zero >= 1):\n",
    "        return 0.0, sr_base\n",
    "    sr_star = np.sqrt(sr_base ** 2 + r2_zero) / np.sqrt(1 - r2_zero)\n",
    "    return sr_star - sr_base, sr_star\n",
    "\n",
    "rf_file = \"/Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/CRSP_2016_2024_top50_with_exret.csv\"\n",
    "rf_df = pd.read_csv(rf_file, usecols=[\"date\", \"rf\"])\n",
    "rf_df[\"date\"] = pd.to_datetime(rf_df[\"date\"])\n",
    "rf_df = rf_df.drop_duplicates(\"date\").set_index(\"date\").sort_index()\n",
    "rf_series = rf_df[\"rf\"].astype(float)\n",
    "\n",
    "px = yf.download(\"^GSPC\", start=\"2016-01-01\", end=\"2024-12-31\")[\"Close\"]\n",
    "sp_ret = px.pct_change().dropna()\n",
    "rf_align = rf_series.reindex(sp_ret.index).fillna(method=\"ffill\")\n",
    "sp_excess = sp_ret.values - rf_align.values\n",
    "\n",
    "SR_MKT_EX = annual_sharpe(sp_excess)\n",
    "print(f\"[INFO] S&P500 Excess Sharpe (2016-24) = {SR_MKT_EX:.3f}\")\n",
    "\n",
    "def calc_directional_metrics(y_true, y_pred, permnos=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    - Sample-level sign prediction\n",
    "    - If grouped by stock, compute Overall, Up, Down for each stock and then average\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    if permnos is None:\n",
    "        s_true = np.sign(y_true)\n",
    "        s_pred = np.sign(y_pred)\n",
    "        mask = s_true != 0\n",
    "        s_true = s_true[mask]\n",
    "        s_pred = s_pred[mask]\n",
    "\n",
    "        overall_acc = np.mean(s_true == s_pred)\n",
    "\n",
    "        up_mask = s_true > 0\n",
    "        down_mask = s_true < 0\n",
    "        up_acc = np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else 0\n",
    "        down_acc = np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else 0\n",
    "\n",
    "    else:\n",
    "        df = pd.DataFrame({\"permno\": permnos, \"yt\": y_true, \"yp\": y_pred})\n",
    "        overall_accs = []\n",
    "        up_accs = []\n",
    "        down_accs = []\n",
    "\n",
    "        for _, g in df.groupby(\"permno\"):\n",
    "            s_true = np.sign(g[\"yt\"].values)\n",
    "            s_pred = np.sign(g[\"yp\"].values)\n",
    "            mask = s_true != 0\n",
    "            s_true = s_true[mask]\n",
    "            s_pred = s_pred[mask]\n",
    "            if len(s_true) == 0:\n",
    "                continue\n",
    "            overall_accs.append(np.mean(s_true == s_pred))\n",
    "\n",
    "            up_mask = s_true > 0\n",
    "            down_mask = s_true < 0\n",
    "            up_accs.append(np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else np.nan)\n",
    "            down_accs.append(np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else np.nan)\n",
    "\n",
    "        overall_acc = np.nanmean(overall_accs)\n",
    "        up_acc = np.nanmean(up_accs)\n",
    "        down_acc = np.nanmean(down_accs)\n",
    "\n",
    "    return overall_acc, up_acc, down_acc\n",
    "\n",
    "def regression_metrics(y_true, y_pred, k, meta=None, permnos=None):\n",
    "    \"\"\"\n",
    "    Combined regression metrics:\n",
    "    - Regression metrics\n",
    "    - Pointwise directional accuracy\n",
    "    - Market cap group metrics\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    n = len(y_true)\n",
    "\n",
    "    r2 = r2_zero(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    dir_acc, up_acc, down_acc = calc_directional_metrics(y_true, y_pred, permnos)\n",
    "\n",
    "    metrics = {\n",
    "        \"R²_zero\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"Directional Accuracy\": dir_acc,\n",
    "        \"Up_Directional_Acc\": up_acc,\n",
    "        \"Down_Directional_Acc\": down_acc\n",
    "    }\n",
    "\n",
    "    if meta is not None and \"MKTCAP_PERCENTILE\" in meta:\n",
    "        top_mask = meta[\"MKTCAP_PERCENTILE\"] >= 0.75\n",
    "        bottom_mask = meta[\"MKTCAP_PERCENTILE\"] <= 0.25\n",
    "\n",
    "        if np.any(top_mask):\n",
    "            yt_top = y_true[top_mask]\n",
    "            yp_top = y_pred[top_mask]\n",
    "            perm_top = permnos[top_mask] if permnos is not None else None\n",
    "            r2_top = r2_zero(yt_top, yp_top)\n",
    "            rmse_top = np.sqrt(mean_squared_error(yt_top, yp_top))\n",
    "            mae_top = mean_absolute_error(yt_top, yp_top)\n",
    "            mse_top = mean_squared_error(yt_top, yp_top)\n",
    "            dir_top, up_top, down_top = calc_directional_metrics(yt_top, yp_top, perm_top)\n",
    "            metrics.update({\n",
    "                \"Top25_R2_zero\": r2_top,\n",
    "                \"Top25_RMSE\": rmse_top,\n",
    "                \"Top25_MAE\": mae_top,\n",
    "                \"Top25_MSE\": mse_top,\n",
    "                \"Top25_Dir_Acc\": dir_top,\n",
    "                \"Top25_Up_Acc\": up_top,\n",
    "                \"Top25_Down_Acc\": down_top\n",
    "            })\n",
    "\n",
    "        if np.any(bottom_mask):\n",
    "            yt_bot = y_true[bottom_mask]\n",
    "            yp_bot = y_pred[bottom_mask]\n",
    "            perm_bot = permnos[bottom_mask] if permnos is not None else None\n",
    "            r2_bot = r2_zero(yt_bot, yp_bot)\n",
    "            rmse_bot = np.sqrt(mean_squared_error(yt_bot, yp_bot))\n",
    "            mae_bot = mean_absolute_error(yt_bot, yp_bot)\n",
    "            mse_bot = mean_squared_error(yt_bot, yp_bot)\n",
    "            dir_bot, up_bot, down_bot = calc_directional_metrics(yt_bot, yp_bot, perm_bot)\n",
    "            metrics.update({\n",
    "                \"Bottom25_R2_zero\": r2_bot,\n",
    "                \"Bottom25_RMSE\": rmse_bot,\n",
    "                \"Bottom25_MAE\": mae_bot,\n",
    "                \"Bottom25_MSE\": mse_bot,\n",
    "                \"Bottom25_Dir_Acc\": dir_bot,\n",
    "                \"Bottom25_Up_Acc\": up_bot,\n",
    "                \"Bottom25_Down_Acc\": down_bot\n",
    "            })\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def f_statistic(y_true, y_pred, k):\n",
    "    \"\"\"Return F statistic and corresponding p-value.\"\"\"\n",
    "    n   = len(y_true)\n",
    "    rss = np.sum((y_true - y_pred) ** 2)\n",
    "    tss = np.sum(y_true ** 2)\n",
    "    r2  = 1 - rss / tss\n",
    "    if (r2 <= 0) or (n <= k):\n",
    "        return 0.0, 1.0\n",
    "    F = (r2 / k) / ((1 - r2) / (n - k))\n",
    "    p = f_dist.sf(F, k, n - k)\n",
    "    return F, p\n",
    "\n",
    "def overall_interval_metrics_method1(y_all, yhat_all, k, permnos_all=None, meta_all=None):\n",
    "    \"\"\"\n",
    "    Method 1: Compute metrics for the entire interval at once (all samples from 2016-2024 concatenated).\n",
    "    Returns a dict that can be passed to save_metrics().\n",
    "    \"\"\"\n",
    "    base = regression_metrics(\n",
    "        y_true=y_all, \n",
    "        y_pred=yhat_all, \n",
    "        k=k, \n",
    "        meta=meta_all, \n",
    "        permnos=permnos_all\n",
    "    )\n",
    "    F, p = f_statistic(y_all, yhat_all, k)\n",
    "    base[\"F_stat\"]     = F\n",
    "    base[\"F_pvalue\"]   = p\n",
    "    base[\"N_obs\"] = len(y_all)\n",
    "    \n",
    "    delta_cash, sr_star_cash = delta_sharpe(base[\"R²_zero\"], sr_base=0)\n",
    "    base[\"ΔSharpe_cash\"]      = delta_cash\n",
    "    base[\"Sharpe*_cash\"]      = sr_star_cash\n",
    "\n",
    "    delta_mkt , sr_star_mkt  = delta_sharpe(base[\"R²_zero\"], sr_base=SR_MKT_EX)\n",
    "    base[\"ΔSharpe_mkt\"]       = delta_mkt\n",
    "    base[\"Sharpe*_mkt\"]       = sr_star_mkt\n",
    "    \n",
    "    return base\n",
    "\n",
    "def sortino_ratio(rets, freq=252):\n",
    "    \"\"\"Compute Sortino Ratio.\"\"\"\n",
    "    downside = rets[rets < 0]\n",
    "    if len(downside) == 0:\n",
    "        return np.inf\n",
    "    mu = rets.mean() * freq\n",
    "    sigma = np.sqrt((downside ** 2).mean()) * np.sqrt(freq)\n",
    "    return mu / sigma\n",
    "\n",
    "def cvar(rets, alpha=0.95):\n",
    "    \"\"\"Compute CVaR.\"\"\"\n",
    "    q = np.quantile(rets, 1 - alpha)\n",
    "    return rets[rets <= q].mean()\n",
    "\n",
    "def save_predictions(model_name, window_size, y_true, y_pred, permnos, path=\"predictions/\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"PERMNO\": permnos,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred\n",
    "    })\n",
    "\n",
    "    filename = f\"{model_name}_w{window_size}.csv\"\n",
    "    df.to_csv(os.path.join(path, filename), index=False)\n",
    "    print(f\"[Save] {filename}\")\n",
    "\n",
    "def save_metrics(metrics_dict, name, window, path=\"results.csv\"):\n",
    "    \"\"\"Save evaluation metrics.\"\"\"\n",
    "    row = pd.DataFrame([metrics_dict])\n",
    "    row.insert(0, \"Model\", name)\n",
    "    row.insert(1, \"Window\", window)\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[~((df[\"Model\"] == name) & (df[\"Window\"] == window))]\n",
    "        df = pd.concat([df, row], ignore_index=True)\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"[Update] Metrics updated for {name} w={window}\")\n",
    "    else:\n",
    "        row.to_csv(path, index=False)\n",
    "        print(f\"[Create] New metrics file created with {name} w={window}\")\n",
    "\n",
    "def get_quarter_periods(start_year=2015, end_year=2024):\n",
    "    \"\"\"Generate quarterly periods.\"\"\"\n",
    "    quarters = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for q in range(1, 5):\n",
    "            quarters.append((year, q))\n",
    "    return quarters\n",
    "\n",
    "def load_y_scaler(window, scaler_dir=\"/Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/\"):\n",
    "    \"\"\"\n",
    "    Load the y-scaler for the given window.\n",
    "    \n",
    "    Args:\n",
    "        window: window size (5, 21, 252, 512)\n",
    "        scaler_dir: directory where scaler files are stored\n",
    "    \n",
    "    Returns:\n",
    "        The loaded scaler object, or None if loading fails.\n",
    "    \"\"\"\n",
    "    scaler_path = os.path.join(scaler_dir, f\"scaler_y_window_{window}.pkl\")\n",
    "    try:\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        print(f\"[Load] Y scaler loaded for window {window}: {scaler_path}\")\n",
    "        return scaler\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed to load Y scaler for window {window}: {e}\")\n",
    "        return None\n",
    "\n",
    "def inverse_transform_predictions(predictions, scaler):\n",
    "    \"\"\"\n",
    "    Inverse transform predictions using the provided scaler.\n",
    "    \n",
    "    Args:\n",
    "        predictions: standardized predictions (numpy array)\n",
    "        scaler: scaler object for inverse transformation\n",
    "    \n",
    "    Returns:\n",
    "        Inverse transformed predictions\n",
    "    \"\"\"\n",
    "    if scaler is None:\n",
    "        print(\"[Warning] No scaler provided, returning original predictions\")\n",
    "        return predictions\n",
    "    \n",
    "    try:\n",
    "        if predictions.ndim == 1:\n",
    "            predictions_2d = predictions.reshape(-1, 1)\n",
    "        else:\n",
    "            predictions_2d = predictions\n",
    "        \n",
    "        inversed = scaler.inverse_transform(predictions_2d).flatten()\n",
    "        print(f\"[Info] Inverse transformed {len(predictions)} predictions\")\n",
    "        return inversed\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed to inverse transform predictions: {e}\")\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-BEATS model architecture\n",
    "class NBeatsBlock(nn.Module):\n",
    "    def __init__(self, input_size, theta_size, basis_size, layers, layer_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_size, layer_size)] + \n",
    "                                   [nn.Linear(layer_size, layer_size) for _ in range(layers-1)])\n",
    "        self.basis_parameters = nn.Linear(layer_size, theta_size)\n",
    "        self.input_size = input_size\n",
    "        self.theta_size = theta_size\n",
    "        self.basis_size = basis_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        theta = self.basis_parameters(x)\n",
    "        backcast = theta[:, :self.input_size]\n",
    "        forecast = theta[:, self.input_size:self.input_size+1]  # predict 1 step\n",
    "        return backcast, forecast\n",
    "\n",
    "class NBeatsNet(nn.Module):\n",
    "    def __init__(self, input_size, stacks=2, blocks_per_stack=2, layers=4, layer_size=128):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.stacks = nn.ModuleList()\n",
    "        for _ in range(stacks):\n",
    "            stack = nn.ModuleList()\n",
    "            for _ in range(blocks_per_stack):\n",
    "                stack.append(NBeatsBlock(input_size, input_size + 1, input_size, layers, layer_size))\n",
    "            self.stacks.append(stack)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        forecast = 0\n",
    "        for stack in self.stacks:\n",
    "            for block in stack:\n",
    "                backcast, block_forecast = block(residual)\n",
    "                residual = residual - backcast\n",
    "                forecast = forecast + block_forecast\n",
    "        return forecast\n",
    "\n",
    "def train_step(model, criterion, optimizer, X_batch, y_batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_batch).squeeze()\n",
    "    loss = criterion(predictions, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    train_step = torch.compile(train_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Hyperparameter Tuning ==========\n",
    "\n",
    "TUNED_MODELS = [\"NBEATS\"]  # List of models for tuning\n",
    "\n",
    "def tune_nbeats_with_optuna(X, y, window, n_trials=10):\n",
    "    \"\"\"N-BEATS hyperparameter tuning using TimeSeriesSplit\"\"\"\n",
    "    if len(y) < 100:\n",
    "        return {\n",
    "            'stacks': 2, \n",
    "            'blocks_per_stack': 2, \n",
    "            'layers': 2, \n",
    "            'layer_size': 128, \n",
    "            'learning_rate': 0.001, \n",
    "            'batch_size': 32,\n",
    "            'max_epochs': 25,\n",
    "            'warm_start_epochs': 15\n",
    "        }\n",
    "    \n",
    "    print(f\"    [Hyperparameter Tuning] Running Optuna optimization for window={window}\")\n",
    "    print(f\"    [Device Setting] Using CPU for hyperparameter tuning\")\n",
    "    \n",
    "    tuning_device = torch.device(\"cpu\")\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    features_per_timestep = X.shape[1] // window\n",
    "    \n",
    "    def objective(trial):\n",
    "        try:\n",
    "            stacks = trial.suggest_int(\"stacks\", 1, 3)\n",
    "            blocks_per_stack = trial.suggest_int(\"blocks_per_stack\", 1, 3)\n",
    "            layers = 2\n",
    "            layer_size = 128\n",
    "            lr = trial.suggest_float(\"lr\", 1e-5, 5e-4, log=True)\n",
    "            batch_size = trial.suggest_categorical(\"batch_size\", [32, 64])\n",
    "            \n",
    "            cv_scores = []\n",
    "            for train_idx, val_idx in tscv.split(X):\n",
    "                X_tr, X_val = X[train_idx], X[val_idx]\n",
    "                y_tr, y_val = y[train_idx], y[val_idx]\n",
    "                \n",
    "                if len(X_tr) < 50 or len(X_val) < 10:\n",
    "                    continue\n",
    "                \n",
    "                lookback = min(20, len(X_tr)//4)\n",
    "                X_seq_tr, y_seq_tr = prepare_sequences(X_tr, y_tr, lookback)\n",
    "                X_seq_val, y_seq_val = prepare_sequences(X_val, y_val, lookback)\n",
    "                \n",
    "                if len(X_seq_tr) == 0 or len(X_seq_val) == 0:\n",
    "                    continue\n",
    "                \n",
    "                X_tensor_tr = torch.FloatTensor(X_seq_tr).to(tuning_device)\n",
    "                y_tensor_tr = torch.FloatTensor(y_seq_tr).to(tuning_device)\n",
    "                X_tensor_val = torch.FloatTensor(X_seq_val).to(tuning_device)\n",
    "                y_tensor_val = torch.FloatTensor(y_seq_val).to(tuning_device)\n",
    "                \n",
    "                input_size = X_seq_tr.shape[-1]\n",
    "                model = NBeatsNet(input_size, stacks, blocks_per_stack, layers, layer_size).to(tuning_device)\n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "                \n",
    "                dataset = TensorDataset(X_tensor_tr, y_tensor_tr)\n",
    "                dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=False, num_workers=0)\n",
    "                \n",
    "                model.train()\n",
    "                for epoch in range(5):\n",
    "                    for X_batch, y_batch in dataloader:\n",
    "                        train_step(model, criterion, optimizer, X_batch, y_batch)\n",
    "                \n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_pred = model(X_tensor_val).squeeze().cpu().numpy()\n",
    "                    mse = mean_squared_error(y_seq_val, val_pred)\n",
    "                    cv_scores.append(mse)\n",
    "                \n",
    "                del model, optimizer, criterion, X_tensor_tr, y_tensor_tr, X_tensor_val, y_tensor_val\n",
    "                if tuning_device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif tuning_device.type == 'mps':\n",
    "                    torch.mps.empty_cache()\n",
    "            \n",
    "            return np.mean(cv_scores) if cv_scores else float('inf')\n",
    "        except Exception as e:\n",
    "            return float('inf')\n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(f\"    [Tuning Completed] Switching back to {device} for model training\")\n",
    "    \n",
    "    if study.best_trial is None:\n",
    "        return {\n",
    "            'stacks': 2, \n",
    "            'blocks_per_stack': 2, \n",
    "            'layers':2, \n",
    "            'layer_size': 128, \n",
    "            'learning_rate': 0.001, \n",
    "            'batch_size': 32,\n",
    "            'max_epochs': 25,\n",
    "            'warm_start_epochs': 15\n",
    "        }\n",
    "    \n",
    "    best_params = study.best_params.copy()\n",
    "    best_params['learning_rate'] = best_params.pop('lr')\n",
    "    best_params['max_epochs'] = 25\n",
    "    best_params['warm_start_epochs'] = 15\n",
    "    best_params['layers'] = 2\n",
    "    best_params['layer_size'] = 128  \n",
    "    \n",
    "    print(f\"    [Optuna] NBEATS best_params={best_params}\")\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nbeats_model(X_train, y_train, X_test, y_test, best_params, max_epochs=50, window_size=None):\n",
    "    \"\"\"Train N-BEATS model and return aligned test data, support inverse y scaling\"\"\"\n",
    "    try:\n",
    "        lookback = min(20, len(X_train)//4)\n",
    "        X_seq_train, y_seq_train = prepare_sequences(X_train, y_train, lookback)\n",
    "        X_seq_test, y_seq_test = prepare_sequences(X_test, y_test, lookback)\n",
    "        \n",
    "        if len(X_seq_train) == 0:\n",
    "            return None, None, None\n",
    "        \n",
    "        X_tensor_train = torch.FloatTensor(X_seq_train).to(device)\n",
    "        y_tensor_train = torch.FloatTensor(y_seq_train).to(device)\n",
    "        X_tensor_test = torch.FloatTensor(X_seq_test).to(device)\n",
    "        \n",
    "        input_size = X_seq_train.shape[-1]\n",
    "        model = NBeatsNet(\n",
    "            input_size=input_size,\n",
    "            stacks=best_params['stacks'],\n",
    "            blocks_per_stack=best_params['blocks_per_stack'],\n",
    "            layers=best_params['layers'],\n",
    "            layer_size=best_params['layer_size']\n",
    "        ).to(device)\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        lr_key = 'learning_rate' if 'learning_rate' in best_params else 'lr'\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=best_params[lr_key], weight_decay=1e-5)\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor_train, y_tensor_train)\n",
    "        pin_memory = device.type == \"cuda\"\n",
    "        dataloader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=best_params['batch_size'], \n",
    "            shuffle=True, \n",
    "            pin_memory=pin_memory,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(max_epochs):\n",
    "            epoch_loss = 0\n",
    "            for X_batch, y_batch in dataloader:\n",
    "                loss = train_step(model, criterion, optimizer, X_batch, y_batch)\n",
    "                epoch_loss += loss\n",
    "            \n",
    "            if epoch > 10 and epoch_loss < 1e-6:\n",
    "                break\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if len(X_seq_test) > 0:\n",
    "                y_pred_tensor = model(X_tensor_test).squeeze()\n",
    "                y_pred = y_pred_tensor.cpu().numpy()\n",
    "                \n",
    "                if window_size is not None:\n",
    "                    y_scaler = load_y_scaler(window_size)\n",
    "                    if y_scaler is not None:\n",
    "                        y_pred = inverse_transform_predictions(y_pred, y_scaler)\n",
    "                \n",
    "                if len(y_pred) < len(y_test):\n",
    "                    y_test_aligned = y_test[-len(y_pred):]\n",
    "                    if window_size is not None:\n",
    "                        y_scaler = load_y_scaler(window_size)\n",
    "                        if y_scaler is not None:\n",
    "                            y_test_aligned = inverse_transform_predictions(y_test_aligned, y_scaler)\n",
    "                    return model, y_pred, y_test_aligned\n",
    "                else:\n",
    "                    y_pred = y_pred[:len(y_test)]\n",
    "                    y_test_copy = y_test.copy()\n",
    "                    if window_size is not None:\n",
    "                        y_scaler = load_y_scaler(window_size)\n",
    "                        if y_scaler is not None:\n",
    "                            y_test_copy = inverse_transform_predictions(y_test_copy, y_scaler)\n",
    "                    return model, y_pred, y_test_copy\n",
    "            else:\n",
    "                return model, np.array([]), np.array([])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Training failed: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def get_model(name: str, best_params=None):\n",
    "    \"\"\"Get default model parameters\"\"\"\n",
    "    if name == \"NBEATS\":\n",
    "        if best_params:\n",
    "            return best_params\n",
    "        else:\n",
    "            return {\n",
    "                'stacks': 2, \n",
    "                'blocks_per_stack': 2, \n",
    "                'layers': 2, \n",
    "                'layer_size': 128, \n",
    "                'learning_rate': 0.001, \n",
    "                'batch_size': 32,\n",
    "                'max_epochs': 25,\n",
    "                'warm_start_epochs': 15\n",
    "            }\n",
    "    \n",
    "    raise ValueError(f\"Unexpected model: {name}\")\n",
    "\n",
    "def save_model(fitted_model, model_name, window_size, path=\"models/\"):\n",
    "    \"\"\"Save trained model as .pth file\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    filename = f\"{model_name}_w{window_size}.pth\"\n",
    "    filepath = os.path.join(path, filename)\n",
    "    \n",
    "    if hasattr(fitted_model, 'state_dict'):\n",
    "        torch.save({\n",
    "            'state_dict': fitted_model.state_dict(),\n",
    "            'model_name': model_name,\n",
    "            'window_size': window_size\n",
    "        }, filepath)\n",
    "    else:\n",
    "        torch.save(fitted_model, filepath)\n",
    "    print(f\"[Save] Model saved to {filename}\")\n",
    "\n",
    "def load_model(model_name, window_size, path=\"models/\"):\n",
    "    \"\"\"Load saved model\"\"\"\n",
    "    filename = f\"{model_name}_w{window_size}.pth\"\n",
    "    filepath = os.path.join(path, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        return torch.load(filepath, map_location=device)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model_name, window_size,\n",
    "                       X_train, y_train, X_test, y_test,\n",
    "                       permnos_train, permnos_test, meta=None, shared_params=None):\n",
    "    \"\"\"Train and evaluate N-BEATS model\"\"\"\n",
    "    \n",
    "    if model_name in TUNED_MODELS:\n",
    "        if shared_params is None:\n",
    "            print(f\"[Hyperparameter Tuning] Running Optuna optimization for window={window_size}\")\n",
    "            best_params = tune_nbeats_with_optuna(X_train, y_train, window_size, n_trials=10)\n",
    "            print(f\"[Optuna] {model_name} best_params={best_params}\")\n",
    "            model_params = get_model(model_name, best_params)\n",
    "        else:\n",
    "            print(f\"[Shared Parameters] Using optimized params from window=5 for window={window_size}\")\n",
    "            model_params = get_model(model_name, shared_params)\n",
    "    else:\n",
    "        model_params = get_model(model_name)\n",
    "\n",
    "    fitted_model, y_pred, y_test_aligned = train_nbeats_model(X_train, y_train, X_test, y_test, model_params, window_size=window_size)\n",
    "    \n",
    "    if fitted_model is None or y_pred is None or y_test_aligned is None:\n",
    "        print(f\"[Skip Model] {model_name} failed to fit. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    if len(y_pred) == 0:\n",
    "        print(f\"[Skip Model] {model_name} no valid predictions. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    if len(y_test_aligned) < len(y_test):\n",
    "        offset = len(y_test) - len(y_test_aligned)\n",
    "        meta_aligned = meta.iloc[offset:] if meta is not None else None\n",
    "        permnos_test_aligned = permnos_test[offset:] if permnos_test is not None else None\n",
    "    else:\n",
    "        meta_aligned = meta\n",
    "        permnos_test_aligned = permnos_test\n",
    "\n",
    "    k = X_test.shape[1]\n",
    "    metrics = regression_metrics(y_test_aligned, y_pred, k, meta=meta_aligned, permnos=permnos_test_aligned)\n",
    "\n",
    "    save_model(fitted_model, model_name, window_size)\n",
    "    save_metrics(metrics, model_name, window_size)\n",
    "    save_predictions(model_name, window_size, y_test_aligned, y_pred, permnos_test_aligned)\n",
    "\n",
    "    print(f\"Completed {model_name} w={window_size}: MSE={metrics['MSE']:.6f}, Dir_Acc={metrics['Directional Accuracy']:.4f}\")\n",
    "    \n",
    "    if device.type == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "    elif device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if shared_params is None and model_name in TUNED_MODELS:\n",
    "        return metrics, best_params\n",
    "    else:\n",
    "        return metrics, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBeatsWrapper:\n",
    "    \"\"\"N-BEATS model wrapper, supports extended training for seasonal mode\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, seq_len, stacks=2, blocks_per_stack=2, nlayers=4, \n",
    "                 hidden=128, learning_rate=0.001, batch_size=32, max_epochs=50,\n",
    "                 warm_start_epochs=10, training_device=None, window_size=None):\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = seq_len\n",
    "        self.stacks = stacks\n",
    "        self.blocks_per_stack = blocks_per_stack\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden = hidden\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.max_epochs = max_epochs\n",
    "        self.warm_start_epochs = warm_start_epochs\n",
    "        self.training_device = training_device or device\n",
    "        self.window_size = window_size  # Store window size for inverse scaling\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def _create_model(self):\n",
    "        \"\"\"Create N-BEATS model\"\"\"\n",
    "        self.model = NBeatsNet(\n",
    "            input_size=self.input_size,\n",
    "            stacks=self.stacks,\n",
    "            blocks_per_stack=self.blocks_per_stack,\n",
    "            layers=self.nlayers,\n",
    "            layer_size=self.hidden\n",
    "        ).to(self.training_device)\n",
    "        \n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters(), \n",
    "            lr=self.learning_rate, \n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y, validation_split=0.1):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        if self.model is None:\n",
    "            self._create_model()\n",
    "            \n",
    "        lookback = min(20, len(X)//4)\n",
    "        X_seq, y_seq = prepare_sequences(X, y, lookback)\n",
    "        \n",
    "        if len(X_seq) == 0:\n",
    "            return self\n",
    "            \n",
    "        split_idx = int(len(X_seq) * (1 - validation_split))\n",
    "        X_train_seq, X_val_seq = X_seq[:split_idx], X_seq[split_idx:]\n",
    "        y_train_seq, y_val_seq = y_seq[:split_idx], y_seq[split_idx:]\n",
    "        \n",
    "        X_tensor = torch.FloatTensor(X_train_seq).to(self.training_device)\n",
    "        y_tensor = torch.FloatTensor(y_train_seq).to(self.training_device)\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        pin_memory = self.training_device.type == \"cuda\"\n",
    "        dataloader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True, \n",
    "            pin_memory=pin_memory,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        self.model.train()\n",
    "        best_loss = float('inf')\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.max_epochs):\n",
    "            epoch_loss = 0\n",
    "            for X_batch, y_batch in dataloader:\n",
    "                loss = train_step(self.model, self.criterion, self.optimizer, X_batch, y_batch)\n",
    "                epoch_loss += loss\n",
    "            \n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            \n",
    "            if len(X_val_seq) > 0:\n",
    "                val_loss = self._validate(X_val_seq, y_val_seq)\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                if patience_counter >= patience:\n",
    "                    break\n",
    "            \n",
    "            if epoch > 10 and avg_loss < 1e-6:\n",
    "                break\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def partial_fit(self, X, y, validation_split=0.1, extra_epochs=None):\n",
    "        \"\"\"Incremental training (warm-start)\"\"\"\n",
    "        if self.model is None:\n",
    "            return self.fit(X, y, validation_split)\n",
    "            \n",
    "        epochs = extra_epochs or self.warm_start_epochs\n",
    "        \n",
    "        lookback = min(20, len(X)//4)\n",
    "        X_seq, y_seq = prepare_sequences(X, y, lookback)\n",
    "        \n",
    "        if len(X_seq) == 0:\n",
    "            return self\n",
    "            \n",
    "        split_idx = int(len(X_seq) * (1 - validation_split))\n",
    "        X_train_seq = X_seq[:split_idx]\n",
    "        y_train_seq = y_seq[:split_idx]\n",
    "        \n",
    "        X_tensor = torch.FloatTensor(X_train_seq).to(self.training_device)\n",
    "        y_tensor = torch.FloatTensor(y_train_seq).to(self.training_device)\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        pin_memory = self.training_device.type == \"cuda\"\n",
    "        dataloader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True, \n",
    "            pin_memory=pin_memory,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for X_batch, y_batch in dataloader:\n",
    "                train_step(self.model, self.criterion, self.optimizer, X_batch, y_batch)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def _validate(self, X_val, y_val):\n",
    "        \"\"\"Validate the model\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_tensor = torch.FloatTensor(X_val).to(self.training_device)\n",
    "            y_val_tensor = torch.FloatTensor(y_val).to(self.training_device)\n",
    "            pred = self.model(X_val_tensor).squeeze()\n",
    "            loss = self.criterion(pred, y_val_tensor)\n",
    "            return loss.item()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        if self.model is None or not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted yet\")\n",
    "            \n",
    "        lookback = min(20, len(X)//4)\n",
    "        X_seq, _ = prepare_sequences(X, None, lookback)\n",
    "        \n",
    "        if len(X_seq) == 0:\n",
    "            return np.array([])\n",
    "            \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.FloatTensor(X_seq).to(self.training_device)\n",
    "            pred = self.model(X_tensor).squeeze()\n",
    "            predictions = pred.cpu().numpy()\n",
    "            \n",
    "            # Inverse scaling for y\n",
    "            if self.window_size is not None:\n",
    "                y_scaler = load_y_scaler(self.window_size)\n",
    "                if y_scaler is not None:\n",
    "                    predictions = inverse_transform_predictions(predictions, y_scaler)\n",
    "            \n",
    "            return predictions\n",
    "\n",
    "def save_nbeats_model(model, window, year, quarter, path=\"models/\"):\n",
    "    \"\"\"Save N-BEATS quarterly model as .pth file\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    filename = f\"NBEATS_w{window}_{year}Q{quarter}.pth\"\n",
    "    filepath = os.path.join(path, filename)\n",
    "    \n",
    "    save_dict = {\n",
    "        'state_dict': model.model.state_dict() if model.model is not None else None,\n",
    "        'hyper_params': {\n",
    "            'input_size': model.input_size,\n",
    "            'seq_len': model.seq_len,\n",
    "            'stacks': model.stacks,\n",
    "            'blocks_per_stack': model.blocks_per_stack,\n",
    "            'nlayers': model.nlayers,\n",
    "            'hidden': model.hidden,\n",
    "            'learning_rate': model.learning_rate,\n",
    "            'batch_size': model.batch_size,\n",
    "            'max_epochs': model.max_epochs,\n",
    "            'warm_start_epochs': model.warm_start_epochs,\n",
    "            'window_size': model.window_size  # Store window_size\n",
    "        },\n",
    "        'is_fitted': model.is_fitted\n",
    "    }\n",
    "    \n",
    "    torch.save(save_dict, filepath)\n",
    "    print(f\"[Save] N-BEATS model saved: {filename}\")\n",
    "\n",
    "def load_nbeats_model(window, year, quarter, training_device=None, fallback_hp=None, path=\"models/\"):\n",
    "    \"\"\"Load N-BEATS quarterly model\"\"\"\n",
    "    filename = f\"NBEATS_w{window}_{year}Q{quarter}.pth\"\n",
    "    filepath = os.path.join(path, filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            ckpt = torch.load(filepath, map_location=training_device or device)\n",
    "            \n",
    "            hp = ckpt['hyper_params']\n",
    "            model = NBeatsWrapper(\n",
    "                input_size=hp['input_size'],\n",
    "                seq_len=hp['seq_len'],\n",
    "                stacks=hp['stacks'],\n",
    "                blocks_per_stack=hp['blocks_per_stack'],\n",
    "                nlayers=hp['nlayers'],\n",
    "                hidden=hp['hidden'],\n",
    "                learning_rate=hp['learning_rate'],\n",
    "                batch_size=hp['batch_size'],\n",
    "                max_epochs=hp['max_epochs'],\n",
    "                warm_start_epochs=hp['warm_start_epochs'],\n",
    "                training_device=training_device or device,\n",
    "                window_size=hp.get('window_size', window)\n",
    "            )\n",
    "            \n",
    "            if ckpt['state_dict'] is not None:\n",
    "                model._create_model()\n",
    "                model.model.load_state_dict(ckpt['state_dict'])\n",
    "                model.is_fitted = ckpt.get('is_fitted', True)\n",
    "            \n",
    "            print(f\"[Load] N-BEATS model loaded: {filename}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Failed to load {filename}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_train_device():\n",
    "    \"\"\"Prefer CUDA, then MPS, then CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def train_nbeats_models_expanding_quarterly(\n",
    "    start_year: int = 2015,\n",
    "    end_year: int = 2024,\n",
    "    window_sizes: list[int] | None = None,\n",
    "    npz_path: str = \"/Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/all_window_datasets.npz\",\n",
    "    n_trials_optuna: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Mimic LSTM/Autoformer logic:\n",
    "    - Scan local files before training, skip if model exists\n",
    "    - Initial tuning window: if start_year Q4 model exists, load hyperparameters, else tune with Optuna\n",
    "    - Expand training set by quarter, optionally re-tune, warm-start\n",
    "    \"\"\"\n",
    "    if window_sizes is None:\n",
    "        window_sizes = [5, 21, 252, 512]\n",
    "\n",
    "    data = load_datasets(npz_path)\n",
    "    print(f\"=== N-BEATS quarterly expanding training {start_year}-{end_year} ===\")\n",
    "\n",
    "    best_params_cache: dict[str, dict] = {}\n",
    "    TUNED_WINDOW = 5\n",
    "    TUNE_QUARTERS = {(2020, 4)}\n",
    "\n",
    "    for window in window_sizes:\n",
    "        train_device = get_train_device()\n",
    "        print(f\"\\n>> Window = {window}\")\n",
    "        X_train_init = data[f\"X_train_{window}\"].copy()\n",
    "        y_train_init = data[f\"y_train_{window}\"].copy()\n",
    "        X_test_full  = data[f\"X_test_{window}\"]\n",
    "        y_test_full  = data[f\"y_test_{window}\"]\n",
    "        meta_test    = pd.DataFrame.from_dict(data[f\"meta_test_{window}\"].item())\n",
    "        meta_test[\"ret_date\"] = pd.to_datetime(meta_test[\"ret_date\"])\n",
    "\n",
    "        cache_key = f\"NBEATS_w{window}\"\n",
    "        if window == TUNED_WINDOW:\n",
    "            tuned_model = load_nbeats_model(\n",
    "                window, start_year, 4,\n",
    "                training_device=train_device,\n",
    "                fallback_hp=None\n",
    "            )\n",
    "            if tuned_model is not None:\n",
    "                hp = {\n",
    "                    \"stacks\": tuned_model.stacks,\n",
    "                    \"blocks_per_stack\": tuned_model.blocks_per_stack,\n",
    "                    \"layers\": tuned_model.nlayers,\n",
    "                    \"layer_size\": tuned_model.hidden,\n",
    "                    \"learning_rate\": tuned_model.learning_rate,\n",
    "                    \"batch_size\": tuned_model.batch_size,\n",
    "                    \"max_epochs\": tuned_model.max_epochs,\n",
    "                    \"warm_start_epochs\": tuned_model.warm_start_epochs,\n",
    "                }\n",
    "                print(f\"[Skip-Optuna] hyper-params loaded from existing {start_year}Q4 model\")\n",
    "            else:\n",
    "                print(\"    Optuna tuning on initial window…\")\n",
    "                hp = tune_nbeats_with_optuna(\n",
    "                    X_train_init, y_train_init,\n",
    "                    window, n_trials=n_trials_optuna\n",
    "                )\n",
    "        else:\n",
    "            hp = None\n",
    "        best_params_cache[cache_key] = hp\n",
    "\n",
    "        nbeats_model = None\n",
    "        for year, quarter in get_quarter_periods(start_year, end_year):\n",
    "            if (year == start_year and quarter < 4) or (year == end_year and quarter > 3):\n",
    "                continue\n",
    "\n",
    "            existing = load_nbeats_model(\n",
    "                window, year, quarter,\n",
    "                training_device=train_device,\n",
    "                fallback_hp=best_params_cache.get(cache_key)\n",
    "            )\n",
    "            if existing is not None:\n",
    "                print(f\"[Skip] Model already trained for window={window}, {year}Q{quarter}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[Window {window}] {year}Q{quarter}\")\n",
    "\n",
    "            if not (year == start_year and quarter == 4):\n",
    "                py, pq = (year, quarter-1) if quarter > 1 else (year-1, 4)\n",
    "                mask_prev = (\n",
    "                    (meta_test[\"ret_date\"].dt.year == py) &\n",
    "                    (meta_test[\"ret_date\"].dt.quarter == pq)\n",
    "                )\n",
    "                if mask_prev.any():\n",
    "                    X_prev = X_test_full[mask_prev]\n",
    "                    y_prev = y_test_full[mask_prev]\n",
    "                    X_train_init = np.vstack([X_train_init, X_prev])\n",
    "                    y_train_init = np.hstack([y_train_init, y_prev])\n",
    "                    print(f\"    +{mask_prev.sum()} obs from {py}Q{pq} -> train_size={len(y_train_init)}\")\n",
    "\n",
    "            hp = best_params_cache.get(cache_key)\n",
    "            if hp is None:\n",
    "                hp = best_params_cache[f\"NBEATS_w{TUNED_WINDOW}\"]\n",
    "            if (year, quarter) in TUNE_QUARTERS and window == TUNED_WINDOW:\n",
    "                print(\"    Re-tuning via Optuna…\")\n",
    "                hp = tune_nbeats_with_optuna(\n",
    "                    X_train_init, y_train_init,\n",
    "                    window, n_trials=n_trials_optuna\n",
    "                )\n",
    "                best_params_cache[cache_key] = hp\n",
    "\n",
    "            model_prev = None\n",
    "            if not (year == start_year and quarter == 4):\n",
    "                py, pq = (year, quarter-1) if quarter > 1 else (year-1, 4)\n",
    "                model_prev = load_nbeats_model(\n",
    "                    window, py, pq,\n",
    "                    training_device=train_device,\n",
    "                    fallback_hp=hp\n",
    "                )\n",
    "\n",
    "            if model_prev is not None:\n",
    "                print(\"    Warm-start …\")\n",
    "                model_prev.partial_fit(\n",
    "                    X_train_init, y_train_init,\n",
    "                    validation_split=0.1,\n",
    "                    extra_epochs=hp.get(\"warm_start_epochs\", 10)\n",
    "                )\n",
    "                nbeats_model = model_prev\n",
    "            else:\n",
    "                print(\"    Cold-start …\")\n",
    "                nbeats_model = NBeatsWrapper(\n",
    "                    input_size         = X_train_init.shape[1],\n",
    "                    seq_len            = window,\n",
    "                    stacks             = hp[\"stacks\"],\n",
    "                    blocks_per_stack   = hp[\"blocks_per_stack\"],\n",
    "                    nlayers            = hp[\"layers\"],\n",
    "                    hidden             = hp[\"layer_size\"],\n",
    "                    learning_rate      = hp[\"learning_rate\"],\n",
    "                    batch_size         = hp[\"batch_size\"],\n",
    "                    max_epochs         = hp[\"max_epochs\"],\n",
    "                    warm_start_epochs  = hp.get(\"warm_start_epochs\", 10),\n",
    "                    training_device    = train_device,\n",
    "                    window_size        = window\n",
    "                )\n",
    "                nbeats_model.fit(X_train_init, y_train_init, validation_split=0.1)\n",
    "\n",
    "            save_nbeats_model(nbeats_model, window, year, quarter)\n",
    "            gc.collect()\n",
    "            if torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "            elif torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"=== All N-BEATS quarterly models trained ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio core class\n",
    "# Transaction cost settings\n",
    "TC_GRID = [0.0005, 0.001, 0.002, 0.003, 0.004]  # 5, 10, 20, 30, 40 bps\n",
    "TC_TAG  = {\n",
    "    0.0005: \"tc5\",\n",
    "    0.001:  \"tc10\", \n",
    "    0.002:  \"tc20\",\n",
    "    0.003:  \"tc30\",\n",
    "    0.004:  \"tc40\"\n",
    "}\n",
    "\n",
    "class PortfolioBacktester:\n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        \n",
    "    def calc_turnover(self, w_t, r_t, w_tp1):\n",
    "        \"\"\"Calculate turnover using the standard formula\"\"\"\n",
    "        if w_t is None:\n",
    "            return np.sum(np.abs(w_tp1))\n",
    "        \n",
    "        gross_ret = np.sum(w_t * r_t)\n",
    "        if abs(1 + gross_ret) < 1e-8:\n",
    "            return np.sum(np.abs(w_tp1))\n",
    "        \n",
    "        passive_weight = w_t * (1 + r_t) / (1 + gross_ret)\n",
    "        turnover = np.sum(np.abs(w_tp1 - passive_weight))\n",
    "        return turnover\n",
    "    \n",
    "    def create_portfolios_with_permno_tracking(self, signals, market_caps, permnos, top_pct=0.1, bottom_pct=0.1, weight_scheme=\"VW\"):\n",
    "        \"\"\"\n",
    "        Create portfolio weights based on signals, strictly tracking permno alignment.\n",
    "        weight_scheme: 'VW' for value-weighted, 'EW' for equal-weighted\n",
    "        \"\"\"\n",
    "        n_stocks = len(signals)\n",
    "        top_n    = max(1, int(round(n_stocks * top_pct)))\n",
    "        bottom_n = max(1, int(round(n_stocks * bottom_pct)))\n",
    "        \n",
    "        sorted_idx = np.argsort(signals)[::-1]\n",
    "        \n",
    "        top_idx = sorted_idx[:top_n]\n",
    "        bottom_idx = sorted_idx[-bottom_n:]\n",
    "        \n",
    "        portfolio_data = {}\n",
    "        \n",
    "        long_weights = np.zeros(n_stocks)\n",
    "        if len(top_idx) > 0:\n",
    "            if weight_scheme == \"VW\":\n",
    "                top_market_caps = market_caps[top_idx]\n",
    "                if np.sum(top_market_caps) > 0:\n",
    "                    long_weights[top_idx] = top_market_caps / np.sum(top_market_caps)\n",
    "            else:\n",
    "                long_weights[top_idx] = 1.0 / len(top_idx)\n",
    "        \n",
    "        portfolio_data['long_only'] = {\n",
    "            'weights': long_weights,\n",
    "            'permnos': permnos.copy(),\n",
    "            'selected_permnos': permnos[top_idx] if len(top_idx) > 0 else np.array([])\n",
    "        }\n",
    "        \n",
    "        short_weights = np.zeros(n_stocks)\n",
    "        if len(bottom_idx) > 0:\n",
    "            if weight_scheme == \"VW\":\n",
    "                bottom_market_caps = market_caps[bottom_idx]\n",
    "                if np.sum(bottom_market_caps) > 0:\n",
    "                    short_weights[bottom_idx] = -bottom_market_caps / np.sum(bottom_market_caps)\n",
    "            else:\n",
    "                short_weights[bottom_idx] = -1.0 / len(bottom_idx)\n",
    "        \n",
    "        portfolio_data['short_only'] = {\n",
    "            'weights': short_weights,\n",
    "            'permnos': permnos.copy(),\n",
    "            'selected_permnos': permnos[bottom_idx] if len(bottom_idx) > 0 else np.array([])\n",
    "        }\n",
    "        \n",
    "        ls_raw = long_weights + short_weights\n",
    "\n",
    "        gross_target = 2.0\n",
    "        current_gross = np.sum(np.abs(long_weights)) + np.sum(np.abs(short_weights))\n",
    "        scale = gross_target / current_gross if current_gross > 1e-8 else 0.0\n",
    "        ls_weights = scale * ls_raw\n",
    "\n",
    "        ls_selected_permnos = np.concatenate([\n",
    "            permnos[top_idx] if len(top_idx) > 0 else np.array([]),\n",
    "            permnos[bottom_idx] if len(bottom_idx) > 0 else np.array([])\n",
    "        ])\n",
    "\n",
    "        portfolio_data['long_short'] = {\n",
    "            'weights': ls_weights,\n",
    "            'permnos': permnos.copy(),\n",
    "            'selected_permnos': ls_selected_permnos\n",
    "        }\n",
    "\n",
    "        return portfolio_data\n",
    "    \n",
    "    def calculate_aligned_portfolio_return(self, portfolio_weights, portfolio_permnos, actual_returns, actual_permnos):\n",
    "        \"\"\"Calculate portfolio return strictly aligned by permno\"\"\"\n",
    "        aligned_returns = np.zeros(len(portfolio_permnos))\n",
    "        \n",
    "        return_dict = dict(zip(actual_permnos, actual_returns))\n",
    "        \n",
    "        for i, permno in enumerate(portfolio_permnos):\n",
    "            if permno in return_dict:\n",
    "                aligned_returns[i] = return_dict[permno]\n",
    "        \n",
    "        portfolio_return = np.sum(portfolio_weights * aligned_returns)\n",
    "        return portfolio_return, aligned_returns\n",
    "\n",
    "    def calculate_metrics(self, returns, turnover_series=None):\n",
    "        \"\"\"Calculate portfolio metrics - only returns summary metrics, not full series\"\"\"\n",
    "        returns = np.array(returns)\n",
    "        \n",
    "        annual_return = np.mean(returns) * 252\n",
    "        annual_vol = np.std(returns, ddof=1) * np.sqrt(252)\n",
    "        sharpe = annual_return / annual_vol if annual_vol > 0 else 0\n",
    "        \n",
    "        log_cum = np.cumsum(np.log1p(returns))\n",
    "        peak_log = np.maximum.accumulate(log_cum)\n",
    "        dd_log = peak_log - log_cum\n",
    "        max_drawdown = 1 - np.exp(-dd_log.max()) \n",
    "        max_1d_loss = np.min(returns) \n",
    "        \n",
    "        avg_turnover = np.mean(turnover_series) if turnover_series is not None else 0\n",
    "        \n",
    "        sortino = sortino_ratio(returns)\n",
    "        cvar95  = cvar(returns, alpha=0.95)\n",
    "\n",
    "        result = {\n",
    "            'annual_return': annual_return,\n",
    "            'annual_vol': annual_vol,\n",
    "            'sharpe': sharpe,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'max_1d_loss': max_1d_loss,\n",
    "            'avg_turnover': avg_turnover,\n",
    "            'sortino': sortino,\n",
    "            'cvar95': cvar95\n",
    "        }\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_portfolio_simulation_daily_rebalance(start_year=2016, end_year=2024, window_sizes=None, model_names=None,\n",
    "                                           npz_path=\"/Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/all_window_datasets_scaled.npz\"):\n",
    "    \"\"\"\n",
    "Portfolio simulation (daily prediction, next-day rebalancing):\n",
    "    1. Load quarterly models (trained with quarterly expanding window)\n",
    "    2. Daily prediction to daily signals\n",
    "    3. Daily portfolio construction (T+1 rebalancing, strict permno alignment)\n",
    "    4. Separate summary metrics and time series data\n",
    "    \"\"\"\n",
    "    if window_sizes is None:\n",
    "        window_sizes = [5, 21, 252, 512]\n",
    "    if model_names is None:\n",
    "        model_names = [\"NBEATS\"]\n",
    "    \n",
    "    print(\"Starting daily rebalance portfolio backtesting simulation\")\n",
    "    \n",
    "    backtester = PortfolioBacktester()\n",
    "    datasets = load_datasets(npz_path)\n",
    "    \n",
    "    summary_results = []\n",
    "    daily_series_data = []\n",
    "    pred_rows = []\n",
    "    \n",
    "    WEIGHT_SCHEMES = [\"VW\", \"EW\"]\n",
    "    \n",
    "    y_scalers = {}\n",
    "    for window in window_sizes:\n",
    "        y_scalers[window] = load_y_scaler(window)\n",
    "    \n",
    "    for window in window_sizes:\n",
    "        print(f\"Processing window size: {window}\")\n",
    "        \n",
    "        X_test = datasets[f\"X_test_{window}\"]\n",
    "        y_test = datasets[f\"y_test_{window}\"]\n",
    "        input_size = X_test.shape[1]\n",
    "        meta_test_dict = datasets[f\"meta_test_{window}\"].item()\n",
    "        meta_test = pd.DataFrame.from_dict(meta_test_dict)\n",
    "        \n",
    "        permnos_test = meta_test[\"PERMNO\"].values\n",
    "        meta_test[\"signal_date\"]  = pd.to_datetime(meta_test[\"date\"])\n",
    "        meta_test[\"ret_date\"]     = pd.to_datetime(meta_test[\"ret_date\"])\n",
    "        market_caps = meta_test.get(\"MKTCAP\", np.ones(len(permnos_test)))\n",
    "        \n",
    "        meta_test['date'] = pd.to_datetime(meta_test[\"date\"])\n",
    "        dates_test = meta_test['signal_date']\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            for scheme in WEIGHT_SCHEMES:\n",
    "                all_y_true   = []\n",
    "                all_y_pred   = []\n",
    "                all_permnos  = []\n",
    "                all_meta     = []\n",
    "                print(f\"  Model: {model_name}, Scheme: {scheme}\")\n",
    "                \n",
    "                portfolio_daily_data = {\n",
    "                    'long_only': {'returns': [], 'turnovers': [], 'dates': []},\n",
    "                    'short_only': {'returns': [], 'turnovers': [], 'dates': []},\n",
    "                    'long_short': {'returns': [], 'turnovers': [], 'dates': []}\n",
    "                }\n",
    "                \n",
    "                prev_portfolio_data = {'long_only': None, 'short_only': None, 'long_short': None}\n",
    "                \n",
    "                signals_buf = {}\n",
    "                \n",
    "                for year in range(start_year, min(end_year + 1, 2025)):\n",
    "                    for quarter in range(1, 5):\n",
    "                        # Determine model file year and quarter (T+1 logic: use previous quarter's model to predict current quarter)\n",
    "                        if quarter == 1:\n",
    "                            model_file_year, model_file_quarter = year - 1, 4\n",
    "                        else:\n",
    "                            model_file_year, model_file_quarter = year, quarter - 1\n",
    "                            \n",
    "                        model = load_nbeats_model(\n",
    "                            window=window,\n",
    "                            year=model_file_year,\n",
    "                            quarter=model_file_quarter,\n",
    "                            training_device=device\n",
    "                        )\n",
    "                        \n",
    "                        if model is None:\n",
    "                            print(f\"      Skip: Model file not found for {model_file_year}Q{model_file_quarter}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Filter data for the current quarter\n",
    "                        quarter_mask = (\n",
    "                            (dates_test.dt.year == year) & \n",
    "                            (dates_test.dt.quarter == quarter)\n",
    "                        )\n",
    "                        if not np.any(quarter_mask):\n",
    "                            continue\n",
    "                        \n",
    "                        X_quarter = X_test[quarter_mask]\n",
    "                        y_quarter = y_test[quarter_mask]\n",
    "                        permnos_quarter = permnos_test[quarter_mask]\n",
    "                        market_caps_quarter = market_caps[quarter_mask]\n",
    "                        dates_quarter = dates_test[quarter_mask]\n",
    "                        ret_dates_quarter = meta_test.loc[quarter_mask, 'ret_date'].values\n",
    "                        \n",
    "                        preds = model.predict(X_quarter)\n",
    "                        \n",
    "                        # ========== y inverse standardization ==========\n",
    "                        y_scaler = y_scalers.get(window)\n",
    "                        if y_scaler is not None:\n",
    "                            preds = inverse_transform_predictions(preds, y_scaler)\n",
    "                            y_quarter = inverse_transform_predictions(y_quarter, y_scaler)\n",
    "                        else:\n",
    "                            print(f\"[Warning] No Y scaler found for window {window}, using original scale\")\n",
    "                        # ================================\n",
    "\n",
    "                        # Align by date (daily prediction)\n",
    "                        if len(preds) < len(y_quarter):\n",
    "                            gap = len(y_quarter) - len(preds)\n",
    "                            dates_quarter       = dates_quarter[gap:]\n",
    "                            ret_dates_quarter   = ret_dates_quarter[gap:]\n",
    "                            permnos_quarter     = permnos_quarter[gap:]\n",
    "                            market_caps_quarter = market_caps_quarter[gap:]\n",
    "                            y_quarter           = y_quarter[gap:]\n",
    "\n",
    "                        assert len(preds) == len(y_quarter)\n",
    "\n",
    "                        df_quarter = pd.DataFrame({\n",
    "                            'signal_date': dates_quarter,\n",
    "                            'ret_date'   : ret_dates_quarter,\n",
    "                            'permno'     : permnos_quarter,\n",
    "                            'market_cap' : market_caps_quarter,\n",
    "                            'actual_return': y_quarter,\n",
    "                            'prediction'   : preds\n",
    "                        })\n",
    "                        \n",
    "                        # Only collect in the first scheme to avoid duplication\n",
    "                        if scheme == 'VW':\n",
    "                            df_q_save = df_quarter[['signal_date','ret_date','permno',\n",
    "                                                    'actual_return','prediction','market_cap']].copy()\n",
    "                            df_q_save.rename(columns={'actual_return':'y_true',\n",
    "                                                      'prediction':'y_pred'}, inplace=True)\n",
    "                            df_q_save['model']  = model_name\n",
    "                            df_q_save['window'] = window\n",
    "                            pred_rows.append(df_q_save)\n",
    "                        \n",
    "                        all_y_true.append(df_quarter['actual_return'].values)\n",
    "                        all_y_pred.append(df_quarter['prediction'].values)\n",
    "                        all_permnos.append(df_quarter['permno'].values)\n",
    "                        meta_quarter = meta_test.loc[quarter_mask].copy()\n",
    "                        if len(preds) < len(meta_quarter):\n",
    "                            gap = len(meta_quarter) - len(preds)\n",
    "                            meta_quarter = meta_quarter.iloc[gap:]        \n",
    "\n",
    "                        all_meta.append(meta_quarter)  \n",
    "\n",
    "                        # Loop by date (T+1 rebalancing logic)\n",
    "                        for signal_date, sig_grp in df_quarter.groupby('signal_date'):\n",
    "                            # (1) Today's signals: just calculate and store in buffer, do not rebalance yet\n",
    "                            daily_signals = (\n",
    "                                sig_grp.groupby('permno')['prediction'].mean()\n",
    "                                      .to_frame('prediction')\n",
    "                                      .join(sig_grp.groupby('permno')['market_cap'].mean())\n",
    "                            )\n",
    "                            signals_buf[signal_date] = daily_signals\n",
    "\n",
    "                            # (2) Only use yesterday's signals to rebalance today\n",
    "                            prev_date = signal_date - pd.tseries.offsets.BDay(1)\n",
    "                            if prev_date not in signals_buf:\n",
    "                                continue\n",
    "\n",
    "                            sigs = signals_buf.pop(prev_date)\n",
    "                            if prev_date in signals_buf:\n",
    "                                del signals_buf[prev_date]\n",
    "\n",
    "                            # (3) Use today's actual returns for settlement (ret_date == signal_date)\n",
    "                            ret_grp = df_quarter[df_quarter['ret_date'] == signal_date]\n",
    "                            if len(ret_grp) == 0:\n",
    "                                continue\n",
    "\n",
    "                            daily_actual_returns = (\n",
    "                                ret_grp.groupby('permno')['actual_return']\n",
    "                                       .mean()\n",
    "                                       .reindex(sigs.index, fill_value=0)\n",
    "                                       .values\n",
    "                            )\n",
    "                            daily_permnos = sigs.index.values\n",
    "\n",
    "                            # (4) Generate 3 sets of weights\n",
    "                            portfolios_data = backtester.create_portfolios_with_permno_tracking(\n",
    "                                signals      = sigs['prediction'].values,\n",
    "                                market_caps  = sigs['market_cap'].values,\n",
    "                                permnos      = daily_permnos,\n",
    "                                weight_scheme= scheme\n",
    "                            )\n",
    "                            \n",
    "                            for portfolio_type in ['long_only', 'short_only', 'long_short']:\n",
    "                                portfolio_info = portfolios_data[portfolio_type]\n",
    "                                \n",
    "                                # Calculate strictly aligned portfolio return\n",
    "                                portfolio_return, aligned_returns = backtester.calculate_aligned_portfolio_return(\n",
    "                                    portfolio_weights=portfolio_info['weights'],\n",
    "                                    portfolio_permnos=portfolio_info['permnos'],\n",
    "                                    actual_returns=daily_actual_returns,\n",
    "                                    actual_permnos=daily_permnos\n",
    "                                )\n",
    "                                \n",
    "                                if prev_portfolio_data[portfolio_type] is not None:\n",
    "                                    prev_w_ser = pd.Series(\n",
    "                                        prev_portfolio_data[portfolio_type]['weights'],\n",
    "                                        index=prev_portfolio_data[portfolio_type]['permnos']\n",
    "                                    )\n",
    "                                    cur_w_ser = pd.Series(\n",
    "                                        portfolio_info['weights'],\n",
    "                                        index=portfolio_info['permnos']\n",
    "                                    )\n",
    "\n",
    "                                    prev_r_ser = pd.Series(\n",
    "                                        prev_portfolio_data[portfolio_type]['aligned_returns'],\n",
    "                                        index=prev_portfolio_data[portfolio_type]['permnos']\n",
    "                                    )\n",
    "\n",
    "                                    aligned_prev_w = prev_w_ser.reindex(cur_w_ser.index, fill_value=0).values\n",
    "                                    aligned_prev_r = prev_r_ser.reindex(cur_w_ser.index, fill_value=0).values\n",
    "\n",
    "                                    aligned_cur_w = cur_w_ser.values\n",
    "\n",
    "                                    turnover = backtester.calc_turnover(\n",
    "                                        w_t  = aligned_prev_w,\n",
    "                                        r_t  = aligned_prev_r,\n",
    "                                        w_tp1= aligned_cur_w\n",
    "                                    )\n",
    "                                else:\n",
    "                                    turnover = np.sum(np.abs(portfolio_info['weights']))\n",
    "                                \n",
    "                                portfolio_daily_data[portfolio_type]['returns'].append(portfolio_return)\n",
    "                                portfolio_daily_data[portfolio_type]['turnovers'].append(turnover)\n",
    "                                portfolio_daily_data[portfolio_type]['dates'].append(signal_date)\n",
    "                                \n",
    "                                prev_portfolio_data[portfolio_type] = {\n",
    "                                    'weights'        : portfolio_info['weights'],\n",
    "                                    'permnos'        : portfolio_info['permnos'],\n",
    "                                    'aligned_returns': aligned_returns      \n",
    "                                }\n",
    "                \n",
    "                # Calculate final metrics and store results\n",
    "                for portfolio_type in ['long_only', 'short_only', 'long_short']:\n",
    "                    portfolio_data = portfolio_daily_data[portfolio_type]\n",
    "                    \n",
    "                    if len(portfolio_data['returns']) > 0:\n",
    "                        metrics = backtester.calculate_metrics(\n",
    "                            returns=portfolio_data['returns'],\n",
    "                            turnover_series=portfolio_data['turnovers']\n",
    "                        )\n",
    "                        \n",
    "                        rets = np.array(portfolio_data['returns'])\n",
    "                        tovs = np.array(portfolio_data['turnovers'])\n",
    "\n",
    "                        for tc in TC_GRID:\n",
    "                            tag = TC_TAG[tc]\n",
    "                            adj = rets - tovs * tc\n",
    "\n",
    "                            ann_ret = adj.mean() * 252\n",
    "                            ann_vol = adj.std(ddof=1) * np.sqrt(252)\n",
    "                            sharpe  = ann_ret / ann_vol if ann_vol > 0 else 0\n",
    "\n",
    "                            cum_adj = np.cumprod(1 + adj)\n",
    "                            mdd = ((cum_adj - np.maximum.accumulate(cum_adj)) /\n",
    "                                   np.maximum.accumulate(cum_adj)).min()\n",
    "\n",
    "                            metrics[f'{tag}_annual_return'] = ann_ret\n",
    "                            metrics[f'{tag}_annual_vol']    = ann_vol\n",
    "                            metrics[f'{tag}_sharpe']        = sharpe\n",
    "                            metrics[f'{tag}_max_drawdown']  = mdd\n",
    "                        \n",
    "                        summary_results.append({\n",
    "                            'scheme': scheme,\n",
    "                            'model': model_name,\n",
    "                            'window': window,\n",
    "                            'portfolio_type': portfolio_type,\n",
    "                            **metrics\n",
    "                        })\n",
    "                        \n",
    "                        rets_arr = np.array(portfolio_data['returns'])\n",
    "                        tovs_arr = np.array(portfolio_data['turnovers'])\n",
    "                        cum_no_tc = np.log1p(rets_arr).cumsum()\n",
    "\n",
    "                        tc_ret_dict = {}\n",
    "                        tc_cum_dict = {}\n",
    "                        for tc in TC_GRID:\n",
    "                            tag = TC_TAG[tc]\n",
    "                            r = rets_arr - tovs_arr * tc\n",
    "                            tc_ret_dict[tag] = r\n",
    "                            tc_cum_dict[tag] = np.log1p(r).cumsum()\n",
    "\n",
    "                        for i, date in enumerate(portfolio_data['dates']):\n",
    "                            row = {\n",
    "                                'scheme'        : scheme,\n",
    "                                'model'         : model_name,\n",
    "                                'window'        : window,\n",
    "                                'portfolio_type': portfolio_type,\n",
    "                                'date'          : str(date),\n",
    "                                'return'        : rets_arr[i],\n",
    "                                'turnover'      : tovs_arr[i],\n",
    "                                'cumulative'    : cum_no_tc[i],\n",
    "                            }\n",
    "                            for tag in TC_TAG.values():\n",
    "                                row[f'{tag}_return']     = tc_ret_dict[tag][i]\n",
    "                                row[f'{tag}_cumulative'] = tc_cum_dict[tag][i]\n",
    "\n",
    "                            daily_series_data.append(row)\n",
    "\n",
    "                # After processing all portfolio_types for the current scheme, calculate overall regression metrics\n",
    "                if scheme == \"VW\" and len(all_y_true) > 0:\n",
    "                    y_all    = np.concatenate(all_y_true)\n",
    "                    yhat_all = np.concatenate(all_y_pred)\n",
    "                    perm_all = np.concatenate(all_permnos)\n",
    "                    meta_all = pd.concat(all_meta, ignore_index=True)\n",
    "\n",
    "                    k = X_test.shape[1]\n",
    "\n",
    "                    m1_metrics = overall_interval_metrics_method1(\n",
    "                        y_all, yhat_all, k,\n",
    "                        permnos_all=perm_all,\n",
    "                        meta_all=meta_all\n",
    "                    )\n",
    "\n",
    "                    # Calculate cross-sectional RankIC\n",
    "                    full_pred_df = pd.concat(pred_rows, ignore_index=True)\n",
    "                    mean_ic, t_ic, pos_ic, _ = calc_ic_daily(full_pred_df, method='spearman')\n",
    "                    m1_metrics['RankIC_mean']  = mean_ic\n",
    "                    m1_metrics['RankIC_t']     = t_ic\n",
    "                    m1_metrics['RankIC_pos%']  = pos_ic\n",
    "\n",
    "                    save_metrics(m1_metrics, name=model_name, window=window,\n",
    "                        path=\"portfolio_metrics.csv\")\n",
    "\n",
    "    # Create DataFrame and ensure all TC metrics exist\n",
    "    summary_df = pd.DataFrame(summary_results)\n",
    "    daily_df = pd.DataFrame(daily_series_data) if daily_series_data else pd.DataFrame()\n",
    "    \n",
    "    tc_columns = [c for c in summary_df.columns if c.startswith('tc')]\n",
    "    summary_df[tc_columns] = summary_df[tc_columns].fillna(0.0)\n",
    "    \n",
    "    def save_split_by_scheme(df, base_filename):\n",
    "        \"\"\"Helper function to save files split by scheme\"\"\"\n",
    "        if df.empty:\n",
    "            print(f\"Warning: DataFrame is empty, skipping save for {base_filename}\")\n",
    "            return None, None\n",
    "            \n",
    "        vw_df = df[df['scheme'] == 'VW']\n",
    "        ew_df = df[df['scheme'] == 'EW']\n",
    "        \n",
    "        vw_filename = f\"{base_filename}_VW.csv\"\n",
    "        ew_filename = f\"{base_filename}_EW.csv\"\n",
    "        \n",
    "        vw_df.to_csv(vw_filename, index=False)\n",
    "        ew_df.to_csv(ew_filename, index=False)\n",
    "        \n",
    "        print(f\"VW results saved to {vw_filename}\")\n",
    "        print(f\"EW results saved to {ew_filename}\")\n",
    "        \n",
    "        return vw_filename, ew_filename\n",
    "    \n",
    "    save_split_by_scheme(summary_df, \"portfolio_results_daily_rebalance\")\n",
    "    \n",
    "    if not daily_df.empty:\n",
    "        save_split_by_scheme(daily_df, \"portfolio_daily_series\")\n",
    "    \n",
    "    if pred_rows:\n",
    "        pred_df = pd.concat(pred_rows, ignore_index=True)\n",
    "        pred_df.to_csv(\"predictions_daily.csv\", index=False)\n",
    "        print(f\"Saved {len(pred_df)} prediction rows to predictions_daily.csv\")\n",
    "    \n",
    "    print(f\"Generated {len(summary_results)} portfolio summary records\")\n",
    "    print(f\"Generated {len(daily_series_data)} daily series records\")\n",
    "    \n",
    "    return summary_df, daily_df, backtester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== N-BEATS quarterly expanding training 2015-2024 ===\n",
      "\n",
      ">> Window = 5\n",
      "    Optuna tuning on initial window…\n",
      "    [Hyperparameter Tuning] Running Optuna optimization for window=5\n",
      "    [Device Setting] Using CPU for hyperparameter tuning\n",
      "    [Tuning Completed] Switching back to mps for model training\n",
      "    [Optuna] NBEATS best_params={'stacks': 1, 'blocks_per_stack': 1, 'batch_size': 64, 'learning_rate': 0.0002962151658830348, 'max_epochs': 25, 'warm_start_epochs': 15, 'layers': 2, 'layer_size': 128}\n",
      "[Window 5] 2015Q4\n",
      "    Cold-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2015Q4.pth\n",
      "[Window 5] 2016Q1\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2015Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2016Q1.pth\n",
      "[Window 5] 2016Q2\n",
      "    +2956 obs from 2016Q1 -> train_size=199876\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2016Q2.pth\n",
      "[Window 5] 2016Q3\n",
      "    +3170 obs from 2016Q2 -> train_size=203046\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2016Q3.pth\n",
      "[Window 5] 2016Q4\n",
      "    +3176 obs from 2016Q3 -> train_size=206222\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2016Q4.pth\n",
      "[Window 5] 2017Q1\n",
      "    +3123 obs from 2016Q4 -> train_size=209345\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2017Q1.pth\n",
      "[Window 5] 2017Q2\n",
      "    +3083 obs from 2017Q1 -> train_size=212428\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2017Q2.pth\n",
      "[Window 5] 2017Q3\n",
      "    +3122 obs from 2017Q2 -> train_size=215550\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2017Q3.pth\n",
      "[Window 5] 2017Q4\n",
      "    +3114 obs from 2017Q3 -> train_size=218664\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2017Q4.pth\n",
      "[Window 5] 2018Q1\n",
      "    +3115 obs from 2017Q4 -> train_size=221779\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2018Q1.pth\n",
      "[Window 5] 2018Q2\n",
      "    +2996 obs from 2018Q1 -> train_size=224775\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2018Q2.pth\n",
      "[Window 5] 2018Q3\n",
      "    +3160 obs from 2018Q2 -> train_size=227935\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2018Q3.pth\n",
      "[Window 5] 2018Q4\n",
      "    +3125 obs from 2018Q3 -> train_size=231060\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2018Q4.pth\n",
      "[Window 5] 2019Q1\n",
      "    +3045 obs from 2018Q4 -> train_size=234105\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2019Q1.pth\n",
      "[Window 5] 2019Q2\n",
      "    +3022 obs from 2019Q1 -> train_size=237127\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2019Q2.pth\n",
      "[Window 5] 2019Q3\n",
      "    +3120 obs from 2019Q2 -> train_size=240247\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2019Q3.pth\n",
      "[Window 5] 2019Q4\n",
      "    +3167 obs from 2019Q3 -> train_size=243414\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2019Q4.pth\n",
      "[Window 5] 2020Q1\n",
      "    +3179 obs from 2019Q4 -> train_size=246593\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2020Q1.pth\n",
      "[Window 5] 2020Q2\n",
      "    +2595 obs from 2020Q1 -> train_size=249188\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2020Q2.pth\n",
      "[Window 5] 2020Q3\n",
      "    +2839 obs from 2020Q2 -> train_size=252027\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2020Q3.pth\n",
      "[Window 5] 2020Q4\n",
      "    +3151 obs from 2020Q3 -> train_size=255178\n",
      "    Re-tuning via Optuna…\n",
      "    [Hyperparameter Tuning] Running Optuna optimization for window=5\n",
      "    [Device Setting] Using CPU for hyperparameter tuning\n",
      "    [Tuning Completed] Switching back to mps for model training\n",
      "    [Optuna] NBEATS best_params={'stacks': 1, 'blocks_per_stack': 3, 'batch_size': 32, 'learning_rate': 0.00025959425503112657, 'max_epochs': 25, 'warm_start_epochs': 15, 'layers': 2, 'layer_size': 128}\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2020Q4.pth\n",
      "[Window 5] 2021Q1\n",
      "    +3114 obs from 2020Q4 -> train_size=258292\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2021Q1.pth\n",
      "[Window 5] 2021Q2\n",
      "    +2989 obs from 2021Q1 -> train_size=261281\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2021Q2.pth\n",
      "[Window 5] 2021Q3\n",
      "    +3132 obs from 2021Q2 -> train_size=264413\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2021Q3.pth\n",
      "[Window 5] 2021Q4\n",
      "    +3173 obs from 2021Q3 -> train_size=267586\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2021Q4.pth\n",
      "[Window 5] 2022Q1\n",
      "    +3153 obs from 2021Q4 -> train_size=270739\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2022Q1.pth\n",
      "[Window 5] 2022Q2\n",
      "    +3029 obs from 2022Q1 -> train_size=273768\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2022Q2.pth\n",
      "[Window 5] 2022Q3\n",
      "    +2969 obs from 2022Q2 -> train_size=276737\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2022Q3.pth\n",
      "[Window 5] 2022Q4\n",
      "    +3152 obs from 2022Q3 -> train_size=279889\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2022Q4.pth\n",
      "[Window 5] 2023Q1\n",
      "    +3070 obs from 2022Q4 -> train_size=282959\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2023Q1.pth\n",
      "[Window 5] 2023Q2\n",
      "    +3064 obs from 2023Q1 -> train_size=286023\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2023Q2.pth\n",
      "[Window 5] 2023Q3\n",
      "    +3069 obs from 2023Q2 -> train_size=289092\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2023Q3.pth\n",
      "[Window 5] 2023Q4\n",
      "    +3121 obs from 2023Q3 -> train_size=292213\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2023Q4.pth\n",
      "[Window 5] 2024Q1\n",
      "    +3113 obs from 2023Q4 -> train_size=295326\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2024Q1.pth\n",
      "[Window 5] 2024Q2\n",
      "    +3026 obs from 2024Q1 -> train_size=298352\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2024Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2024Q2.pth\n",
      "[Window 5] 2024Q3\n",
      "    +3112 obs from 2024Q2 -> train_size=301464\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2024Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w5_2024Q3.pth\n",
      "\n",
      ">> Window = 21\n",
      "[Window 21] 2015Q4\n",
      "    Cold-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2015Q4.pth\n",
      "[Window 21] 2016Q1\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2015Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2016Q1.pth\n",
      "[Window 21] 2016Q2\n",
      "    +2956 obs from 2016Q1 -> train_size=199076\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2016Q2.pth\n",
      "[Window 21] 2016Q3\n",
      "    +3170 obs from 2016Q2 -> train_size=202246\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2016Q3.pth\n",
      "[Window 21] 2016Q4\n",
      "    +3176 obs from 2016Q3 -> train_size=205422\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2016Q4.pth\n",
      "[Window 21] 2017Q1\n",
      "    +3123 obs from 2016Q4 -> train_size=208545\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2017Q1.pth\n",
      "[Window 21] 2017Q2\n",
      "    +3083 obs from 2017Q1 -> train_size=211628\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2017Q2.pth\n",
      "[Window 21] 2017Q3\n",
      "    +3122 obs from 2017Q2 -> train_size=214750\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2017Q3.pth\n",
      "[Window 21] 2017Q4\n",
      "    +3114 obs from 2017Q3 -> train_size=217864\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2017Q4.pth\n",
      "[Window 21] 2018Q1\n",
      "    +3115 obs from 2017Q4 -> train_size=220979\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2018Q1.pth\n",
      "[Window 21] 2018Q2\n",
      "    +2996 obs from 2018Q1 -> train_size=223975\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2018Q2.pth\n",
      "[Window 21] 2018Q3\n",
      "    +3160 obs from 2018Q2 -> train_size=227135\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2018Q3.pth\n",
      "[Window 21] 2018Q4\n",
      "    +3125 obs from 2018Q3 -> train_size=230260\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2018Q4.pth\n",
      "[Window 21] 2019Q1\n",
      "    +3045 obs from 2018Q4 -> train_size=233305\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2019Q1.pth\n",
      "[Window 21] 2019Q2\n",
      "    +3022 obs from 2019Q1 -> train_size=236327\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2019Q2.pth\n",
      "[Window 21] 2019Q3\n",
      "    +3120 obs from 2019Q2 -> train_size=239447\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2019Q3.pth\n",
      "[Window 21] 2019Q4\n",
      "    +3167 obs from 2019Q3 -> train_size=242614\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2019Q4.pth\n",
      "[Window 21] 2020Q1\n",
      "    +3179 obs from 2019Q4 -> train_size=245793\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2020Q1.pth\n",
      "[Window 21] 2020Q2\n",
      "    +2595 obs from 2020Q1 -> train_size=248388\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2020Q2.pth\n",
      "[Window 21] 2020Q3\n",
      "    +2839 obs from 2020Q2 -> train_size=251227\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2020Q3.pth\n",
      "[Window 21] 2020Q4\n",
      "    +3151 obs from 2020Q3 -> train_size=254378\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2020Q4.pth\n",
      "[Window 21] 2021Q1\n",
      "    +3114 obs from 2020Q4 -> train_size=257492\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2021Q1.pth\n",
      "[Window 21] 2021Q2\n",
      "    +2989 obs from 2021Q1 -> train_size=260481\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2021Q2.pth\n",
      "[Window 21] 2021Q3\n",
      "    +3132 obs from 2021Q2 -> train_size=263613\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2021Q3.pth\n",
      "[Window 21] 2021Q4\n",
      "    +3173 obs from 2021Q3 -> train_size=266786\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2021Q4.pth\n",
      "[Window 21] 2022Q1\n",
      "    +3153 obs from 2021Q4 -> train_size=269939\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2022Q1.pth\n",
      "[Window 21] 2022Q2\n",
      "    +3029 obs from 2022Q1 -> train_size=272968\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2022Q2.pth\n",
      "[Window 21] 2022Q3\n",
      "    +2969 obs from 2022Q2 -> train_size=275937\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2022Q3.pth\n",
      "[Window 21] 2022Q4\n",
      "    +3152 obs from 2022Q3 -> train_size=279089\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2022Q4.pth\n",
      "[Window 21] 2023Q1\n",
      "    +3070 obs from 2022Q4 -> train_size=282159\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2023Q1.pth\n",
      "[Window 21] 2023Q2\n",
      "    +3064 obs from 2023Q1 -> train_size=285223\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2023Q2.pth\n",
      "[Window 21] 2023Q3\n",
      "    +3069 obs from 2023Q2 -> train_size=288292\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2023Q3.pth\n",
      "[Window 21] 2023Q4\n",
      "    +3121 obs from 2023Q3 -> train_size=291413\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2023Q4.pth\n",
      "[Window 21] 2024Q1\n",
      "    +3113 obs from 2023Q4 -> train_size=294526\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2024Q1.pth\n",
      "[Window 21] 2024Q2\n",
      "    +3026 obs from 2024Q1 -> train_size=297552\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2024Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2024Q2.pth\n",
      "[Window 21] 2024Q3\n",
      "    +3112 obs from 2024Q2 -> train_size=300664\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2024Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w21_2024Q3.pth\n",
      "\n",
      ">> Window = 252\n",
      "[Window 252] 2015Q4\n",
      "    Cold-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2015Q4.pth\n",
      "[Window 252] 2016Q1\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2015Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2016Q1.pth\n",
      "[Window 252] 2016Q2\n",
      "    +2956 obs from 2016Q1 -> train_size=187526\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2016Q2.pth\n",
      "[Window 252] 2016Q3\n",
      "    +3170 obs from 2016Q2 -> train_size=190696\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2016Q3.pth\n",
      "[Window 252] 2016Q4\n",
      "    +3176 obs from 2016Q3 -> train_size=193872\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2016Q4.pth\n",
      "[Window 252] 2017Q1\n",
      "    +3123 obs from 2016Q4 -> train_size=196995\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2017Q1.pth\n",
      "[Window 252] 2017Q2\n",
      "    +3083 obs from 2017Q1 -> train_size=200078\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2017Q2.pth\n",
      "[Window 252] 2017Q3\n",
      "    +3122 obs from 2017Q2 -> train_size=203200\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2017Q3.pth\n",
      "[Window 252] 2017Q4\n",
      "    +3114 obs from 2017Q3 -> train_size=206314\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2017Q4.pth\n",
      "[Window 252] 2018Q1\n",
      "    +3115 obs from 2017Q4 -> train_size=209429\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2018Q1.pth\n",
      "[Window 252] 2018Q2\n",
      "    +2996 obs from 2018Q1 -> train_size=212425\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2018Q2.pth\n",
      "[Window 252] 2018Q3\n",
      "    +3160 obs from 2018Q2 -> train_size=215585\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2018Q3.pth\n",
      "[Window 252] 2018Q4\n",
      "    +3125 obs from 2018Q3 -> train_size=218710\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2018Q4.pth\n",
      "[Window 252] 2019Q1\n",
      "    +3045 obs from 2018Q4 -> train_size=221755\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2019Q1.pth\n",
      "[Window 252] 2019Q2\n",
      "    +3022 obs from 2019Q1 -> train_size=224777\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2019Q2.pth\n",
      "[Window 252] 2019Q3\n",
      "    +3120 obs from 2019Q2 -> train_size=227897\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2019Q3.pth\n",
      "[Window 252] 2019Q4\n",
      "    +3167 obs from 2019Q3 -> train_size=231064\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2019Q4.pth\n",
      "[Window 252] 2020Q1\n",
      "    +3179 obs from 2019Q4 -> train_size=234243\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2020Q1.pth\n",
      "[Window 252] 2020Q2\n",
      "    +2595 obs from 2020Q1 -> train_size=236838\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2020Q2.pth\n",
      "[Window 252] 2020Q3\n",
      "    +2839 obs from 2020Q2 -> train_size=239677\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2020Q3.pth\n",
      "[Window 252] 2020Q4\n",
      "    +3151 obs from 2020Q3 -> train_size=242828\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2020Q4.pth\n",
      "[Window 252] 2021Q1\n",
      "    +3114 obs from 2020Q4 -> train_size=245942\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2021Q1.pth\n",
      "[Window 252] 2021Q2\n",
      "    +2989 obs from 2021Q1 -> train_size=248931\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2021Q2.pth\n",
      "[Window 252] 2021Q3\n",
      "    +3132 obs from 2021Q2 -> train_size=252063\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2021Q3.pth\n",
      "[Window 252] 2021Q4\n",
      "    +3173 obs from 2021Q3 -> train_size=255236\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2021Q4.pth\n",
      "[Window 252] 2022Q1\n",
      "    +3153 obs from 2021Q4 -> train_size=258389\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2022Q1.pth\n",
      "[Window 252] 2022Q2\n",
      "    +3029 obs from 2022Q1 -> train_size=261418\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2022Q2.pth\n",
      "[Window 252] 2022Q3\n",
      "    +2969 obs from 2022Q2 -> train_size=264387\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2022Q3.pth\n",
      "[Window 252] 2022Q4\n",
      "    +3152 obs from 2022Q3 -> train_size=267539\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2022Q4.pth\n",
      "[Window 252] 2023Q1\n",
      "    +3070 obs from 2022Q4 -> train_size=270609\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2023Q1.pth\n",
      "[Window 252] 2023Q2\n",
      "    +3064 obs from 2023Q1 -> train_size=273673\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2023Q2.pth\n",
      "[Window 252] 2023Q3\n",
      "    +3069 obs from 2023Q2 -> train_size=276742\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2023Q3.pth\n",
      "[Window 252] 2023Q4\n",
      "    +3121 obs from 2023Q3 -> train_size=279863\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2023Q4.pth\n",
      "[Window 252] 2024Q1\n",
      "    +3113 obs from 2023Q4 -> train_size=282976\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2024Q1.pth\n",
      "[Window 252] 2024Q2\n",
      "    +3026 obs from 2024Q1 -> train_size=286002\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2024Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2024Q2.pth\n",
      "[Window 252] 2024Q3\n",
      "    +3112 obs from 2024Q2 -> train_size=289114\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2024Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w252_2024Q3.pth\n",
      "\n",
      ">> Window = 512\n",
      "[Window 512] 2015Q4\n",
      "    Cold-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2015Q4.pth\n",
      "[Window 512] 2016Q1\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2015Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2016Q1.pth\n",
      "[Window 512] 2016Q2\n",
      "    +2956 obs from 2016Q1 -> train_size=174526\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2016Q2.pth\n",
      "[Window 512] 2016Q3\n",
      "    +3170 obs from 2016Q2 -> train_size=177696\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2016Q3.pth\n",
      "[Window 512] 2016Q4\n",
      "    +3176 obs from 2016Q3 -> train_size=180872\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2016Q4.pth\n",
      "[Window 512] 2017Q1\n",
      "    +3123 obs from 2016Q4 -> train_size=183995\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2017Q1.pth\n",
      "[Window 512] 2017Q2\n",
      "    +3083 obs from 2017Q1 -> train_size=187078\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2017Q2.pth\n",
      "[Window 512] 2017Q3\n",
      "    +3122 obs from 2017Q2 -> train_size=190200\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2017Q3.pth\n",
      "[Window 512] 2017Q4\n",
      "    +3114 obs from 2017Q3 -> train_size=193314\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2017Q4.pth\n",
      "[Window 512] 2018Q1\n",
      "    +3115 obs from 2017Q4 -> train_size=196429\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2018Q1.pth\n",
      "[Window 512] 2018Q2\n",
      "    +2996 obs from 2018Q1 -> train_size=199425\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2018Q2.pth\n",
      "[Window 512] 2018Q3\n",
      "    +3160 obs from 2018Q2 -> train_size=202585\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2018Q3.pth\n",
      "[Window 512] 2018Q4\n",
      "    +3125 obs from 2018Q3 -> train_size=205710\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2018Q4.pth\n",
      "[Window 512] 2019Q1\n",
      "    +3045 obs from 2018Q4 -> train_size=208755\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2019Q1.pth\n",
      "[Window 512] 2019Q2\n",
      "    +3022 obs from 2019Q1 -> train_size=211777\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2019Q2.pth\n",
      "[Window 512] 2019Q3\n",
      "    +3120 obs from 2019Q2 -> train_size=214897\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2019Q3.pth\n",
      "[Window 512] 2019Q4\n",
      "    +3167 obs from 2019Q3 -> train_size=218064\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2019Q4.pth\n",
      "[Window 512] 2020Q1\n",
      "    +3179 obs from 2019Q4 -> train_size=221243\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2020Q1.pth\n",
      "[Window 512] 2020Q2\n",
      "    +2595 obs from 2020Q1 -> train_size=223838\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2020Q2.pth\n",
      "[Window 512] 2020Q3\n",
      "    +2839 obs from 2020Q2 -> train_size=226677\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2020Q3.pth\n",
      "[Window 512] 2020Q4\n",
      "    +3151 obs from 2020Q3 -> train_size=229828\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2020Q4.pth\n",
      "[Window 512] 2021Q1\n",
      "    +3114 obs from 2020Q4 -> train_size=232942\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2021Q1.pth\n",
      "[Window 512] 2021Q2\n",
      "    +2989 obs from 2021Q1 -> train_size=235931\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2021Q2.pth\n",
      "[Window 512] 2021Q3\n",
      "    +3132 obs from 2021Q2 -> train_size=239063\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2021Q3.pth\n",
      "[Window 512] 2021Q4\n",
      "    +3173 obs from 2021Q3 -> train_size=242236\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2021Q4.pth\n",
      "[Window 512] 2022Q1\n",
      "    +3153 obs from 2021Q4 -> train_size=245389\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2022Q1.pth\n",
      "[Window 512] 2022Q2\n",
      "    +3029 obs from 2022Q1 -> train_size=248418\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2022Q2.pth\n",
      "[Window 512] 2022Q3\n",
      "    +2969 obs from 2022Q2 -> train_size=251387\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2022Q3.pth\n",
      "[Window 512] 2022Q4\n",
      "    +3152 obs from 2022Q3 -> train_size=254539\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2022Q4.pth\n",
      "[Window 512] 2023Q1\n",
      "    +3070 obs from 2022Q4 -> train_size=257609\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2023Q1.pth\n",
      "[Window 512] 2023Q2\n",
      "    +3064 obs from 2023Q1 -> train_size=260673\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2023Q2.pth\n",
      "[Window 512] 2023Q3\n",
      "    +3069 obs from 2023Q2 -> train_size=263742\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2023Q3.pth\n",
      "[Window 512] 2023Q4\n",
      "    +3121 obs from 2023Q3 -> train_size=266863\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q3.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2023Q4.pth\n",
      "[Window 512] 2024Q1\n",
      "    +3113 obs from 2023Q4 -> train_size=269976\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q4.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2024Q1.pth\n",
      "[Window 512] 2024Q2\n",
      "    +3026 obs from 2024Q1 -> train_size=273002\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2024Q1.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2024Q2.pth\n",
      "[Window 512] 2024Q3\n",
      "    +3112 obs from 2024Q2 -> train_size=276114\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2024Q2.pth\n",
      "    Warm-start …\n",
      "[Save] N-BEATS model saved: NBEATS_w512_2024Q3.pth\n",
      "=== All N-BEATS quarterly models trained ===\n"
     ]
    }
   ],
   "source": [
    "train_nbeats_models_expanding_quarterly(\n",
    "    start_year=2015,\n",
    "    end_year=2024,\n",
    "    window_sizes=[5, 21, 252, 512],\n",
    "    n_trials_optuna=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Daily Rebalance Portfolio Backtesting Simulation\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "Processing window size: 5\n",
      "  Model: NBEATS, Scheme: VW\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2015Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3170 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3176 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3123 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3083 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3122 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3115 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2996 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3160 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3125 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3045 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3022 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3120 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3167 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3179 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2595 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2839 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3151 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2989 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3173 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3029 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3152 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3070 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3064 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3069 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3121 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3113 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3026 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2024Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2024Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3162 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2024Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Create] New metrics file created with NBEATS w=5\n",
      "  Model: NBEATS, Scheme: EW\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2015Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3170 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3176 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3123 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2016Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3083 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3122 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3115 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2017Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2996 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3160 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3125 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3045 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2018Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3022 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3120 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3167 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3179 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2019Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2595 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2839 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3151 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2020Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2989 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3173 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2021Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3029 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3152 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3070 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2022Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3064 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3069 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3121 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3113 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2023Q4.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3026 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2024Q1.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2024Q2.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3162 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w5_2024Q3.pth\n",
      "[Load] Y scaler loaded for window 5: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_5.pkl\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "Processing window size: 21\n",
      "  Model: NBEATS, Scheme: VW\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2015Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3170 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3176 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3123 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3083 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3122 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3115 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2996 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3160 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3125 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3045 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3022 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3120 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3167 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3179 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2595 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2839 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3151 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2989 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3173 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3029 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3152 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3070 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3064 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3069 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3121 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3113 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3026 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2024Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2024Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3162 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2024Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Update] Metrics updated for NBEATS w=21\n",
      "  Model: NBEATS, Scheme: EW\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2015Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3170 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3176 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3123 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2016Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3083 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3122 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3115 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2017Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2996 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3160 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3125 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3045 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2018Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3022 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3120 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3167 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3179 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2019Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2595 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2839 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3151 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2020Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2989 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3173 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2021Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3029 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3152 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3070 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2022Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3064 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3069 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3121 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3113 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2023Q4.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3026 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2024Q1.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2024Q2.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3162 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w21_2024Q3.pth\n",
      "[Load] Y scaler loaded for window 21: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_21.pkl\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "Processing window size: 252\n",
      "  Model: NBEATS, Scheme: VW\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2015Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3170 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3176 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3123 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3083 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3122 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3115 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2996 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3160 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3125 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3045 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3022 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3120 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3167 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3179 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2595 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2839 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3151 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2989 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3173 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3029 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3152 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3070 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3064 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3069 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3121 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3113 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3026 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2024Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2024Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3162 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2024Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Update] Metrics updated for NBEATS w=252\n",
      "  Model: NBEATS, Scheme: EW\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2015Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3170 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3176 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3123 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2016Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3083 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3122 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3115 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2017Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2996 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3160 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3125 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3045 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2018Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3022 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3120 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3167 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3179 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2019Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2595 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2839 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3151 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2020Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2989 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3173 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2021Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3029 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3152 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3070 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2022Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3064 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3069 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3121 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3113 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2023Q4.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3026 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2024Q1.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2024Q2.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3162 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w252_2024Q3.pth\n",
      "[Load] Y scaler loaded for window 252: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_252.pkl\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "Processing window size: 512\n",
      "  Model: NBEATS, Scheme: VW\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2015Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3170 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3176 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3123 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3083 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3122 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3115 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2996 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3160 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3125 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3045 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3022 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3120 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3167 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3179 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2595 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2839 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3151 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2989 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3173 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3029 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3152 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3070 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3064 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3069 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3121 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3113 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3026 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2024Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2024Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3162 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2024Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Update] Metrics updated for NBEATS w=512\n",
      "  Model: NBEATS, Scheme: EW\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2015Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 2986 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3150 predictions\n",
      "[Info] Inverse transformed 3170 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3156 predictions\n",
      "[Info] Inverse transformed 3176 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3103 predictions\n",
      "[Info] Inverse transformed 3123 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2016Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3063 predictions\n",
      "[Info] Inverse transformed 3083 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3102 predictions\n",
      "[Info] Inverse transformed 3122 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3095 predictions\n",
      "[Info] Inverse transformed 3115 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2017Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2976 predictions\n",
      "[Info] Inverse transformed 2996 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3140 predictions\n",
      "[Info] Inverse transformed 3160 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3105 predictions\n",
      "[Info] Inverse transformed 3125 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3025 predictions\n",
      "[Info] Inverse transformed 3045 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2018Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3002 predictions\n",
      "[Info] Inverse transformed 3022 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3100 predictions\n",
      "[Info] Inverse transformed 3120 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3147 predictions\n",
      "[Info] Inverse transformed 3167 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3159 predictions\n",
      "[Info] Inverse transformed 3179 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2019Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2575 predictions\n",
      "[Info] Inverse transformed 2595 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2819 predictions\n",
      "[Info] Inverse transformed 2839 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3131 predictions\n",
      "[Info] Inverse transformed 3151 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "[Info] Inverse transformed 3114 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2020Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Info] Inverse transformed 2989 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Info] Inverse transformed 3173 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3133 predictions\n",
      "[Info] Inverse transformed 3153 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2021Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3009 predictions\n",
      "[Info] Inverse transformed 3029 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2949 predictions\n",
      "[Info] Inverse transformed 2969 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3132 predictions\n",
      "[Info] Inverse transformed 3152 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3050 predictions\n",
      "[Info] Inverse transformed 3070 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2022Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3044 predictions\n",
      "[Info] Inverse transformed 3064 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3049 predictions\n",
      "[Info] Inverse transformed 3069 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3101 predictions\n",
      "[Info] Inverse transformed 3121 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3093 predictions\n",
      "[Info] Inverse transformed 3113 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2023Q4.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3006 predictions\n",
      "[Info] Inverse transformed 3026 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2024Q1.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3092 predictions\n",
      "[Info] Inverse transformed 3112 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2024Q2.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3142 predictions\n",
      "[Info] Inverse transformed 3162 predictions\n",
      "[Load] N-BEATS model loaded: NBEATS_w512_2024Q3.pth\n",
      "[Load] Y scaler loaded for window 512: /Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/scaler_y_window_512.pkl\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3074 predictions\n",
      "[Info] Inverse transformed 3094 predictions\n",
      "VW results saved to portfolio_results_daily_rebalance_VW.csv\n",
      "EW results saved to portfolio_results_daily_rebalance_EW.csv\n",
      "VW results saved to portfolio_daily_series_VW.csv\n",
      "EW results saved to portfolio_daily_series_EW.csv\n",
      "Saved 440520 prediction rows to predictions_daily.csv\n",
      "Generated 24 portfolio summary records\n",
      "Generated 51672 daily series records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   scheme   model  window portfolio_type  annual_return  annual_vol    sharpe  \\\n",
       " 0      VW  NBEATS       5      long_only       0.200589    0.195665  1.025167   \n",
       " 1      VW  NBEATS       5     short_only      -0.091117    0.193805 -0.470147   \n",
       " 2      VW  NBEATS       5     long_short       0.109472    0.195500  0.559961   \n",
       " 3      EW  NBEATS       5      long_only       0.190501    0.201918  0.943457   \n",
       " 4      EW  NBEATS       5     short_only      -0.055643    0.210143 -0.264788   \n",
       " 5      EW  NBEATS       5     long_short       0.134858    0.180195  0.748400   \n",
       " 6      VW  NBEATS      21      long_only       0.130978    0.211384  0.619619   \n",
       " 7      VW  NBEATS      21     short_only      -0.150597    0.214384 -0.702462   \n",
       " 8      VW  NBEATS      21     long_short      -0.019619    0.205308 -0.095559   \n",
       " 9      EW  NBEATS      21      long_only       0.105022    0.223125  0.470686   \n",
       " 10     EW  NBEATS      21     short_only      -0.174878    0.227892 -0.767372   \n",
       " 11     EW  NBEATS      21     long_short      -0.069856    0.180374 -0.387283   \n",
       " 12     VW  NBEATS     252      long_only       0.200698    0.198559  1.010773   \n",
       " 13     VW  NBEATS     252     short_only      -0.096020    0.199655 -0.480932   \n",
       " 14     VW  NBEATS     252     long_short       0.104678    0.184944  0.565999   \n",
       " 15     EW  NBEATS     252      long_only       0.161231    0.203346  0.792889   \n",
       " 16     EW  NBEATS     252     short_only      -0.075985    0.204371 -0.371802   \n",
       " 17     EW  NBEATS     252     long_short       0.085245    0.162122  0.525811   \n",
       " 18     VW  NBEATS     512      long_only       0.161486    0.193071  0.836406   \n",
       " 19     VW  NBEATS     512     short_only      -0.117662    0.193812 -0.607091   \n",
       " 20     VW  NBEATS     512     long_short       0.043824    0.185432  0.236335   \n",
       " 21     EW  NBEATS     512      long_only       0.122293    0.195571  0.625311   \n",
       " 22     EW  NBEATS     512     short_only      -0.126614    0.193657 -0.653808   \n",
       " 23     EW  NBEATS     512     long_short      -0.004321    0.156182 -0.027669   \n",
       " \n",
       "     max_drawdown  max_1d_loss  avg_turnover  ...  tc20_sharpe  \\\n",
       " 0       0.213197    -0.051213      1.601758  ...    -3.088927   \n",
       " 1       0.660587    -0.073426      1.130754  ...    -3.399494   \n",
       " 2       0.321764    -0.073426      2.732443  ...    -6.418593   \n",
       " 3       0.202162    -0.053264      1.465041  ...    -2.704812   \n",
       " 4       0.558523    -0.073426      1.100805  ...    -2.901353   \n",
       " 5       0.229945    -0.073426      2.565063  ...    -6.401184   \n",
       " 6       0.466007    -0.057613      1.762667  ...    -3.579294   \n",
       " 7       0.800193    -0.073426      1.763821  ...    -4.835977   \n",
       " 8       0.433900    -0.073426      3.526530  ...    -8.723938   \n",
       " 9       0.444311    -0.048970      1.609330  ...    -3.161488   \n",
       " 10      0.839778    -0.073426      1.597394  ...    -4.297920   \n",
       " 11      0.556560    -0.073426      3.206638  ...    -9.304705   \n",
       " 12      0.411216    -0.050243      1.823728  ...    -3.618938   \n",
       " 13      0.673453    -0.049956      1.826356  ...    -5.074425   \n",
       " 14      0.502246    -0.059846      3.649687  ...    -9.338738   \n",
       " 15      0.242104    -0.055165      1.734159  ...    -3.507773   \n",
       " 16      0.628334    -0.057077      1.740163  ...    -4.657512   \n",
       " 17      0.311136    -0.052536      3.473742  ...   -10.256774   \n",
       " 18      0.264063    -0.068088      1.828544  ...    -3.924127   \n",
       " 19      0.730278    -0.048296      1.815143  ...    -5.319698   \n",
       " 20      0.401058    -0.050239      3.643531  ...    -9.632812   \n",
       " 21      0.331984    -0.061060      1.744805  ...    -3.860717   \n",
       " 22      0.771391    -0.047282      1.750747  ...    -5.199783   \n",
       " 23      0.516907    -0.054171      3.495440  ...   -11.234368   \n",
       " \n",
       "     tc20_max_drawdown  tc30_annual_return  tc30_annual_vol  tc30_sharpe  \\\n",
       " 0           -0.995297           -1.010340         0.197214    -5.123056   \n",
       " 1           -0.997130           -0.945967         0.195696    -4.833860   \n",
       " 2           -0.999983           -1.956255         0.199905    -9.785934   \n",
       " 3           -0.992256           -0.917070         0.203210    -4.512920   \n",
       " 4           -0.995699           -0.887852         0.211097    -4.205898   \n",
       " 5           -0.999957           -1.804330         0.182453    -9.889271   \n",
       " 6           -0.998742           -1.201599         0.211987    -5.668255   \n",
       " 7           -0.999891           -1.484046         0.215517    -6.885990   \n",
       " 8           -1.000000           -2.685676         0.206894   -12.980929   \n",
       " 9           -0.998082           -1.111632         0.223643    -4.970568   \n",
       " 10          -0.999826           -1.382507         0.228265    -6.056580   \n",
       " 11          -1.000000           -2.494074         0.182144   -13.692845   \n",
       " 12          -0.998215           -1.178040         0.198736    -5.927671   \n",
       " 13          -0.999863           -1.476745         0.200876    -7.351529   \n",
       " 14          -1.000000           -2.654485         0.186694   -14.218362   \n",
       " 15          -0.998141           -1.149793         0.203281    -5.656168   \n",
       " 16          -0.999775           -1.391549         0.204892    -6.791615   \n",
       " 17          -0.999999           -2.540903         0.162904   -15.597517   \n",
       " 18          -0.998729           -1.220894         0.194245    -6.285319   \n",
       " 19          -0.999883           -1.489910         0.194490    -7.660580   \n",
       " 20          -1.000000           -2.710686         0.186937   -14.500527   \n",
       " 21          -0.998679           -1.196780         0.196523    -6.089783   \n",
       " 22          -0.999856           -1.450179         0.194391    -7.460100   \n",
       " 23          -1.000000           -2.646874         0.158103   -16.741489   \n",
       " \n",
       "     tc30_max_drawdown  tc40_annual_return  tc40_annual_vol  tc40_sharpe  \\\n",
       " 0           -0.999852           -1.413982         0.198302    -7.130458   \n",
       " 1           -0.999747           -1.230917         0.197553    -6.230832   \n",
       " 2           -1.000000           -2.644830         0.203204   -13.015641   \n",
       " 3           -0.999673           -1.286260         0.204082    -6.302675   \n",
       " 4           -0.999598           -1.165255         0.212165    -5.492200   \n",
       " 5           -1.000000           -2.450726         0.184796   -13.261804   \n",
       " 6           -0.999972           -1.645791         0.212544    -7.743279   \n",
       " 7           -0.999998           -1.928528         0.216242    -8.918375   \n",
       " 8           -1.000000           -3.574362         0.208179   -17.169619   \n",
       " 9           -0.999941           -1.517183         0.224079    -6.770752   \n",
       " 10          -0.999994           -1.785050         0.228653    -7.806806   \n",
       " 11          -1.000000           -3.302147         0.183439   -18.001369   \n",
       " 12          -0.999965           -1.637619         0.199092    -8.225450   \n",
       " 13          -0.999997           -1.936987         0.201581    -9.608965   \n",
       " 14          -1.000000           -3.574206         0.187973   -19.014499   \n",
       " 15          -0.999956           -1.586802         0.203462    -7.798997   \n",
       " 16          -0.999995           -1.830070         0.205259    -8.915907   \n",
       " 17          -1.000000           -3.416286         0.163684   -20.871197   \n",
       " 18          -0.999975           -1.681687         0.194944    -8.626499   \n",
       " 19          -0.999998           -1.947326         0.195066    -9.982883   \n",
       " 20          -1.000000           -3.628856         0.188135   -19.288569   \n",
       " 21          -0.999970           -1.636471         0.197049    -8.304914   \n",
       " 22          -0.999997           -1.891367         0.194839    -9.707336   \n",
       " 23          -1.000000           -3.527725         0.159266   -22.149927   \n",
       " \n",
       "     tc40_max_drawdown  \n",
       " 0           -0.999995  \n",
       " 1           -0.999978  \n",
       " 2           -1.000000  \n",
       " 3           -0.999986  \n",
       " 4           -0.999963  \n",
       " 5           -1.000000  \n",
       " 6           -0.999999  \n",
       " 7           -1.000000  \n",
       " 8           -1.000000  \n",
       " 9           -0.999998  \n",
       " 10          -1.000000  \n",
       " 11          -1.000000  \n",
       " 12          -0.999999  \n",
       " 13          -1.000000  \n",
       " 14          -1.000000  \n",
       " 15          -0.999999  \n",
       " 16          -1.000000  \n",
       " 17          -1.000000  \n",
       " 18          -1.000000  \n",
       " 19          -1.000000  \n",
       " 20          -1.000000  \n",
       " 21          -0.999999  \n",
       " 22          -1.000000  \n",
       " 23          -1.000000  \n",
       " \n",
       " [24 rows x 32 columns],\n",
       "       scheme   model  window portfolio_type                 date    return  \\\n",
       " 0         VW  NBEATS       5      long_only  2016-01-05 00:00:00  0.001074   \n",
       " 1         VW  NBEATS       5      long_only  2016-01-06 00:00:00 -0.015464   \n",
       " 2         VW  NBEATS       5      long_only  2016-01-07 00:00:00 -0.035263   \n",
       " 3         VW  NBEATS       5      long_only  2016-01-08 00:00:00 -0.005331   \n",
       " 4         VW  NBEATS       5      long_only  2016-01-11 00:00:00  0.007531   \n",
       " ...      ...     ...     ...            ...                  ...       ...   \n",
       " 51667     EW  NBEATS     512     long_short  2024-12-20 00:00:00  0.000357   \n",
       " 51668     EW  NBEATS     512     long_short  2024-12-23 00:00:00 -0.002736   \n",
       " 51669     EW  NBEATS     512     long_short  2024-12-24 00:00:00 -0.002014   \n",
       " 51670     EW  NBEATS     512     long_short  2024-12-27 00:00:00 -0.008550   \n",
       " 51671     EW  NBEATS     512     long_short  2024-12-30 00:00:00 -0.006763   \n",
       " \n",
       "        turnover  cumulative  tc5_return  tc5_cumulative  tc10_return  \\\n",
       " 0      1.000000    0.001073    0.000574        0.000573     0.000074   \n",
       " 1      2.000000   -0.014512   -0.016464       -0.016027    -0.017464   \n",
       " 2      2.000000   -0.050411   -0.036263       -0.052964    -0.037263   \n",
       " 3      0.799999   -0.055757   -0.005731       -0.058712    -0.006131   \n",
       " 4      1.977360   -0.048254    0.006543       -0.052190     0.005554   \n",
       " ...         ...         ...         ...             ...          ...   \n",
       " 51667  3.597960   -0.120965   -0.001442       -3.880470    -0.003241   \n",
       " 51668  3.628586   -0.123705   -0.004550       -3.885031    -0.006364   \n",
       " 51669  3.985779   -0.125721   -0.004007       -3.889045    -0.006000   \n",
       " 51670  3.617791   -0.134307   -0.010359       -3.899458    -0.012168   \n",
       " 51671  3.195557   -0.141093   -0.008360       -3.907854    -0.009958   \n",
       " \n",
       "        tc10_cumulative  tc20_return  tc20_cumulative  tc30_return  \\\n",
       " 0             0.000074    -0.000926        -0.000927    -0.001926   \n",
       " 1            -0.017545    -0.019464        -0.020583    -0.021464   \n",
       " 2            -0.055519    -0.039263        -0.060637    -0.041263   \n",
       " 3            -0.061669    -0.006931        -0.067592    -0.007731   \n",
       " 4            -0.056131     0.003577        -0.064022     0.001599   \n",
       " ...                ...          ...              ...          ...   \n",
       " 51667        -7.646655    -0.006839       -15.199161    -0.010437   \n",
       " 51668        -7.653040    -0.009993       -15.209204    -0.013621   \n",
       " 51669        -7.659058    -0.009985       -15.219240    -0.013971   \n",
       " 51670        -7.671300    -0.015786       -15.235152    -0.019403   \n",
       " 51671        -7.681308    -0.013154       -15.248393    -0.016349   \n",
       " \n",
       "        tc30_cumulative  tc40_return  tc40_cumulative  \n",
       " 0            -0.001928    -0.002926        -0.002931  \n",
       " 1            -0.023626    -0.023464        -0.026674  \n",
       " 2            -0.065764    -0.043263        -0.070901  \n",
       " 3            -0.073525    -0.008531        -0.079469  \n",
       " 4            -0.071927    -0.000378        -0.079847  \n",
       " ...                ...          ...              ...  \n",
       " 51667       -22.778678    -0.014035       -30.385401  \n",
       " 51668       -22.792393    -0.017250       -30.402801  \n",
       " 51669       -22.806462    -0.017957       -30.420921  \n",
       " 51670       -22.826057    -0.023021       -30.444212  \n",
       " 51671       -22.842541    -0.019545       -30.463950  \n",
       " \n",
       " [51672 rows x 18 columns],\n",
       " <__main__.PortfolioBacktester at 0x16b0f8b60>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_portfolio_simulation_daily_rebalance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] 5_factor_analysis_VW_gross.csv \n",
      "[Saved] 5_factor_analysis_VW_net.csv \n",
      "[Saved] 5_factor_analysis_EW_gross.csv \n",
      "[Saved] 5_factor_analysis_EW_net.csv \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_factor_regression(port_ret, factors, use_excess=True):\n",
    "    \"\"\"\n",
    "    Main function for 5-factor regression.\n",
    "    \"\"\"\n",
    "    df = pd.concat([port_ret, factors], axis=1, join='inner').dropna()\n",
    "    df.columns = ['ret'] + list(factors.columns)\n",
    "    \n",
    "    if use_excess:\n",
    "        y = df['ret'].values\n",
    "    else:\n",
    "        y = df['ret'].values - df['rf'].values\n",
    "    \n",
    "    X = df[['mktrf','smb','hml','rmw','cma','umd']].values\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    model = sm.OLS(y, X)\n",
    "    res = model.fit()\n",
    "    alpha = res.params[0]          # daily alpha\n",
    "    resid_std = res.resid.std(ddof=1)\n",
    "\n",
    "    ir_daily = alpha / resid_std          # daily IR\n",
    "    ir_annual = ir_daily * np.sqrt(252)   # annualized IR\n",
    "\n",
    "    y_hat = np.asarray(res.fittedvalues)\n",
    "    \n",
    "    out = {\n",
    "        'N_obs'            : len(y),\n",
    "        'alpha_daily'      : alpha,\n",
    "        'alpha_annual'     : alpha*252,      \n",
    "        't_alpha'          : res.tvalues[0],\n",
    "        'IR_daily'         : ir_daily,\n",
    "        'IR_annual'        : ir_annual,\n",
    "        'R2_zero'          : r2_zero(y, y_hat),\n",
    "    }\n",
    "    \n",
    "    factor_names = ['MKT','SMB','HML','RMW','CMA','UMD']\n",
    "    for i, fac in enumerate(factor_names, start=1):\n",
    "        out[f'beta_{fac}'] = res.params[i]\n",
    "        out[f't_{fac}']    = res.tvalues[i]\n",
    "    \n",
    "    return out\n",
    "\n",
    "def batch_factor_analysis(\n",
    "    daily_df: pd.DataFrame,\n",
    "    factors_path: str,\n",
    "    scheme: str,\n",
    "    tc_levels=(0, 5, 10, 20, 40),\n",
    "    portfolio_types=('long_only','short_only','long_short'),\n",
    "    model_filter=None,\n",
    "    window_filter=None,\n",
    "    gross_only=False,            \n",
    "    out_dir='factor_IR_results',\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a CSV containing IR results.\n",
    "    If gross_only=True, only tc=0 is calculated; if False, all tc_levels are included.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    fac = (pd.read_csv(factors_path, parse_dates=['date'])\n",
    "             .set_index('date')\n",
    "             .sort_index())\n",
    "\n",
    "    sub = daily_df[daily_df['scheme'] == scheme].copy()\n",
    "    if model_filter is not None:\n",
    "        sub = sub[sub['model'].isin(model_filter)]\n",
    "    if window_filter is not None:\n",
    "        sub = sub[sub['window'].isin(window_filter)]\n",
    "\n",
    "    tc_iter = (0,) if gross_only else tc_levels\n",
    "    results = []\n",
    "\n",
    "    for (model, win, ptype), g in sub.groupby(['model','window','portfolio_type']):\n",
    "        g = g.sort_values('date').set_index(pd.to_datetime(g['date']))\n",
    "\n",
    "        for tc in tc_iter:\n",
    "            col = 'return' if tc == 0 else f'tc{tc}_return'\n",
    "            if col not in g.columns:\n",
    "                continue\n",
    "            port_ret = g[col]\n",
    "            stats = run_factor_regression(port_ret, fac, use_excess=True)\n",
    "            stats.update({\n",
    "                'scheme'        : scheme,\n",
    "                'model'         : model,\n",
    "                'window'        : win,\n",
    "                'portfolio_type': ptype,\n",
    "                'tc_bps'        : tc,\n",
    "            })\n",
    "            results.append(stats)\n",
    "\n",
    "    df_out = pd.DataFrame(results)[[\n",
    "        'scheme','model','window','portfolio_type','tc_bps','N_obs',\n",
    "        'alpha_daily','alpha_annual','t_alpha',\n",
    "        'IR_daily','IR_annual','R2_zero',\n",
    "        'beta_MKT','t_MKT','beta_SMB','t_SMB',\n",
    "        'beta_HML','t_HML','beta_RMW','t_RMW',\n",
    "        'beta_CMA','t_CMA','beta_UMD','t_UMD'\n",
    "    ]]\n",
    "\n",
    "    tag = 'gross' if gross_only else 'net'\n",
    "    fname = f'5_factor_analysis_{scheme}_{tag}.csv'\n",
    "    df_out.to_csv(os.path.join(out_dir, fname), index=False)\n",
    "    print(f'[Saved] {fname}')\n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "def run_all_factor_tests(vw_csv=\"portfolio_daily_series_VW.csv\",\n",
    "                         ew_csv=\"portfolio_daily_series_EW.csv\",\n",
    "                         factor_csv=\"/Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/5_Factors_Plus_Momentum.csv\",\n",
    "                         save_dir=\"results\",\n",
    "                         y_is_excess=True,\n",
    "                         hac_lags=5,\n",
    "                         save_txt=True):\n",
    "    vw_df = pd.read_csv(vw_csv)\n",
    "    ew_df = pd.read_csv(ew_csv)\n",
    "\n",
    "    vw_gross = batch_factor_analysis(\n",
    "        vw_df, factor_csv, scheme='VW', gross_only=True)\n",
    "    vw_net   = batch_factor_analysis(\n",
    "        vw_df, factor_csv, scheme='VW', gross_only=False)\n",
    "\n",
    "    ew_gross = batch_factor_analysis(\n",
    "        ew_df, factor_csv, scheme='EW', gross_only=True)\n",
    "    ew_net   = batch_factor_analysis(\n",
    "        ew_df, factor_csv, scheme='EW', gross_only=False)\n",
    "\n",
    "    return vw_gross, vw_net, ew_gross, ew_net\n",
    "    \n",
    "\n",
    "vw_gross, vw_net, ew_gross, ew_net = run_all_factor_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish: portfolio_daily_series_VW_with_rf.csv\n",
      "Finish: portfolio_daily_series_EW_with_rf.csv\n"
     ]
    }
   ],
   "source": [
    "# === File paths ===\n",
    "rf_file = \"/Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/CRSP_2016_2024_top50_with_exret.csv\"\n",
    "vw_file = \"portfolio_daily_series_VW.csv\"\n",
    "ew_file = \"portfolio_daily_series_EW.csv\"\n",
    "\n",
    "# === Load risk-free rate data ===\n",
    "\n",
    "rf_df = pd.read_csv(rf_file, usecols=[\"date\", \"rf\"])\n",
    "rf_df[\"date\"] = pd.to_datetime(rf_df[\"date\"])\n",
    "rf_dict = dict(zip(rf_df[\"date\"], rf_df[\"rf\"]))\n",
    "\n",
    "\n",
    "def adjust_returns_with_rf_grouped(file_path, output_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Parse date with flexible format\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format='mixed', dayfirst=True)\n",
    "\n",
    "    # Find all return columns (exclude cumulative)\n",
    "    return_cols = [col for col in df.columns if \"return\" in col and \"cumul\" not in col]\n",
    "\n",
    "    # Set portfolio_type order to avoid groupby sorting issues\n",
    "    order = [\"long_only\", \"short_only\", \"long_short\"]\n",
    "    df[\"portfolio_type\"] = pd.Categorical(df[\"portfolio_type\"], categories=order, ordered=True)\n",
    "\n",
    "    df_list = []\n",
    "    for _, group in df.groupby([\"scheme\", \"model\", \"window\", \"portfolio_type\"], sort=False):\n",
    "        group = group.sort_values(\"date\").copy()\n",
    "        for col in return_cols:\n",
    "            group[col] = group.apply(lambda row: row[col] + rf_dict.get(row[\"date\"], 0), axis=1)\n",
    "            cum_col = col.replace(\"return\", \"cumulative\")\n",
    "            group[cum_col] = np.log1p(group[col]).cumsum()\n",
    "        df_list.append(group)\n",
    "\n",
    "    df_new = pd.concat(df_list).sort_values([\"scheme\", \"model\", \"window\", \"portfolio_type\", \"date\"])\n",
    "    df_new.to_csv(output_path, index=False)\n",
    "    print(f\"Finished: {output_path}\")\n",
    "\n",
    "adjust_returns_with_rf_grouped(vw_file, \"portfolio_daily_series_VW_with_rf.csv\")\n",
    "adjust_returns_with_rf_grouped(ew_file, \"portfolio_daily_series_EW_with_rf.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All figures have been generated and saved to: Baseline_Portfolio/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download S&P500 (2016-2024)\n",
    "sp500 = yf.download(\"^GSPC\", start=\"2016-01-01\", end=\"2024-12-31\")\n",
    "price_col = \"Adj Close\" if \"Adj Close\" in sp500.columns else \"Close\"\n",
    "sp500[\"daily_return\"] = sp500[price_col].pct_change().fillna(0)\n",
    "# Cumulative log return (as in the paper)\n",
    "sp500[\"cum_return\"] = np.cumsum(np.log1p(sp500[\"daily_return\"]))\n",
    "sp500 = sp500[[\"cum_return\"]]\n",
    "sp500.index = pd.to_datetime(sp500.index)\n",
    "\n",
    "# Configuration\n",
    "files = [\n",
    "    (\"VW\", \"portfolio_daily_series_VW_with_rf.csv\"),\n",
    "    (\"EW\", \"portfolio_daily_series_EW_with_rf.csv\")\n",
    "]\n",
    "tc_levels = [0, 5, 10, 20, 40]      # Transaction cost (bps)\n",
    "windows = [5, 21, 252, 512]         # Window sizes\n",
    "strategies = [\"long_only\", \"short_only\", \"long_short\"]\n",
    "\n",
    "output_dir = \"Baseline_Portfolio\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Economic event periods (for shading)\n",
    "crisis_periods = [\n",
    "    (datetime(2018, 6, 1), datetime(2019, 1, 1), \"US-China Trade War\"),\n",
    "    (datetime(2020, 2, 1), datetime(2020, 7, 1), \"COVID-19\"),\n",
    "    (datetime(2022, 2, 1), datetime(2022, 6, 1), \"Russia-Ukraine War\"),\n",
    "    (datetime(2023, 1, 1), datetime(2023, 4, 1), \"US Bank Crisis\"),\n",
    "]\n",
    "\n",
    "def plot_comparison_styled(df, scheme, tc, window):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    model_names = df[\"model\"].unique()\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(model_names)))\n",
    "\n",
    "    offset_step = 0.02\n",
    "\n",
    "    for i, strat in enumerate(strategies, 1):\n",
    "        ax = plt.subplot(3, 1, i)\n",
    "\n",
    "        plt.plot(sp500.index, sp500[\"cum_return\"],\n",
    "                 color=\"black\", lw=2.5, label=\"S&P500 (Total Return)\", zorder=10)\n",
    "\n",
    "        for idx, model_name in enumerate(model_names):\n",
    "            sub = df[(df[\"window\"] == window) &\n",
    "                     (df[\"portfolio_type\"] == strat) &\n",
    "                     (df[\"model\"] == model_name)].sort_values(\"date\")\n",
    "            if sub.empty:\n",
    "                continue\n",
    "\n",
    "            if tc == 0:\n",
    "                ret_col = \"return\"          # Raw excess return\n",
    "            else:\n",
    "                ret_col = f\"tc{tc}_return\"  # Return with transaction cost\n",
    "\n",
    "            if ret_col not in sub.columns:\n",
    "                continue\n",
    "\n",
    "            log_cum = np.cumsum(np.log1p(sub[ret_col].values))\n",
    "\n",
    "            y_shift = idx * offset_step\n",
    "            plt.plot(sub[\"date\"], log_cum + y_shift,\n",
    "                     label=f\"{model_name} ({strat.replace('_',' ').title()})\",\n",
    "                     lw=2, color=colors[idx], alpha=0.9)\n",
    "\n",
    "        for start, end, label in crisis_periods:\n",
    "            ax.axvspan(start, end, color='grey', alpha=0.3)\n",
    "            ax.text(start + pd.Timedelta(days=10),\n",
    "                    ax.get_ylim()[1]*0.92, label, fontsize=8, color='grey')\n",
    "        ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "        ax.set_ylabel(\"Cumulative log return (start = 0)\")\n",
    "        ax.set_title(f\"{scheme} | Window={window} | Strategy={strat} | TC={tc} bps\")\n",
    "        ax.grid(alpha=0.3)\n",
    "        plt.xticks(rotation=30)\n",
    "        plt.legend(bbox_to_anchor=(1.04, 1), loc='upper left', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fname = f\"{scheme}_window{window}_TC{tc}_logreturn_offset.png\"\n",
    "    plt.savefig(os.path.join(output_dir, fname), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Main loop to generate all figures\n",
    "for scheme, file_path in files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    for tc in tc_levels:\n",
    "        for window in windows:\n",
    "            plot_comparison_styled(df, scheme, tc, window)\n",
    "\n",
    "print(f\"All figures have been generated and saved to: {output_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Update] ΔSharpe has been written to portfolio_results_daily_rebalance_VW.csv\n",
      "[Update] ΔSharpe has been written to portfolio_results_daily_rebalance_EW.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load R²_zero from portfolio_metrics.csv\n",
    "metrics_df = pd.read_csv(\"portfolio_metrics.csv\")[[\"Model\", \"Window\", \"R²_zero\"]]\n",
    "metrics_df.rename(columns={\"Model\": \"model\", \"Window\": \"window\"}, inplace=True)\n",
    "\n",
    "# Process VW/EW files\n",
    "for fname in [\"portfolio_results_daily_rebalance_VW.csv\", \"portfolio_results_daily_rebalance_EW.csv\"]:\n",
    "    df = pd.read_csv(fname)\n",
    "\n",
    "    # Merge R²_zero by model and window\n",
    "    df = df.merge(metrics_df, on=[\"model\", \"window\"], how=\"left\")\n",
    "\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        r2 = float(row[\"R²_zero\"]) if not pd.isna(row[\"R²_zero\"]) else 0.0\n",
    "        if row[\"portfolio_type\"] == \"long_only\":\n",
    "            d_sr, sr_star = delta_sharpe(r2, SR_MKT_EX)\n",
    "            row[\"ΔSharpe\"]  = d_sr\n",
    "            row[\"Sharpe*\"]  = sr_star\n",
    "            row[\"baseline\"] = f\"SPX_excess ({SR_MKT_EX:.2f})\"\n",
    "        else:\n",
    "            d_sr, sr_star = delta_sharpe(r2, 0)\n",
    "            row[\"ΔSharpe\"]  = d_sr\n",
    "            row[\"Sharpe*\"]  = sr_star\n",
    "            row[\"baseline\"] = \"cash (0)\"\n",
    "        rows.append(row)\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(fname, index=False)\n",
    "    print(f\"[Update] ΔSharpe has been written to {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/7nbyftys3g77fcp37r3t0_lm0000gn/T/ipykernel_61895/1104344638.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = (df_group.groupby(\"signal_date\", observed=True).apply(_day_ic).dropna())\n",
      "/var/folders/wj/7nbyftys3g77fcp37r3t0_lm0000gn/T/ipykernel_61895/1104344638.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = (df_group.groupby(\"signal_date\", observed=True).apply(_day_ic).dropna())\n",
      "/var/folders/wj/7nbyftys3g77fcp37r3t0_lm0000gn/T/ipykernel_61895/1104344638.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = (df_group.groupby(\"signal_date\", observed=True).apply(_day_ic).dropna())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Overwrote portfolio_metrics.csv with new RankIC )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/7nbyftys3g77fcp37r3t0_lm0000gn/T/ipykernel_61895/1104344638.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = (df_group.groupby(\"signal_date\", observed=True).apply(_day_ic).dropna())\n",
      "/var/folders/wj/7nbyftys3g77fcp37r3t0_lm0000gn/T/ipykernel_61895/1104344638.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(rankic_stats)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "PRED_PATH = \"predictions_daily.csv\"\n",
    "METRICS_PATH = \"portfolio_metrics.csv\"\n",
    "TREAT_CONSTANT_DAY_AS_ZERO = False\n",
    "MIN_DAYS_FOR_STATS = 1\n",
    "\n",
    "def _day_ic(g):\n",
    "    if g[\"y_pred\"].nunique(dropna=True) <= 1 or g[\"y_true\"].nunique(dropna=True) <= 1:\n",
    "        return 0.0 if TREAT_CONSTANT_DAY_AS_ZERO else np.nan\n",
    "    return g[\"y_pred\"].corr(g[\"y_true\"], method=\"spearman\")\n",
    "\n",
    "def rankic_stats(df_group):\n",
    "    ics = (df_group.groupby(\"signal_date\", observed=True).apply(_day_ic).dropna())\n",
    "    n = int(ics.shape[0])\n",
    "    if n < MIN_DAYS_FOR_STATS:\n",
    "        return pd.Series({\"RankIC_mean\": np.nan, \"RankIC_t\": np.nan, \"RankIC_pos%\": np.nan, \"N_days\": n})\n",
    "    mean_ic = float(ics.mean())\n",
    "    std_ic  = float(ics.std(ddof=1))\n",
    "    t_ic    = mean_ic / (std_ic / np.sqrt(n)) if std_ic > 0 else np.nan\n",
    "    pos_pct = float((ics > 0).mean())\n",
    "    return pd.Series({\"RankIC_mean\": mean_ic, \"RankIC_t\": t_ic, \"RankIC_pos%\": pos_pct, \"N_days\": n})\n",
    "\n",
    "# Read data and calculate RankIC\n",
    "pred = pd.read_csv(PRED_PATH)\n",
    "pred[\"signal_date\"] = pd.to_datetime(pred[\"signal_date\"], errors=\"coerce\")\n",
    "pred = pred.dropna(subset=[\"signal_date\", \"y_true\", \"y_pred\", \"model\", \"window\"])\n",
    "pred[\"window\"] = pd.to_numeric(pred[\"window\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "rankic_df = (pred.groupby([\"model\", \"window\"], dropna=False)\n",
    "                .apply(rankic_stats)\n",
    "                .reset_index()\n",
    "                .rename(columns={\"model\":\"Model\",\"window\":\"Window\"}))\n",
    "\n",
    "# Merge: keep new RankIC columns, add _old suffix to original metrics columns\n",
    "metrics = pd.read_csv(METRICS_PATH)\n",
    "metrics[\"Window\"] = pd.to_numeric(metrics[\"Window\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "merged = metrics.merge(rankic_df, on=[\"Model\",\"Window\"], how=\"left\", suffixes=(\"_old\",\"\"))\n",
    "\n",
    "# Drop old columns (with _old suffix)\n",
    "to_drop = [c for c in merged.columns if c.endswith(\"_old\")]\n",
    "merged = merged.drop(columns=to_drop)\n",
    "\n",
    "# Save and overwrite\n",
    "merged.to_csv(METRICS_PATH, index=False)\n",
    "print(\"[OK] Overwrote portfolio_metrics.csv with new RankIC\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-mac)",
   "language": "python",
   "name": "tf-mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
