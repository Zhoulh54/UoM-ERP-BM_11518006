{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc50f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_predictions_static_and_dm_from_csv.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ========= Path configuration =========\n",
    "ROOT = r\"/Users/june/Documents/University of Manchester/Data Science/ERP/Project code/4_Portfolio\"\n",
    "CSV_DIR    = os.path.join(ROOT, \"Predictions_by_window\")\n",
    "OUTPUT_DIR = os.path.join(ROOT, \"DM_from_static_figures_fixed\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(CSV_DIR,    exist_ok=True)\n",
    "\n",
    "# ========= Options =========\n",
    "USE_VALUE_WEIGHT = False   # True: cross-section is value-weighted; False: equal-weighted\n",
    "MIN_TIME_T = 12           # Minimum number of valid trading days to compute DM\n",
    "ALPHA = 0.05\n",
    "ALPHA_STRICT = 0.01\n",
    "NONSIG_ALPHA = 0.70\n",
    "\n",
    "# ========= Possible synonymous column names =========\n",
    "TRUE_CAND   = [\"y_true\",\"true\",\"target\",\"y\",\"label\",\"ret\",\"return\",\"excess_ret\",\"excess_return\"]\n",
    "PRED_CAND   = [\"y_pred\",\"pred\",\"prediction\",\"forecast\",\"yhat\",\"y_hat\",\"pred_mean\",\"preds\"]\n",
    "DATE1_CAND  = [\"signal_date\",\"signaldate\",\"sig_date\"]\n",
    "DATE2_CAND  = [\"ret_date\",\"retdate\",\"date\",\"trddt\"]\n",
    "PERMNO_CAND = [\"permno\",\"PERMNO\",\"id\",\"sid\",\"ticker\"]\n",
    "MCAP_CAND   = [\"market_cap\",\"mktcap\",\"cap\",\"size\"]\n",
    "MODEL_CAND  = [\"model\",\"Model\",\"MODEL\"]\n",
    "WINDOW_CAND = [\"window\",\"win\",\"h\",\"H\"]\n",
    "\n",
    "def _find_col(cols, candidates):\n",
    "    m = {c.lower(): c for c in cols}\n",
    "    for k in candidates:\n",
    "        if k.lower() in m: return m[k.lower()]\n",
    "    return None\n",
    "\n",
    "def _extract_window_from_path(path):\n",
    "    m = re.search(r'window[_\\-\\s]?(\\d+)', path, re.I)\n",
    "    return int(m.group(1)) if m else np.nan\n",
    "\n",
    "# ========= Model name normalization =========\n",
    "def canonical_model_name(name: str) -> str:\n",
    "    raw = str(name).strip()\n",
    "    s = re.sub(r'[\\s_\\-]+',' ', raw).lower()\n",
    "    base = {\n",
    "        'ols':'OLS','ridge':'Ridge','lasso':'Lasso','enet':'Enet','pls':'PLS','pcr':'PCR',\n",
    "        'rf':'RF','random forest':'RF','xgb':'XGB','arima':'ARIMA',\n",
    "        'lstm':'LSTM','nbeats':'NBEATS','autoformer':'Autoformer',\n",
    "        'nn1':'NN1','nn2':'NN2','nn3':'NN3','nn4':'NN4','nn5':'NN5',\n",
    "        'timesfm1.0':'TimesFm1.0','timesfm2.0':'TimesFm2.0','timesfm1':'TimesFm1.0','timesfm2':'TimesFm2.0'\n",
    "    }\n",
    "    if s in base: return base[s]\n",
    "    if 'random' in s and 'forest' in s: return 'RF'\n",
    "    if 'xgb' in s or 'xgboost' in s: return 'XGB'\n",
    "    if 'chronos' in s:\n",
    "        if 'tiny' in s:  return 'Chronos-Tiny'\n",
    "        if 'mini' in s:  return 'Chronos-Mini'\n",
    "        if 'small' in s: return 'Chronos-Small'\n",
    "        if 'base' in s:  return 'Chronos-Base'\n",
    "        if 'large' in s: return 'Chronos-Large'\n",
    "        return 'Chronos-Base'\n",
    "    if 'moirai' in s or 'uni2ts' in s or s.startswith('units'):\n",
    "        if 'small' in s: return 'Uni2ts-Small'\n",
    "        if 'base'  in s: return 'Uni2ts-Base'\n",
    "        if 'large' in s: return 'Uni2ts-Large'\n",
    "        return 'Uni2ts-Base'\n",
    "    if 'timesfm' in s:\n",
    "        return 'TimesFm2.0' if '2' in s else 'TimesFm1.0'\n",
    "    m = re.match(r'(nn)\\s*(\\d+)', s)\n",
    "    if m: return f\"NN{m.group(2)}\"\n",
    "    return raw\n",
    "\n",
    "# ========= Aggregate predictions_daily.csv =========\n",
    "def collect_predictions(root: str) -> pd.DataFrame:\n",
    "    files = []\n",
    "    for r, _, fs in os.walk(root):\n",
    "        for f in fs:\n",
    "            if f.lower() == \"predictions_daily.csv\":\n",
    "                files.append(os.path.join(r, f))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\"No predictions_daily.csv found.\")\n",
    "\n",
    "    rows = []\n",
    "    for p in sorted(files):\n",
    "        try:\n",
    "            df = pd.read_csv(p)\n",
    "        except Exception:\n",
    "            df = pd.read_csv(p, sep=';')\n",
    "\n",
    "        col_true = _find_col(df.columns, TRUE_CAND)\n",
    "        col_pred = _find_col(df.columns, PRED_CAND)\n",
    "        if col_true is None or col_pred is None:\n",
    "            print(f\"[SKIP] Missing y_true/y_pred -> {p}\")\n",
    "            continue\n",
    "\n",
    "        col_perm = _find_col(df.columns, PERMNO_CAND)\n",
    "        col_mdl  = _find_col(df.columns, MODEL_CAND)\n",
    "        col_win  = _find_col(df.columns, WINDOW_CAND)\n",
    "        col_sig  = _find_col(df.columns, DATE1_CAND)\n",
    "        col_ret  = _find_col(df.columns, DATE2_CAND)\n",
    "        col_mcap = _find_col(df.columns, MCAP_CAND)\n",
    "\n",
    "        tmp = pd.DataFrame({\n",
    "            \"signal_date\": df[col_sig] if col_sig else pd.NaT,\n",
    "            \"ret_date\":    df[col_ret] if col_ret else pd.NaT,\n",
    "            \"permno\":      df[col_perm] if col_perm else np.nan,\n",
    "            \"y_true\":      df[col_true],\n",
    "            \"y_pred\":      df[col_pred],\n",
    "            \"market_cap\":  df[col_mcap] if col_mcap else np.nan,\n",
    "            \"model\":       df[col_mdl]  if col_mdl  else os.path.basename(os.path.dirname(p)),\n",
    "            \"window\":      df[col_win]  if col_win  else _extract_window_from_path(p)\n",
    "        })\n",
    "\n",
    "        tmp[\"model\"]  = tmp[\"model\"].map(canonical_model_name)\n",
    "        tmp[\"window\"] = pd.to_numeric(tmp[\"window\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        rows.append(tmp)\n",
    "\n",
    "    all_df = pd.concat(rows, ignore_index=True)\n",
    "    all_df = all_df.dropna(subset=[\"y_true\",\"y_pred\",\"model\",\"window\"], how=\"any\")\n",
    "\n",
    "    for c in [\"signal_date\",\"ret_date\"]:\n",
    "        if c in all_df.columns:\n",
    "            try: all_df[c] = pd.to_datetime(all_df[c], errors=\"coerce\")\n",
    "            except: pass\n",
    "    return all_df\n",
    "\n",
    "# ========= Split CSV by window =========\n",
    "def export_csv_by_window(df_all: pd.DataFrame, out_dir: str):\n",
    "    df = df_all.copy()\n",
    "    df[\"window\"] = pd.to_numeric(df[\"window\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"window\"])\n",
    "    df[\"window\"] = df[\"window\"].astype(int)\n",
    "\n",
    "    need_cols = [\"signal_date\",\"ret_date\",\"permno\",\"y_true\",\"y_pred\",\"market_cap\",\"model\",\"window\"]\n",
    "    for c in need_cols:\n",
    "        if c not in df.columns: df[c] = pd.NA\n",
    "    df = df[need_cols]\n",
    "\n",
    "    for c in [\"signal_date\",\"ret_date\"]:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    wins = sorted(df[\"window\"].unique().tolist())\n",
    "    print(\"[DEBUG] windows detected:\", wins)\n",
    "\n",
    "    paths = {}\n",
    "    for w, sub in df.groupby(\"window\", sort=True):\n",
    "        out_path = os.path.join(out_dir, f\"predictions_window{int(w)}.csv\")\n",
    "        sub.to_csv(out_path, index=False)\n",
    "        paths[int(w)] = out_path\n",
    "        print(f\"[OK] write {out_path} rows={len(sub)}\")\n",
    "    return paths\n",
    "\n",
    "# ========= Main process =========\n",
    "if __name__ == \"__main__\":\n",
    "    all_pred = collect_predictions(ROOT)\n",
    "    window_csv_map = export_csv_by_window(all_pred, CSV_DIR)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    from scipy import stats\n",
    "    from statsmodels.tsa.stattools import acovf\n",
    "\n",
    "    WINDOWS = sorted(window_csv_map.keys())\n",
    "\n",
    "    DESIRED_ORDER = [\n",
    "        \"OLS\",\"Ridge\",\"Lasso\",\"Enet\",\"PCR\",\"PLS\",\n",
    "        \"RF\",\"XGB\",\n",
    "        \"NN1\",\"NN2\",\"NN3\",\"NN4\",\"NN5\",\n",
    "        \"LSTM\",\"NBEATS\",\"Autoformer\",\n",
    "        \"Chronos-T5 (Tiny)\",\"Chronos-T5 (Mini)\",\"Chronos-T5 (Small)\",\"Chronos-T5 (Base)\",\"Chronos-T5 (Large)\",\n",
    "        \"TimesFm1.0\",\"TimesFm2.0\",\n",
    "        \"Moirai-1.1-R (Small)\",\"Moirai-1.1-R (Base)\",\"Moirai-1.1-R (Large)\"\n",
    "    ]\n",
    "    DISPLAY_MAP = {\n",
    "        \"Chronos-Tiny\":\"Chronos-T5 (Tiny)\",\"Chronos-Mini\":\"Chronos-T5 (Mini)\",\n",
    "        \"Chronos-Small\":\"Chronos-T5 (Small)\",\"Chronos-Base\":\"Chronos-T5 (Base)\",\"Chronos-Large\":\"Chronos-T5 (Large)\",\n",
    "        \"Uni2ts-Small\":\"Moirai-1.1-R (Small)\",\"Uni2ts-Base\":\"Moirai-1.1-R (Base)\",\"Uni2ts-Large\":\"Moirai-1.1-R (Large)\"\n",
    "    }\n",
    "    def display_name(x): return DISPLAY_MAP.get(x, x)\n",
    "    def normalize_key(s): return re.sub(r\"[^0-9a-z]\",\"\", str(s).lower())\n",
    "    def sort_models_by_desired(model_list):\n",
    "        remaining = list(dict.fromkeys(model_list))\n",
    "        ordered = []\n",
    "        norm_remaining = {m: normalize_key(m) for m in remaining}\n",
    "        for target in DESIRED_ORDER:\n",
    "            tnorm = normalize_key(target)\n",
    "            matched = [m for m, mn in norm_remaining.items() if tnorm in mn or mn in tnorm]\n",
    "            for m in matched:\n",
    "                if m in remaining:\n",
    "                    ordered.append(m)\n",
    "                    remaining.remove(m)\n",
    "                    norm_remaining.pop(m, None)\n",
    "        ordered += sorted(remaining)\n",
    "        return ordered\n",
    "\n",
    "    # ---- NW helper: bandwidth and variance (for time series) ----\n",
    "    def nw_bandwidth(T: int) -> int:\n",
    "        # Common Bartlett rule; you can also fix to 6 or use other data-driven rules\n",
    "        return int(np.floor(4.0 * (T/100.0)**(2.0/9.0))) if T > 1 else 0\n",
    "\n",
    "    def nw_var_of_mean_ts(series: pd.Series) -> float:\n",
    "        x = np.asarray(series.values, dtype=float)\n",
    "        T = len(x)\n",
    "        if T <= 1:\n",
    "            return np.nan\n",
    "        L = max(1, nw_bandwidth(T))\n",
    "        ac = acovf(x, fft=False, demean=True)\n",
    "        s = ac[0]\n",
    "        for k in range(1, min(L+1, T)):\n",
    "            w = 1.0 - k / float(L+1)\n",
    "            s += 2.0 * w * ac[k]\n",
    "        return s / T\n",
    "\n",
    "    # ---- Cross-sectional mean difference by date (equal-weighted / value-weighted) ----\n",
    "    def cs_mean_diff_by_date(values_diff: np.ndarray, dates: np.ndarray, weights: np.ndarray | None):\n",
    "        df = pd.DataFrame({\"date\": pd.to_datetime(dates), \"d\": values_diff})\n",
    "        if USE_VALUE_WEIGHT and weights is not None:\n",
    "            df[\"w\"] = weights\n",
    "            g = (df.dropna(subset=[\"d\",\"w\"])\n",
    "                   .query(\"w > 0\")\n",
    "                   .groupby(\"date\")\n",
    "                   .apply(lambda s: np.average(s[\"d\"].values, weights=s[\"w\"].values))\n",
    "                 )\n",
    "            return g.sort_index()\n",
    "        else:\n",
    "            return df.dropna(subset=[\"d\"]).groupby(\"date\")[\"d\"].mean().sort_index()\n",
    "\n",
    "    per_win_df = {}\n",
    "    for w in WINDOWS:\n",
    "        p = window_csv_map[w]\n",
    "        try:\n",
    "            df = pd.read_csv(p)\n",
    "        except Exception:\n",
    "            df = pd.read_csv(p, sep=';')\n",
    "        per_win_df[w] = df\n",
    "        print(f\"[DEBUG] load {p} rows={len(df)}\")\n",
    "\n",
    "    # ---- For each window: align -> DM (MSE/DA) time series NW -> McNemar ----\n",
    "    results = {}\n",
    "    for w in WINDOWS:\n",
    "        df = per_win_df.get(int(w))\n",
    "        if df is None or df.empty:\n",
    "            print(f\"[SKIP] window{w} has no data.\")\n",
    "            continue\n",
    "\n",
    "        need = [\"ret_date\",\"permno\",\"y_true\",\"y_pred\",\"model\",\"market_cap\"]\n",
    "        miss = [c for c in need if c not in df.columns]\n",
    "        if any(m not in df.columns for m in [\"ret_date\",\"permno\",\"y_true\",\"y_pred\",\"model\"]):\n",
    "            raise ValueError(f\"window{w} missing core columns.\")\n",
    "\n",
    "        d = df[need].copy()\n",
    "        d[\"Model\"] = d[\"model\"].astype(str).map(display_name)\n",
    "        d[\"ret_date\"] = pd.to_datetime(d[\"ret_date\"], errors=\"coerce\")\n",
    "        d = d.dropna(subset=[\"ret_date\",\"permno\",\"y_true\",\"y_pred\"])\n",
    "        d[\"market_cap\"] = pd.to_numeric(d[\"market_cap\"], errors=\"coerce\")\n",
    "\n",
    "        keys = [\"ret_date\",\"permno\"]\n",
    "        pivot_pred = d.pivot_table(index=keys, columns=\"Model\", values=\"y_pred\", aggfunc=\"last\").sort_index()\n",
    "        aligned = (d.drop_duplicates(keys)\n",
    "                    .set_index(keys)\n",
    "                    .reindex(pivot_pred.index))\n",
    "        y_true_aligned = aligned[\"y_true\"].astype(float).values\n",
    "        mcap_aligned   = aligned[\"market_cap\"].astype(float).values\n",
    "\n",
    "        model_names = sort_models_by_desired([c for c in pivot_pred.columns])\n",
    "\n",
    "        ytrue = y_true_aligned.astype(float)\n",
    "        valid_true = np.isfinite(ytrue)\n",
    "        pred_mat  = {m: pivot_pred[m].astype(float).values for m in model_names}\n",
    "        valid_mat = {m: valid_true & np.isfinite(pred_mat[m]) for m in model_names}\n",
    "\n",
    "        dm_stats_mse = pd.DataFrame(np.nan, index=model_names, columns=model_names)\n",
    "        dm_pvals_mse = pd.DataFrame(np.nan, index=model_names, columns=model_names)\n",
    "        dm_stats_da  = pd.DataFrame(np.nan, index=model_names, columns=model_names)\n",
    "        dm_pvals_da  = pd.DataFrame(np.nan, index=model_names, columns=model_names)\n",
    "        mcn_std      = pd.DataFrame(np.nan, index=model_names, columns=model_names)\n",
    "        mcn_pval     = pd.DataFrame(np.nan, index=model_names, columns=model_names)\n",
    "\n",
    "        rows_mse, rows_da = [], []\n",
    "\n",
    "        idx = pivot_pred.index\n",
    "        dates_full = np.array([ix[0] for ix in idx])\n",
    "\n",
    "        for i, mi in enumerate(model_names):\n",
    "            for j, mj in enumerate(model_names):\n",
    "                if mi == mj: continue\n",
    "                mask = valid_mat[mi] & valid_mat[mj]\n",
    "                if mask.sum() < 5:\n",
    "                    continue\n",
    "\n",
    "                yi = pred_mat[mi][mask]\n",
    "                yj = pred_mat[mj][mask]\n",
    "                yt = ytrue[mask]\n",
    "                dd = dates_full[mask]\n",
    "                ww = mcap_aligned[mask] if USE_VALUE_WEIGHT else None\n",
    "\n",
    "                d_loss = (yt - yi)**2 - (yt - yj)**2\n",
    "                d_ts = cs_mean_diff_by_date(d_loss, dd, ww)\n",
    "                Tts = len(d_ts)\n",
    "                if Tts >= MIN_TIME_T:\n",
    "                    var_mean = nw_var_of_mean_ts(d_ts)\n",
    "                    if not np.isfinite(var_mean) or var_mean <= 0:\n",
    "                        var_mean = d_ts.var(ddof=1) / max(Tts,1)\n",
    "                    DMm = float(d_ts.mean() / np.sqrt(var_mean))\n",
    "                    pmm = float(2.0 * stats.norm.sf(abs(DMm)))\n",
    "                else:\n",
    "                    DMm, pmm = np.nan, np.nan\n",
    "\n",
    "                dm_stats_mse.loc[mi, mj] = DMm\n",
    "                dm_pvals_mse.loc[mi, mj] = pmm\n",
    "                rows_mse.append({\n",
    "                    \"ModelA\": mi, \"ModelB\": mj, \"window\": int(w),\n",
    "                    \"N_time\": Tts, \"DM\": DMm, \"pval\": pmm,\n",
    "                    \"winner\": (\n",
    "                        mi if (pd.notna(pmm) and pmm < ALPHA and DMm < 0)\n",
    "                        else (mj if (pd.notna(pmm) and pmm < ALPHA and DMm > 0) else \"NoSig\")\n",
    "                    )\n",
    "                })\n",
    "\n",
    "                corr_i = (np.sign(yi) == np.sign(yt)).astype(float)\n",
    "                corr_j = (np.sign(yj) == np.sign(yt)).astype(float)\n",
    "                d_da = (1.0 - corr_i) - (1.0 - corr_j)\n",
    "                d_da_ts = cs_mean_diff_by_date(d_da, dd, ww)\n",
    "                Tts2 = len(d_da_ts)\n",
    "                if Tts2 >= MIN_TIME_T:\n",
    "                    var_mean_da = nw_var_of_mean_ts(d_da_ts)\n",
    "                    if not np.isfinite(var_mean_da) or var_mean_da <= 0:\n",
    "                        var_mean_da = d_da_ts.var(ddof=1) / max(Tts2,1)\n",
    "                    DMd = float(d_da_ts.mean() / np.sqrt(var_mean_da))\n",
    "                    pmd = float(2.0 * stats.norm.sf(abs(DMd)))\n",
    "                else:\n",
    "                    DMd, pmd = np.nan, np.nan\n",
    "\n",
    "                dm_stats_da.loc[mi, mj] = DMd\n",
    "                dm_pvals_da.loc[mi, mj] = pmd\n",
    "\n",
    "                onlyA = int(np.sum((corr_i == 1) & (corr_j == 0)))\n",
    "                onlyB = int(np.sum((corr_i == 0) & (corr_j == 1)))\n",
    "                n = onlyA + onlyB\n",
    "                if n > 0:\n",
    "                    bc = onlyA - onlyB\n",
    "                    z  = bc / np.sqrt(n)\n",
    "                    try:\n",
    "                        p_mc = stats.binomtest(min(onlyA, onlyB), n=n).pvalue\n",
    "                    except AttributeError:\n",
    "                        p_mc = stats.binom_test(min(onlyA, onlyB), n=n, p=0.5)\n",
    "                    mcn_std.loc[mi, mj]  = z\n",
    "                    mcn_pval.loc[mi, mj] = p_mc\n",
    "\n",
    "                rows_da.append({\n",
    "                    \"ModelA\": mi, \"ModelB\": mj, \"window\": int(w),\n",
    "                    \"N_time\": Tts2, \"DM\": DMd, \"pval\": pmd,\n",
    "                    \"winner\": (\n",
    "                        mi if (pd.notna(pmd) and pmd < ALPHA and DMd < 0)\n",
    "                        else (mj if (pd.notna(pmd) and pmd < ALPHA and DMd > 0) else \"NoSig\")\n",
    "                    ),\n",
    "                    \"mcnemar_onlyA\": onlyA, \"mcnemar_onlyB\": onlyB,\n",
    "                    \"mcnemar_bc\": (onlyA - onlyB) if n>0 else np.nan,\n",
    "                    \"mcnemar_z\": z if n>0 else np.nan,\n",
    "                    \"mcnemar_pval\": p_mc if n>0 else np.nan\n",
    "                })\n",
    "\n",
    "        pd.DataFrame(rows_mse)[[\"ModelA\",\"ModelB\",\"window\",\"N_time\",\"DM\",\"pval\",\"winner\"]].to_csv(\n",
    "            os.path.join(OUTPUT_DIR, f\"DM_summary_mse_w{w}.csv\"), index=False)\n",
    "        pd.DataFrame(rows_da)[[\"ModelA\",\"ModelB\",\"window\",\"N_time\",\"DM\",\"pval\",\"winner\",\n",
    "                               \"mcnemar_onlyA\",\"mcnemar_onlyB\",\"mcnemar_bc\",\"mcnemar_z\",\"mcnemar_pval\"]].to_csv(\n",
    "            os.path.join(OUTPUT_DIR, f\"DM_summary_da_w{w}.csv\"), index=False)\n",
    "\n",
    "        results[int(w)] = dict(\n",
    "            dm_stats_mse=dm_stats_mse, dm_pvals_mse=dm_pvals_mse,\n",
    "            dm_stats_da=dm_stats_da,   dm_pvals_da=dm_pvals_da,\n",
    "            mcnemar_std=mcn_std,       mcnemar_pval=mcn_pval,\n",
    "            models=dm_stats_mse.index.tolist()\n",
    "        )\n",
    "\n",
    "    # ---- Plotting: non-significant cells gray + asterisks ----\n",
    "    def _draw_heat(ax, arr, labels, pvals_df, vmax, title=None,\n",
    "                   alpha=NONSIG_ALPHA, alpha_lo=ALPHA, alpha_hi=ALPHA_STRICT):\n",
    "        im = ax.imshow(arr, cmap='bwr', vmin=-vmax, vmax=vmax, aspect='auto', interpolation='nearest')\n",
    "        n = arr.shape[0]\n",
    "        ax.set_xticks(range(n)); ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(labels, rotation=90, fontsize=8)\n",
    "        ax.set_yticklabels(labels, fontsize=8)\n",
    "\n",
    "        for (i, j), v in np.ndenumerate(arr):\n",
    "            try:\n",
    "                p = pvals_df.iat[i, j]\n",
    "            except Exception:\n",
    "                p = np.nan\n",
    "            if pd.notna(p) and p <= alpha_lo and np.isfinite(v):\n",
    "                ax.text(j, i, f\"{v:.2f}\", ha=\"center\", va=\"center\", fontsize=6.2, zorder=3)\n",
    "                star = \"**\" if p <= alpha_hi else \"*\"\n",
    "                ax.text(j + 0.46, i - 0.46, star, ha=\"right\", va=\"top\",\n",
    "                        fontsize=6.6, fontweight=\"bold\", color=\"black\", zorder=4)\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                try:\n",
    "                    p = pvals_df.iat[i, j]\n",
    "                except Exception:\n",
    "                    p = np.nan\n",
    "                if not (pd.notna(p) and p <= alpha_lo):\n",
    "                    rect = mpatches.Rectangle((j-0.5, i-0.5), 1, 1,\n",
    "                                              facecolor=\"lightgray\", edgecolor=None,\n",
    "                                              alpha=alpha, zorder=2)\n",
    "                    ax.add_patch(rect)\n",
    "        if title: ax.set_title(title, fontsize=10)\n",
    "        return im\n",
    "\n",
    "    def _vmax(*mats):\n",
    "        vmax = 0.0\n",
    "        for a in mats:\n",
    "            if a is None: continue\n",
    "            m = np.nanmax(np.abs(a))\n",
    "            if np.isfinite(m): vmax = max(vmax, m)\n",
    "        return vmax or 1.0\n",
    "\n",
    "    def save_per_window_plots():\n",
    "        for w, r in results.items():\n",
    "            labels = r[\"dm_stats_mse\"].index.tolist()\n",
    "            arr1 = r[\"dm_stats_mse\"].values.astype(float)\n",
    "            arr2 = r[\"dm_stats_da\"].values.astype(float)\n",
    "            arr3 = (-r[\"mcnemar_std\"].values.astype(float))\n",
    "            v1 = _vmax(arr1); v2 = _vmax(arr2); v3 = _vmax(arr3)\n",
    "\n",
    "            for (arr, pv, ttl, fn, vmax_) in [\n",
    "                (arr1, r[\"dm_pvals_mse\"], f\"DM (MSE) w={w}  (negative = row is better; * p≤0.05, ** p≤0.01)\",  f\"DM_signed_MSE_w{w}.png\", v1),\n",
    "                (arr2, r[\"dm_pvals_da\"],  f\"DM (DA)  w={w}  (negative = row is better; * p≤0.05, ** p≤0.01)\",  f\"DM_signed_DA_w{w}.png\",  v2),\n",
    "                (arr3, r[\"mcnemar_pval\"], f\"McNemar Test w={w}  (negative = row is better; * p≤0.05, ** p≤0.01)\", f\"McNemar_std_w{w}.png\", v3),\n",
    "            ]:\n",
    "                fig, ax = plt.subplots(figsize=(max(8, len(labels)*0.38), max(6, len(labels)*0.34)))\n",
    "                im = _draw_heat(ax, arr, labels, pv, vmax_, title=ttl)\n",
    "                cbar = fig.colorbar(mappable=im, ax=ax, fraction=0.05)\n",
    "                cbar.ax.set_ylabel(\"Value\", rotation=270, labelpad=12)\n",
    "                out = os.path.join(OUTPUT_DIR, fn)\n",
    "                fig.savefig(out, dpi=200, bbox_inches=\"tight\")\n",
    "                plt.close(fig)\n",
    "                print(\"Saved:\", out)\n",
    "\n",
    "    def save_2x2_composites():\n",
    "        if len(results) < 4:\n",
    "            print(\"Not all windows present; skip 2x2 composites.\")\n",
    "            return\n",
    "        wins = sorted(results.keys())\n",
    "        labels = results[wins[0]][\"dm_stats_mse\"].index.tolist()\n",
    "\n",
    "        def grid_for(metric_key, title, fname, is_mcnemar=False):\n",
    "            if is_mcnemar:\n",
    "                mats = [(-results[w][\"mcnemar_std\"].reindex(index=labels, columns=labels).values.astype(float)) for w in wins]\n",
    "                pvals = [results[w][\"mcnemar_pval\"].reindex(index=labels, columns=labels) for w in wins]\n",
    "            else:\n",
    "                mats = [results[w][metric_key].reindex(index=labels, columns=labels).values.astype(float) for w in wins]\n",
    "                pkey = metric_key.replace(\"dm_stats\", \"dm_pvals\", 1)\n",
    "                pvals = [results[w][pkey].reindex(index=labels, columns=labels) for w in wins]\n",
    "\n",
    "            vmax = _vmax(*mats)\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(18, 14), constrained_layout=True)\n",
    "            ims = []\n",
    "            for ax, arr, pv, ww in zip(axes.ravel(), mats, pvals, wins):\n",
    "                im = _draw_heat(ax, arr, labels, pv, vmax, title=f\"w={ww}\")\n",
    "                ims.append(im)\n",
    "            cbar = fig.colorbar(mappable=ims[0], ax=axes.ravel().tolist(), fraction=0.02, pad=0.02)\n",
    "            cbar.ax.set_ylabel(\"Value\", rotation=270, labelpad=12)\n",
    "            fig.suptitle(title, fontsize=14)\n",
    "            out = os.path.join(OUTPUT_DIR, fname)\n",
    "            fig.savefig(out, dpi=220, bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "            print(\"Saved 2x2:\", out)\n",
    "\n",
    "        grid_for(\"dm_stats_mse\", \"DM (MSE) across windows  (negative = row is better; * p≤0.05, ** p≤0.01)\", \"DM_MSE_2x2.png\")\n",
    "        grid_for(\"dm_stats_da\",  \"DM (DA)  across windows  (negative = row is better; * p≤0.05, ** p≤0.01)\", \"DM_DA_2x2.png\")\n",
    "        grid_for(None,           \"McNemar Test across windows  (negative = row is better; * p≤0.05, ** p≤0.01)\", \"McNemar_std_2x2.png\", is_mcnemar=True)\n",
    "\n",
    "    save_per_window_plots()\n",
    "    save_2x2_composites()\n",
    "    print(\"All done. CSVs at:\", CSV_DIR, \"| Figures at:\", OUTPUT_DIR,\n",
    "          \"| Weighted:\", \"Value-weighted\" if USE_VALUE_WEIGHT else \"Equal-weighted\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
