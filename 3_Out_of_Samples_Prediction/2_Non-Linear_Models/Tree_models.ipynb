{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.16.1)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# ========== Basic Libraries ==========\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# ========== Models and Preprocessing ==========\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ========== Evaluation Metrics ==========\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    ")\n",
    "\n",
    "# ========== Visualization and Hyperparameter Tuning ==========\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "! pip install optuna\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ========== Global Configuration ==========\n",
    "np.random.seed(42)\n",
    "plt.rcdefaults()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. Data Loading ==========\n",
    "def load_datasets(npz_path=\"/Users/june/Documents/University of Manchester/Data Science/ERP/Project code/1_Data_Preprocessing/all_window_datasets.npz\"):\n",
    "    \"\"\"Load dataset from npz file\"\"\"\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    datasets = {}\n",
    "    for key in data.files:\n",
    "        datasets[key] = data[key]\n",
    "    return datasets\n",
    "\n",
    "# ========== 2. Evaluation Metrics ==========\n",
    "def r2_zero(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute zero-based R² (baseline is 0)\n",
    "    y_true: true values (N,)\n",
    "    y_pred: predicted values (N,)\n",
    "    \"\"\"\n",
    "    rss = np.sum((y_true - y_pred)**2)  \n",
    "    tss = np.sum(y_true**2)            \n",
    "    return 1 - rss / tss\n",
    "\n",
    "def calc_directional_metrics(y_true, y_pred, permnos=None):\n",
    "    \"\"\"\n",
    "    Calculate sign prediction accuracy and up/down accuracy.\n",
    "    If permnos is provided, compute metrics per group and average.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    if permnos is None:\n",
    "        s_true = np.sign(y_true)\n",
    "        s_pred = np.sign(y_pred)\n",
    "        mask = s_true != 0\n",
    "        s_true = s_true[mask]\n",
    "        s_pred = s_pred[mask]\n",
    "\n",
    "        overall_acc = np.mean(s_true == s_pred)\n",
    "\n",
    "        up_mask = s_true > 0\n",
    "        down_mask = s_true < 0\n",
    "        up_acc = np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else 0\n",
    "        down_acc = np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else 0\n",
    "\n",
    "    else:\n",
    "        df = pd.DataFrame({\"permno\": permnos, \"yt\": y_true, \"yp\": y_pred})\n",
    "        overall_accs = []\n",
    "        up_accs = []\n",
    "        down_accs = []\n",
    "\n",
    "        for _, g in df.groupby(\"permno\"):\n",
    "            s_true = np.sign(g[\"yt\"].values)\n",
    "            s_pred = np.sign(g[\"yp\"].values)\n",
    "            mask = s_true != 0\n",
    "            s_true = s_true[mask]\n",
    "            s_pred = s_pred[mask]\n",
    "            if len(s_true) == 0:\n",
    "                continue\n",
    "            overall_accs.append(np.mean(s_true == s_pred))\n",
    "\n",
    "            up_mask = s_true > 0\n",
    "            down_mask = s_true < 0\n",
    "            up_accs.append(np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else np.nan)\n",
    "            down_accs.append(np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else np.nan)\n",
    "\n",
    "        overall_acc = np.nanmean(overall_accs)\n",
    "        up_acc = np.nanmean(up_accs)\n",
    "        down_acc = np.nanmean(down_accs)\n",
    "\n",
    "    return overall_acc, up_acc, down_acc\n",
    "\n",
    "def regression_metrics(y_true, y_pred, k, meta=None, permnos=None):\n",
    "    \"\"\"\n",
    "    Compute regression metrics and directional accuracy.\n",
    "    If meta is provided and contains MKTCAP_PERCENTILE, also compute metrics for top and bottom market cap groups.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    n = len(y_true)\n",
    "\n",
    "    r2 = r2_zero(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    dir_acc, up_acc, down_acc = calc_directional_metrics(y_true, y_pred, permnos)\n",
    "\n",
    "    metrics = {\n",
    "        \"R2_zero\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"Directional Accuracy\": dir_acc,\n",
    "        \"Up_Directional_Acc\": up_acc,\n",
    "        \"Down_Directional_Acc\": down_acc\n",
    "    }\n",
    "\n",
    "    if meta is not None and \"MKTCAP_PERCENTILE\" in meta:\n",
    "        top_mask = meta[\"MKTCAP_PERCENTILE\"] >= 0.75\n",
    "        bottom_mask = meta[\"MKTCAP_PERCENTILE\"] <= 0.25\n",
    "\n",
    "        if np.any(top_mask):\n",
    "            yt_top = y_true[top_mask]\n",
    "            yp_top = y_pred[top_mask]\n",
    "            perm_top = permnos[top_mask] if permnos is not None else None\n",
    "            r2_top = r2_zero(yt_top, yp_top)\n",
    "            rmse_top = np.sqrt(mean_squared_error(yt_top, yp_top))\n",
    "            mae_top = mean_absolute_error(yt_top, yp_top)\n",
    "            mse_top = mean_squared_error(yt_top, yp_top)\n",
    "            dir_top, up_top, down_top = calc_directional_metrics(yt_top, yp_top, perm_top)\n",
    "            metrics.update({\n",
    "                \"Top25_R2_zero\": r2_top,\n",
    "                \"Top25_RMSE\": rmse_top,\n",
    "                \"Top25_MAE\": mae_top,\n",
    "                \"Top25_MSE\": mse_top,\n",
    "                \"Top25_Dir_Acc\": dir_top,\n",
    "                \"Top25_Up_Acc\": up_top,\n",
    "                \"Top25_Down_Acc\": down_top\n",
    "            })\n",
    "\n",
    "        if np.any(bottom_mask):\n",
    "            yt_bot = y_true[bottom_mask]\n",
    "            yp_bot = y_pred[bottom_mask]\n",
    "            perm_bot = permnos[bottom_mask] if permnos is not None else None\n",
    "            r2_bot = r2_zero(yt_bot, yp_bot)\n",
    "            rmse_bot = np.sqrt(mean_squared_error(yt_bot, yp_bot))\n",
    "            mae_bot = mean_absolute_error(yt_bot, yp_bot)\n",
    "            mse_bot = mean_squared_error(yt_bot, yp_bot)\n",
    "            dir_bot, up_bot, down_bot = calc_directional_metrics(yt_bot, yp_bot, perm_bot)\n",
    "            metrics.update({\n",
    "                \"Bottom25_R2_zero\": r2_bot,\n",
    "                \"Bottom25_RMSE\": rmse_bot,\n",
    "                \"Bottom25_MAE\": mae_bot,\n",
    "                \"Bottom25_MSE\": mse_bot,\n",
    "                \"Bottom25_Dir_Acc\": dir_bot,\n",
    "                \"Bottom25_Up_Acc\": up_bot,\n",
    "                \"Bottom25_Down_Acc\": down_bot\n",
    "            })\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 3. Save Model and Metrics ==========\n",
    "def save_model(model, name, window, path=\"models/\"):\n",
    "    \"\"\"Save model\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    joblib.dump(model, os.path.join(path, f\"{name}_w{window}.joblib\"))\n",
    "\n",
    "def save_metrics(metrics_dict, name, window, path=\"results.csv\"):\n",
    "    \"\"\"Save evaluation metrics\"\"\"\n",
    "    row = pd.DataFrame([metrics_dict])\n",
    "    row.insert(0, \"Model\", name)\n",
    "    row.insert(1, \"Window\", window)\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[~((df[\"Model\"] == name) & (df[\"Window\"] == window))]\n",
    "        df = pd.concat([df, row], ignore_index=True)\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"[Update] Metrics updated for {name} w={window}\")\n",
    "    else:\n",
    "        row.to_csv(path, index=False)\n",
    "        print(f\"[Create] New metrics file created with {name} w={window}\")\n",
    "\n",
    "def save_predictions(model_name, window_size, y_true, y_pred, permnos, path=\"predictions/\"):\n",
    "    \"\"\"Save prediction results\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"PERMNO\": permnos,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred\n",
    "    })\n",
    "\n",
    "    filename = f\"{model_name}_w{window_size}.csv\"\n",
    "    df.to_csv(os.path.join(path, filename), index=False)\n",
    "    print(f\"[Save] {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 4. Model Hyperparameter Tuning ==========\n",
    "TUNED_MODELS = {\"RF\", \"XGB\"}\n",
    "\n",
    "\n",
    "def tune_model_with_optuna(model_name, X, y, permnos=None, n_trials=30):\n",
    "    \"\"\"Use Optuna for hyperparameter tuning - MSE as objective (suitable for portfolio construction)\"\"\"\n",
    "    if model_name not in TUNED_MODELS:\n",
    "        print(f\"[Skip] {model_name} is not a tunable model. Skipped tuning.\")\n",
    "        return None\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    def objective(trial):\n",
    "        try:\n",
    "            if model_name == \"RF\":\n",
    "                params = {\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "                    'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "                    'min_samples_split': trial.suggest_int('min_samples_split', 2, 8),\n",
    "                    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "                    'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "                }\n",
    "                model = RandomForestRegressor(**params, random_state=42, n_jobs=-1)\n",
    "\n",
    "            elif model_name == \"XGB\":\n",
    "                params = {\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "                    'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "                    'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "                    'min_child_weight': trial.suggest_int('min_child_weight', 1, 6),\n",
    "                    'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 0.1, log=True),\n",
    "                    'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 0.1, log=True),\n",
    "                }\n",
    "                model = XGBRegressor(**params, random_state=42, n_jobs=-1)\n",
    "\n",
    "            scores = []\n",
    "            for train_idx, val_idx in tscv.split(X):\n",
    "                X_tr, X_val = X[train_idx], X[val_idx]\n",
    "                y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "                model.fit(X_tr, y_tr)\n",
    "                preds = model.predict(X_val)\n",
    "                \n",
    "                mse = mean_squared_error(y_val, preds)\n",
    "                scores.append(mse)\n",
    "\n",
    "            return np.mean(scores)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[Optuna Trial Failed] {e}\")\n",
    "            return float('inf')\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "        pruner=optuna.pruners.MedianPruner()\n",
    "    )\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=-1)\n",
    "\n",
    "    if len(study.trials) == 0 or study.best_trial is None:\n",
    "        print(f\"[Skip Model] {model_name} failed to complete any trial. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "    print(f\"[Optuna] {model_name} best_MSE={best_score:.6f}, best_params={best_params}\")\n",
    "\n",
    "    if model_name == \"RF\":\n",
    "        return RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "    elif model_name == \"XGB\":\n",
    "        return XGBRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 5. Main Training and Evaluation Function ==========\n",
    "def train_and_evaluate(model_name, window_size, X_train, y_train, X_test, y_test, \n",
    "                      permnos_train, permnos_test, meta_train, meta_test):\n",
    "    \"\"\"Train and evaluate the model\"\"\"\n",
    "    print(f\"\\nTraining {model_name} on Window = {window_size}\")\n",
    "    \n",
    "    model = tune_model_with_optuna(model_name, X_train, y_train, permnos_train)\n",
    "    \n",
    "    if model is None:\n",
    "        print(f\"[Skip] {model_name} tuning failed, using default parameters\")\n",
    "        if model_name == \"RF\":\n",
    "            model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "        elif model_name == \"XGB\":\n",
    "            model = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\n=== Directional Sanity Check ===\")\n",
    "    print(\"Pos ratio (y_test):\", (y_test > 0).mean())\n",
    "    print(\"Neg ratio (y_test):\", (y_test < 0).mean())\n",
    "    sign_pred = np.sign(y_pred)\n",
    "    print(\"Pred +1 ratio:\", (sign_pred > 0).mean())\n",
    "    print(\"Pred -1 ratio:\", (sign_pred < 0).mean())\n",
    "    \n",
    "    sign_true = np.sign(y_test)\n",
    "    sign_pred = np.sign(y_pred)\n",
    "    \n",
    "    mask = (sign_true != 0) & (sign_pred != 0)\n",
    "    if mask.sum() > 0:\n",
    "        cm = confusion_matrix(sign_true[mask], sign_pred[mask], labels=[1, -1])\n",
    "        print(\"      Pred+  Pred-\")\n",
    "        print(\"+1 |\", cm[0])\n",
    "        print(\"-1 |\", cm[1])\n",
    "    else:\n",
    "        print(\"\\n[Warning] After filtering zeros, no valid samples remain.\")\n",
    "    \n",
    "    metrics = regression_metrics(y_test, y_pred, k=X_test.shape[1], \n",
    "                               meta=meta_test, permnos=permnos_test)\n",
    "    \n",
    "    save_model(model, model_name, window_size)\n",
    "    save_metrics(metrics, model_name, window_size)\n",
    "    save_predictions(model_name, window_size, y_test, y_pred, permnos_test)\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 6. Main scheduling function: loop through all models and windows ==========\n",
    "def loop_all_models():\n",
    "    \"\"\"Train all models on different window sizes\"\"\"\n",
    "    datasets = load_datasets()\n",
    "    \n",
    "    model_list = [\"RF\", \"XGB\"]\n",
    "    window_sizes = [5, 21, 252, 512]\n",
    "\n",
    "    for window in window_sizes:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing Window Size: {window}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        X_train = datasets[f\"X_train_{window}\"]\n",
    "        y_train = datasets[f\"y_train_{window}\"]\n",
    "        X_test = datasets[f\"X_test_{window}\"]\n",
    "        y_test = datasets[f\"y_test_{window}\"]\n",
    "        \n",
    "        meta_train_dict = datasets[f\"meta_train_{window}\"].item()\n",
    "        meta_train = pd.DataFrame.from_dict(meta_train_dict, orient=\"columns\")\n",
    "        permnos_train = meta_train[\"PERMNO\"].values\n",
    "        \n",
    "        meta_test_dict = datasets[f\"meta_test_{window}\"].item()\n",
    "        meta_test = pd.DataFrame.from_dict(meta_test_dict, orient=\"columns\")\n",
    "        permnos_test = meta_test[\"PERMNO\"].values\n",
    "\n",
    "        for model_name in model_list:\n",
    "            print(f\"Training {model_name} on Window = {window}\")\n",
    "            train_and_evaluate(model_name, window, X_train, y_train, X_test, y_test, \n",
    "                             permnos_train, permnos_test, meta_train, meta_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing Window Size: 5\n",
      "==================================================\n",
      "Training RF on Window = 5\n",
      "\n",
      "▶ Training RF on Window = 5\n",
      "[Optuna] RF best_MSE=0.000298, best_params={'n_estimators': 176, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt'}\n",
      "\n",
      "=== Directional Sanity Check ===\n",
      "Pos ratio (y_test): 0.5225259359494813\n",
      "Neg ratio (y_test): 0.47667117726657643\n",
      "Pred +1 ratio: 0.9690121786197564\n",
      "Pred -1 ratio: 0.03098782138024357\n",
      "      Pred+  Pred-\n",
      "+1 | [56276  1646]\n",
      "-1 | [51055  1784]\n",
      "[Update] Metrics updated for RF w=5\n",
      "[Save] RF_w5.csv\n",
      "Training XGB on Window = 5\n",
      "\n",
      "▶ Training XGB on Window = 5\n",
      "[Optuna] XGB best_MSE=0.000299, best_params={'n_estimators': 150, 'max_depth': 4, 'learning_rate': 0.0521063977683361, 'subsample': 0.7510326400110393, 'min_child_weight': 6, 'reg_alpha': 0.00024594068746898375, 'reg_lambda': 0.0005482087312288792}\n",
      "\n",
      "=== Directional Sanity Check ===\n",
      "Pos ratio (y_test): 0.5225259359494813\n",
      "Neg ratio (y_test): 0.47667117726657643\n",
      "Pred +1 ratio: 0.9539738385205232\n",
      "Pred -1 ratio: 0.046026161479476774\n",
      "      Pred+  Pred-\n",
      "+1 | [55442  2480]\n",
      "-1 | [50227  2612]\n",
      "[Update] Metrics updated for XGB w=5\n",
      "[Save] XGB_w5.csv\n",
      "\n",
      "==================================================\n",
      "Processing Window Size: 21\n",
      "==================================================\n",
      "Training RF on Window = 21\n",
      "\n",
      "▶ Training RF on Window = 21\n",
      "[Optuna] RF best_MSE=0.000296, best_params={'n_estimators': 115, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n",
      "\n",
      "=== Directional Sanity Check ===\n",
      "Pos ratio (y_test): 0.5225259359494813\n",
      "Neg ratio (y_test): 0.47667117726657643\n",
      "Pred +1 ratio: 0.9726116373477672\n",
      "Pred -1 ratio: 0.027388362652232746\n",
      "      Pred+  Pred-\n",
      "+1 | [56474  1448]\n",
      "-1 | [51255  1584]\n",
      "[Update] Metrics updated for RF w=21\n",
      "[Save] RF_w21.csv\n",
      "Training XGB on Window = 21\n",
      "\n",
      "▶ Training XGB on Window = 21\n",
      "[Optuna] XGB best_MSE=0.000297, best_params={'n_estimators': 122, 'max_depth': 4, 'learning_rate': 0.04938079032317639, 'subsample': 0.8992683674021377, 'min_child_weight': 3, 'reg_alpha': 0.04932569374393152, 'reg_lambda': 0.0010959958277454473}\n",
      "\n",
      "=== Directional Sanity Check ===\n",
      "Pos ratio (y_test): 0.5225259359494813\n",
      "Neg ratio (y_test): 0.47667117726657643\n",
      "Pred +1 ratio: 0.9921515561569689\n",
      "Pred -1 ratio: 0.007848443843031122\n",
      "      Pred+  Pred-\n",
      "+1 | [57501   421]\n",
      "-1 | [52392   447]\n",
      "[Update] Metrics updated for XGB w=21\n",
      "[Save] XGB_w21.csv\n",
      "\n",
      "==================================================\n",
      "Processing Window Size: 252\n",
      "==================================================\n",
      "Training RF on Window = 252\n",
      "\n",
      "▶ Training RF on Window = 252\n",
      "[Optuna] RF best_MSE=0.000284, best_params={'n_estimators': 267, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}\n",
      "\n",
      "=== Directional Sanity Check ===\n",
      "Pos ratio (y_test): 0.5225259359494813\n",
      "Neg ratio (y_test): 0.47667117726657643\n",
      "Pred +1 ratio: 0.9985656292286874\n",
      "Pred -1 ratio: 0.0014343707713125847\n",
      "      Pred+  Pred-\n",
      "+1 | [57853    69]\n",
      "-1 | [52749    90]\n",
      "[Update] Metrics updated for RF w=252\n",
      "[Save] RF_w252.csv\n",
      "Training XGB on Window = 252\n",
      "\n",
      "▶ Training XGB on Window = 252\n",
      "[Optuna] XGB best_MSE=0.000284, best_params={'n_estimators': 266, 'max_depth': 5, 'learning_rate': 0.028115490459072374, 'subsample': 0.8864121174372909, 'min_child_weight': 4, 'reg_alpha': 0.0019405169949659948, 'reg_lambda': 0.05632464850661171}\n",
      "\n",
      "=== Directional Sanity Check ===\n",
      "Pos ratio (y_test): 0.5225259359494813\n",
      "Neg ratio (y_test): 0.47667117726657643\n",
      "Pred +1 ratio: 0.9704916553901669\n",
      "Pred -1 ratio: 0.029508344609833106\n",
      "      Pred+  Pred-\n",
      "+1 | [56313  1609]\n",
      "-1 | [51183  1656]\n",
      "[Update] Metrics updated for XGB w=252\n",
      "[Save] XGB_w252.csv\n",
      "\n",
      "==================================================\n",
      "Processing Window Size: 512\n",
      "==================================================\n",
      "Training RF on Window = 512\n",
      "\n",
      "▶ Training RF on Window = 512\n",
      "[Optuna] RF best_MSE=0.000282, best_params={'n_estimators': 142, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}\n",
      "\n",
      "=== Directional Sanity Check ===\n",
      "Pos ratio (y_test): 0.5225259359494813\n",
      "Neg ratio (y_test): 0.47667117726657643\n",
      "Pred +1 ratio: 0.9995038340099233\n",
      "Pred -1 ratio: 0.0004961659900766802\n",
      "      Pred+  Pred-\n",
      "+1 | [57895    27]\n",
      "-1 | [52811    28]\n",
      "[Update] Metrics updated for RF w=512\n",
      "[Save] RF_w512.csv\n",
      "Training XGB on Window = 512\n",
      "\n",
      "▶ Training XGB on Window = 512\n",
      "[Optuna] XGB best_MSE=0.000285, best_params={'n_estimators': 293, 'max_depth': 5, 'learning_rate': 0.060149286128351, 'subsample': 0.7673706860111275, 'min_child_weight': 2, 'reg_alpha': 0.0009913595434635216, 'reg_lambda': 0.00013322130199415922}\n",
      "\n",
      "=== Directional Sanity Check ===\n",
      "Pos ratio (y_test): 0.5225259359494813\n",
      "Neg ratio (y_test): 0.47667117726657643\n",
      "Pred +1 ratio: 0.7543888137122238\n",
      "Pred -1 ratio: 0.24561118628777628\n",
      "      Pred+  Pred-\n",
      "+1 | [43971 13951]\n",
      "-1 | [39593 13246]\n",
      "[Update] Metrics updated for XGB w=512\n",
      "[Save] XGB_w512.csv\n"
     ]
    }
   ],
   "source": [
    "# ========== 7. Main entry point ==========\n",
    "if __name__ == \"__main__\":\n",
    "    loop_all_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-mac)",
   "language": "python",
   "name": "tf-mac"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
