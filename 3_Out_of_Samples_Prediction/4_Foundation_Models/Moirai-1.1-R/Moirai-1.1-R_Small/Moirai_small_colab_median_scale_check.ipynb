{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdWeWQdHI5m9",
        "outputId": "2295b6cc-9734-4a9c-981c-04ecff6dc90f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/uni2ts_small_project\n",
            "fatal: destination path 'uni2ts' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/uni2ts_small_project/uni2ts\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: gluonts in /usr/local/lib/python3.11/dist-packages (0.16.2)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.2)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pandas<3,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gluonts) (2.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.11/dist-packages (from gluonts) (2.11.7)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.11/dist-packages (from gluonts) (0.12.1)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (0.15.0)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (1.8.0)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jaxtyping) (0.1.7)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.12.14)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.0->gluonts) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.0->gluonts) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.0->gluonts) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.0->gluonts) (1.17.0)\n",
            "CUDA is available: True\n",
            "Current CUDA device: 0\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Uni2TS Small - Google Colab T4 GPU\n",
        "# ============================================================================\n",
        "\n",
        "# Step 1: Mount Google Drive and set up environment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/uni2ts_small_project\n",
        "\n",
        "%cd /content/drive/MyDrive/uni2ts_small_project\n",
        "\n",
        "!git clone https://github.com/SalesforceAIResearch/uni2ts\n",
        "%cd uni2ts\n",
        "\n",
        "%pip install torch transformers scikit-learn tqdm joblib gluonts lightning pytorch-lightning jaxtyping hydra-core\n",
        "\n",
        "import torch\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current CUDA device:\", torch.cuda.current_device())\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2rnKuNSI5m-",
        "outputId": "fddceaca-c3c1-47ce-ff19-5b3075e2493c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "Using device: cuda\n",
            "Model: Salesforce/moirai-1.1-R-small\n",
            "Prediction length: 1\n",
            "Data loaded successfully!\n",
            "T4 GPU optimized batch size configuration:\n",
            "  Window 5: batch size = 4096\n",
            "  Window 21: batch size = 4096\n",
            "  Window 252: batch size = 512\n",
            "  Window 512: batch size = 256\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "from gluonts.dataset.common import ListDataset\n",
        "sys.path.append(\"src\")\n",
        "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
        "import random\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "MODEL_NAME = \"Salesforce/moirai-1.1-R-small\"\n",
        "PRED_LEN = 1\n",
        "PATCH_SIZE = \"auto\"\n",
        "\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Prediction length: {PRED_LEN}\")\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/ERP Data/all_window_datasets_unscaled.npz\"\n",
        "if os.path.exists(data_path):\n",
        "    data = np.load(data_path, allow_pickle=True)\n",
        "    print(\"Data loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Data file not found: {data_path}\")\n",
        "    print(\"Please ensure all_window_datasets.npz is uploaded to Google Drive 'ERP Data' folder\")\n",
        "\n",
        "window_sizes = [5, 21, 252, 512]\n",
        "results = {}\n",
        "\n",
        "def get_batch_size(window_size):\n",
        "    \"\"\"\n",
        "    Batch size optimized for T4 GPU (16GB).\n",
        "    Uni2TS model is relatively large, so use conservative batch sizes.\n",
        "    \"\"\"\n",
        "    if window_size <= 5:\n",
        "        return 4096\n",
        "    elif window_size <= 21:\n",
        "        return 4096\n",
        "    elif window_size <= 252:\n",
        "        return 512\n",
        "    elif window_size <= 512:\n",
        "        return 256\n",
        "    else:\n",
        "        return 4\n",
        "\n",
        "print(\"T4 GPU optimized batch size configuration:\")\n",
        "for ws in window_sizes:\n",
        "    batch_size = get_batch_size(ws)\n",
        "    print(f\"  Window {ws}: batch size = {batch_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ED2-CJgI5m_"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Prediction\n",
        "# ============================================================================\n",
        "\n",
        "def r2_zero(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate R² (zero-based, baseline is 0)\n",
        "    y_true: true values array (N,)\n",
        "    y_pred: predicted values array (N,)\n",
        "    \"\"\"\n",
        "    rss = np.sum((y_true - y_pred)**2)\n",
        "    tss = np.sum(y_true**2)\n",
        "    return 1 - rss / tss\n",
        "\n",
        "def calc_directional_metrics(y_true, y_pred, permnos=None):\n",
        "    \"\"\"Calculate directional accuracy metrics\"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "\n",
        "    if permnos is None:\n",
        "        s_true = np.sign(y_true)\n",
        "        s_pred = np.sign(y_pred)\n",
        "        mask = s_true != 0\n",
        "        s_true = s_true[mask]\n",
        "        s_pred = s_pred[mask]\n",
        "        overall_acc = np.mean(s_true == s_pred)\n",
        "        up_mask = s_true > 0\n",
        "        down_mask = s_true < 0\n",
        "        up_acc = np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else 0\n",
        "        down_acc = np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else 0\n",
        "    else:\n",
        "        df = pd.DataFrame({\"permno\": permnos, \"yt\": y_true, \"yp\": y_pred})\n",
        "        overall_accs = []\n",
        "        up_accs = []\n",
        "        down_accs = []\n",
        "        for _, g in df.groupby(\"permno\"):\n",
        "            s_true = np.sign(g[\"yt\"].values)\n",
        "            s_pred = np.sign(g[\"yp\"].values)\n",
        "            mask = s_true != 0\n",
        "            s_true = s_true[mask]\n",
        "            s_pred = s_pred[mask]\n",
        "            if len(s_true) == 0:\n",
        "                continue\n",
        "            overall_accs.append(np.mean(s_true == s_pred))\n",
        "            up_mask = s_true > 0\n",
        "            down_mask = s_true < 0\n",
        "            up_accs.append(np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else np.nan)\n",
        "            down_accs.append(np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else np.nan)\n",
        "        overall_acc = np.nanmean(overall_accs)\n",
        "        up_acc = np.nanmean(up_accs)\n",
        "        down_acc = np.nanmean(down_accs)\n",
        "    return overall_acc, up_acc, down_acc\n",
        "\n",
        "def r2_traditional(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate traditional R² (mean-based)\n",
        "    \"\"\"\n",
        "    rss = np.sum((y_true - y_pred)**2)\n",
        "    tss = np.sum((y_true - y_true.mean())**2)\n",
        "    return 1 - rss / tss if tss != 0 else float('-inf')\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, permnos=None, meta=None):\n",
        "    \"\"\"Calculate evaluation metrics\"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    dir_acc, up_acc, down_acc = calc_directional_metrics(y_true, y_pred, permnos)\n",
        "    r2_zero_based = r2_zero(y_true, y_pred)\n",
        "    r2_trad = r2_traditional(y_true, y_pred)\n",
        "\n",
        "    metrics = {\n",
        "        \"R2_zero\": r2_zero_based,\n",
        "        \"R2_traditional\": r2_trad,\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"Directional Accuracy\": dir_acc,\n",
        "        \"Up_Directional_Acc\": up_acc,\n",
        "        \"Down_Directional_Acc\": down_acc\n",
        "    }\n",
        "\n",
        "    # Market cap group metrics\n",
        "    if meta is not None and \"MKTCAP_PERCENTILE\" in meta:\n",
        "        top_mask = meta[\"MKTCAP_PERCENTILE\"] >= 0.75\n",
        "        bottom_mask = meta[\"MKTCAP_PERCENTILE\"] <= 0.25\n",
        "\n",
        "        if np.any(top_mask):\n",
        "            yt_top = y_true[top_mask]\n",
        "            yp_top = y_pred[top_mask]\n",
        "            perm_top = permnos[top_mask] if permnos is not None else None\n",
        "            r2_zero_top = r2_zero(yt_top, yp_top)\n",
        "            r2_trad_top = r2_traditional(yt_top, yp_top)\n",
        "            mae_top = mean_absolute_error(yt_top, yp_top)\n",
        "            mse_top = mean_squared_error(yt_top, yp_top)\n",
        "            dir_top, up_top, down_top = calc_directional_metrics(yt_top, yp_top, perm_top)\n",
        "            metrics.update({\n",
        "                \"Top25_R2_zero\": r2_zero_top,\n",
        "                \"Top25_R2_traditional\": r2_trad_top,\n",
        "                \"Top25_MAE\": mae_top,\n",
        "                \"Top25_MSE\": mse_top,\n",
        "                \"Top25_Dir_Acc\": dir_top,\n",
        "                \"Top25_Up_Acc\": up_top,\n",
        "                \"Top25_Down_Acc\": down_top\n",
        "            })\n",
        "\n",
        "        if np.any(bottom_mask):\n",
        "            yt_bot = y_true[bottom_mask]\n",
        "            yp_bot = y_pred[bottom_mask]\n",
        "            perm_bot = permnos[bottom_mask] if permnos is not None else None\n",
        "            r2_zero_bot = r2_zero(yt_bot, yp_bot)\n",
        "            r2_trad_bot = r2_traditional(yt_bot, yp_bot)\n",
        "            mae_bot = mean_absolute_error(yt_bot, yp_bot)\n",
        "            mse_bot = mean_squared_error(yt_bot, yp_bot)\n",
        "            dir_bot, up_bot, down_bot = calc_directional_metrics(yt_bot, yp_bot, perm_bot)\n",
        "            metrics.update({\n",
        "                \"Bottom25_R2_zero\": r2_zero_bot,\n",
        "                \"Bottom25_R2_traditional\": r2_trad_bot,\n",
        "                \"Bottom25_MAE\": mae_bot,\n",
        "                \"Bottom25_MSE\": mse_bot,\n",
        "                \"Bottom25_Dir_Acc\": dir_bot,\n",
        "                \"Bottom25_Up_Acc\": up_bot,\n",
        "                \"Bottom25_Down_Acc\": down_bot\n",
        "            })\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA5Oo934I5m_",
        "outputId": "5e09de54-64c0-47b1-d4f7-df87cdd9a06b"
      },
      "outputs": [],
      "source": [
        "def batch_predict_uni2ts(X_test, predictor, batch_size):\n",
        "    \"\"\"T4 GPU optimized batch inference function\"\"\"\n",
        "    num_samples = len(X_test)\n",
        "    all_predictions = np.zeros(num_samples)\n",
        "    original_batch_size = batch_size\n",
        "\n",
        "    print(f\"Starting GPU optimized inference with batch size: {batch_size}\")\n",
        "\n",
        "    for i in tqdm(range(0, num_samples, batch_size), desc=\"GPU Batch Inference\"):\n",
        "        try:\n",
        "            batch_end = min(i + batch_size, num_samples)\n",
        "            batch_X = X_test[i:batch_end]\n",
        "\n",
        "            # Prepare GluonTS data format\n",
        "            batch_data = []\n",
        "            for j in range(len(batch_X)):\n",
        "                target = batch_X[j].flatten()\n",
        "\n",
        "                data_entry = {\n",
        "                    \"target\": target.tolist(),\n",
        "                    \"start\": pd.Timestamp(\"2000-01-01\"),\n",
        "                    \"item_id\": f\"item_{i+j}\",\n",
        "                }\n",
        "                batch_data.append(data_entry)\n",
        "\n",
        "            dataset = ListDataset(batch_data, freq=\"D\")\n",
        "            forecasts = list(predictor.predict(dataset))\n",
        "\n",
        "            for k, forecast in enumerate(forecasts):\n",
        "                all_predictions[i+k] = forecast.quantile(0.5)[0]\n",
        "\n",
        "            if i % (batch_size * 10) == 0 and torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"out of memory\" in str(e).lower():\n",
        "                print(f\"\\nOOM detected. Reducing batch size from {batch_size} to {batch_size//2}\")\n",
        "                torch.cuda.empty_cache()\n",
        "                batch_size = max(batch_size // 2, 1)\n",
        "\n",
        "                # Retry current batch\n",
        "                batch_end = min(i + batch_size, num_samples)\n",
        "                batch_X = X_test[i:batch_end]\n",
        "\n",
        "                batch_data = []\n",
        "                for j in range(len(batch_X)):\n",
        "                    target = batch_X[j].flatten()\n",
        "\n",
        "                    data_entry = {\n",
        "                      \"target\": target.tolist(),\n",
        "                      \"start\": pd.Timestamp(\"2000-01-01\"),\n",
        "                      \"item_id\": f\"item_{i+j}\",\n",
        "                    }\n",
        "                    batch_data.append(data_entry)\n",
        "\n",
        "                dataset = ListDataset(batch_data, freq=\"D\")\n",
        "                forecasts = list(predictor.predict(dataset))\n",
        "\n",
        "                for k, forecast in enumerate(forecasts):\n",
        "                    all_predictions[i+k] = all_predictions[i+k] = forecast.quantile(0.5)[0]\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\nInference completed. Final batch size: {batch_size} (original: {original_batch_size})\")\n",
        "    return all_predictions\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/uni2ts_small_project/uni2ts_results\n",
        "!mkdir -p /content/drive/MyDrive/uni2ts_small_project/uni2ts_predictions\n",
        "\n",
        "print(\"Starting T4 GPU optimized prediction...\")\n",
        "print(f\"Data file contains keys: {list(data.keys())}\")\n",
        "\n",
        "for window_size in window_sizes:\n",
        "    print(f\"\\n=== Processing Window Size: {window_size} ===\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    X_train = data[f\"X_train_{window_size}\"]\n",
        "    y_train = data[f\"y_train_{window_size}\"]\n",
        "    X_test = data[f\"X_test_{window_size}\"]\n",
        "    y_test = data[f\"y_test_{window_size}\"]\n",
        "    meta_test = pd.DataFrame(data[f\"meta_test_{window_size}\"].item())\n",
        "\n",
        "    current_batch_size = get_batch_size(window_size)\n",
        "\n",
        "    print(f\"Test samples: {len(X_test):,}\")\n",
        "    print(\"X_test shape:\", X_test.shape)\n",
        "    print(f\"Optimized batch size: {current_batch_size}\")\n",
        "\n",
        "    print(\"Initializing Uni2TS model...\")\n",
        "    model = MoiraiForecast(\n",
        "        module=MoiraiModule.from_pretrained(MODEL_NAME),\n",
        "        prediction_length=PRED_LEN,\n",
        "        context_length=window_size,\n",
        "        patch_size=PATCH_SIZE,\n",
        "        num_samples=100,\n",
        "        target_dim=1,\n",
        "        feat_dynamic_real_dim=0,\n",
        "        past_feat_dynamic_real_dim=0,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        model = model.to(device)\n",
        "        print(f\"Model loaded on: {device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load on {device}, using CPU: {str(e)}\")\n",
        "        model = model.to(\"cpu\")\n",
        "        device = \"cpu\"\n",
        "\n",
        "    predictor = model.create_predictor(batch_size=current_batch_size)\n",
        "\n",
        "    print(\"Starting batch inference...\")\n",
        "    all_predictions = batch_predict_uni2ts(X_test, predictor, current_batch_size)\n",
        "\n",
        "    print(\"\\n=== Quick value scale check ===\")\n",
        "    print(\"y_true mean/std/min/max:\", f\"{y_test.mean():.6f}\", f\"{y_test.std():.6f}\", f\"{y_test.min():.6f}\", f\"{y_test.max():.6f}\")\n",
        "    print(\"y_pred mean/std/min/max:\", f\"{all_predictions.mean():.6f}\", f\"{all_predictions.std():.6f}\", f\"{all_predictions.min():.6f}\", f\"{all_predictions.max():.6f}\")\n",
        "\n",
        "    print(\"\\n=== Correlation analysis (based on training subset) ===\")\n",
        "    print(f\"Running inference on training subset for correlation analysis...\")\n",
        "    calib_size = min(len(X_train), 5000)\n",
        "    calib_indices = np.random.choice(len(X_train), calib_size, replace=False)\n",
        "    X_calib = X_train[calib_indices]\n",
        "    y_calib_true = y_train[calib_indices]\n",
        "\n",
        "    calib_predictions = batch_predict_uni2ts(X_calib, predictor, min(current_batch_size, 512))\n",
        "\n",
        "    print(f\"Analysis set statistics:\")\n",
        "    print(f\"  Set size: {len(y_calib_true)}\")\n",
        "    print(f\"  y_true: mean={np.mean(y_calib_true):.6f}, std={np.std(y_calib_true):.6f}\")\n",
        "    print(f\"  y_pred: mean={np.mean(calib_predictions):.6f}, std={np.std(calib_predictions):.6f}\")\n",
        "\n",
        "    correlation = np.corrcoef(y_calib_true, calib_predictions)[0, 1]\n",
        "    print(f\"  Correlation coefficient: {correlation:.6f}\")\n",
        "\n",
        "    y_pred_std = np.std(calib_predictions)\n",
        "    y_true_std = np.std(y_calib_true)\n",
        "    std_ratio = y_true_std / y_pred_std if y_pred_std > 1e-12 else float('inf')\n",
        "    print(f\"  Std ratio (true/pred): {std_ratio:.6f}\")\n",
        "\n",
        "    mean_diff = np.mean(y_calib_true) - np.mean(calib_predictions)\n",
        "    print(f\"  Mean difference (true - pred): {mean_diff:.6f}\")\n",
        "\n",
        "    r2_train_subset = r2_zero(y_calib_true, calib_predictions)\n",
        "    print(f\"  R² on training subset: {r2_train_subset:.6f}\")\n",
        "\n",
        "    print(\"\\nCalculating evaluation metrics...\")\n",
        "    permnos_test = meta_test[\"PERMNO\"].values\n",
        "    try:\n",
        "        metrics = calculate_metrics(y_test, all_predictions, permnos_test, meta_test)\n",
        "    except Exception as err:\n",
        "        print(f\" calculate_metrics failed: {err}\")\n",
        "        metrics = {}\n",
        "\n",
        "    print(\"\\n=== Directional Sanity Check ===\")\n",
        "    print(\"Pos ratio (y_test):\", (y_test > 0).mean())\n",
        "    print(\"Neg ratio (y_test):\", (y_test < 0).mean())\n",
        "    sign_pred = np.sign(all_predictions)\n",
        "    print(\"Pred +1 ratio:\", (sign_pred > 0).mean())\n",
        "    print(\"Pred -1 ratio:\", (sign_pred < 0).mean())\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    conf = confusion_matrix(np.sign(y_test), sign_pred, labels=[1, -1])\n",
        "    print(\"      Pred+  Pred-\")\n",
        "    print(\"+1 |\", conf[0])\n",
        "    print(\"-1 |\", conf[1])\n",
        "\n",
        "    results[window_size] = {\n",
        "        'predictions': all_predictions,\n",
        "        'true_values': y_test,\n",
        "        'metrics': metrics,\n",
        "        'meta': meta_test,\n",
        "        'analysis_stats': {\n",
        "            'correlation': correlation,\n",
        "            'std_ratio': std_ratio,\n",
        "            'mean_diff': mean_diff,\n",
        "            'r2_train_subset': r2_train_subset\n",
        "        }\n",
        "    }\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    samples_per_second = len(X_test) / elapsed_time\n",
        "\n",
        "    print(f\"\\nWindow {window_size} processing completed:\")\n",
        "    print(f\"Total time: {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Processing speed: {samples_per_second:.0f} samples/second\")\n",
        "\n",
        "    print(f\"\\nMetrics for window {window_size}:\")\n",
        "    if metrics:\n",
        "        for metric_name, value in metrics.items():\n",
        "            print(f\"{metric_name}: {value:.4f}\")\n",
        "    else:\n",
        "        print(\"  (metrics is empty, skipped)\")\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        'PERMNO': meta_test['PERMNO'],\n",
        "        'y_true': y_test,\n",
        "        'y_pred': all_predictions\n",
        "    })\n",
        "    results_df.to_csv(f'/content/drive/MyDrive/uni2ts_small_project/uni2ts_predictions/uni2ts_small_w{window_size}.csv', index=False)\n",
        "    print(f\"Predictions saved to uni2ts_small_w{window_size}.csv\")\n",
        "\n",
        "    try:\n",
        "        del model, predictor\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Memory cleanup failed: {str(e)}\")\n",
        "\n",
        "print(\"\\n=== All predictions completed! ===\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JurSzsz_I5m_"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Save results and generate visualizations\n",
        "# ============================================================================\n",
        "\n",
        "results_dict = {\n",
        "    'window_sizes': window_sizes,\n",
        "    'results': results,\n",
        "    'model_name': 'Uni2TS-Small',\n",
        "    'model_version': 'T4_GPU_Optimized_NoCalibration',\n",
        "    'model_params': {\n",
        "        'device': device,\n",
        "        'batch_sizes': {ws: get_batch_size(ws) for ws in window_sizes},\n",
        "        'gpu_optimized': True,\n",
        "        'calibration_applied': False\n",
        "    }\n",
        "}\n",
        "joblib.dump(results_dict, \"/content/drive/MyDrive/uni2ts_small_project/uni2ts_results/results.pkl\")\n",
        "print(\"Results saved to results.pkl\")\n",
        "\n",
        "# Only generate summary if all windows have valid metrics\n",
        "valid_results = {ws: results[ws] for ws in window_sizes if results[ws]['metrics']}\n",
        "\n",
        "if valid_results:\n",
        "    metrics_df = pd.DataFrame([\n",
        "        {**{\"Window\": window_size}, **valid_results[window_size][\"metrics\"]}\n",
        "        for window_size in valid_results.keys()\n",
        "    ])\n",
        "    metrics_df.to_csv(\"/content/drive/MyDrive/uni2ts_small_project/uni2ts_results/uni2ts_small_metrics.csv\", index=False)\n",
        "    print(\"Metrics saved to uni2ts_small_metrics.csv\")\n",
        "\n",
        "    print(\"\\n=== Metrics Summary ===\")\n",
        "    print(metrics_df.round(4))\n",
        "\n",
        "    metrics_to_plot = [\"R²\", \"MAE\", \"MSE\", \"Directional Accuracy\", \"Up_Directional_Acc\", \"Down_Directional_Acc\"]\n",
        "    metric_names = {\n",
        "        \"R²\": \"R²\",\n",
        "        \"MAE\": \"Mean Absolute Error (MAE)\",\n",
        "        \"MSE\": \"Mean Squared Error (MSE)\",\n",
        "        \"Directional Accuracy\": \"Directional Accuracy\",\n",
        "        \"Up_Directional_Acc\": \"Up Directional Accuracy\",\n",
        "        \"Down_Directional_Acc\": \"Down Directional Accuracy\"\n",
        "    }\n",
        "\n",
        "    available_metrics = [m for m in metrics_to_plot if m in metrics_df.columns]\n",
        "\n",
        "    if available_metrics:\n",
        "        fig, axs = plt.subplots(3, 2, figsize=(14, 12))\n",
        "        axs = axs.flatten()\n",
        "\n",
        "        for idx, metric in enumerate(available_metrics[:6]):\n",
        "            ax = axs[idx]\n",
        "            ax.plot(metrics_df[\"Window\"], metrics_df[metric],\n",
        "                    marker='o', linestyle='-', linewidth=2, color='#1f77b4')\n",
        "\n",
        "            ax.set_title(metric_names[metric], fontsize=14, weight=\"bold\")\n",
        "            ax.set_xlabel(\"Window Size\", fontsize=12)\n",
        "            ax.set_ylabel(metric_names[metric], fontsize=12)\n",
        "            ax.set_xticks(list(valid_results.keys()))\n",
        "            ax.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "        for idx in range(len(available_metrics), 6):\n",
        "            axs[idx].set_visible(False)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"/content/drive/MyDrive/uni2ts_small_project/uni2ts_results/uni2ts_small_metrics.png\", dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"No valid metrics found, skipping visualization\")\n",
        "\n",
        "print(\"\\n=== All results saved to Google Drive! ===\")\n",
        "print(\"Files saved to: /content/drive/MyDrive/uni2ts_small_project/\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (UniTS)",
      "language": "python",
      "name": "uni2ts"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
