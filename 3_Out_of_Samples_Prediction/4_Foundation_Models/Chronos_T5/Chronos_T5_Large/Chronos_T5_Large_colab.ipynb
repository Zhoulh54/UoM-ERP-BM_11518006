{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CYHKV4dTfBT",
        "outputId": "7d9e9884-07b5-4be1-c41f-673050e89516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/chronos_t5_large_project\n",
            "Cloning into 'chronos-forecasting'...\n",
            "remote: Enumerating objects: 500, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 500 (delta 22), reused 2 (delta 2), pack-reused 472 (from 3)\u001b[K\n",
            "Receiving objects: 100% (500/500), 1.03 MiB | 7.08 MiB/s, done.\n",
            "Resolving deltas: 100% (217/217), done.\n",
            "/content/drive/MyDrive/chronos_t5_large_project/chronos-forecasting\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.34.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "CUDA is available: True\n",
            "Current CUDA device: 0\n",
            "Device name: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Chronos T5 Large - Google Colab T4 GPU Optimized Version\n",
        "# ============================================================================\n",
        "\n",
        "# Cell 1: Environment setup and model loading\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/chronos_t5_large_project\n",
        "\n",
        "%cd /content/drive/MyDrive/chronos_t5_large_project\n",
        "\n",
        "!git clone https://github.com/amazon-science/chronos-forecasting\n",
        "%cd chronos-forecasting\n",
        "\n",
        "%pip install torch\n",
        "%pip install transformers\n",
        "%pip install datasets\n",
        "%pip install accelerate\n",
        "%pip install scikit-learn\n",
        "%pip install tqdm\n",
        "%pip install joblib\n",
        "\n",
        "import torch\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current CUDA device:\", torch.cuda.current_device())\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "ebdc20a0f14d4d849d6cd16bb52017d9",
            "7b85653570384311839b0cc6b1bcb9a5",
            "fcc1518998d646b3aefd76cae108597b",
            "16cb3bc8012c48f99bcb9bdc92827538",
            "17e6ffc236754da7a2e799c611c9c3c4",
            "1f254a0ca04149ab8b387e67374707ea",
            "0112748a28a14ab5985962738186ffe0",
            "0c539af8e78a4f6780cd051c508b8956",
            "b1a8bc16b0004469aab3c0534fff9089",
            "62da8eed91ad4d3c98fbda09dd0e2684",
            "16463d3e67df43ec8a3d7dfeb75b6f1f",
            "841716f0450a4e5baecba32d420adbbc",
            "2efefef56d4b407cb124948f0e8f1e68",
            "0b97e54c97784287b95ac5f2d51efa6b",
            "596626123c76488089d5a856396610b4",
            "2889611abbf6449ab8772523aafce5ba",
            "f0b6906b782a426799ffb5694b61352f",
            "ef30bd0b217e45149b4623dc0d04d5ee",
            "2aaaa3c3d022432e929bc2bb306f3871",
            "2ff7767ae1614b60bbecc30425076cdb",
            "de5890497148458da8a518e04da24474",
            "74a5174c03e94760bccfa7e660b7e1dd",
            "c0d15934e85043df94fd384797bd9efb",
            "7eb5f8e436864d4fa8bca870fa281c7c",
            "c9b7da5e20d94a0f99907e4137fc3238",
            "95d4f01f163c4ec4af273923a88d20df",
            "b34168fa9a5d494496d20911c1954d67",
            "16a93c967327441da3997f92ee71a20f",
            "320543de3caf44188bdac1df29d80d84",
            "41503e23b8c64ab1840afae42a0e7793",
            "0b6d38fb9bf74b858f0257245c06662f",
            "32abfa0e8bef42ffbff1ff1405578264",
            "7d5734ba84d34327906b511e9ab943f3"
          ]
        },
        "id": "KUy9Z_IDTyd0",
        "outputId": "3e3f4ab1-de9a-4095-aad3-ecb85f427172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebdc20a0f14d4d849d6cd16bb52017d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "841716f0450a4e5baecba32d420adbbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.84G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0d15934e85043df94fd384797bd9efb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded Chronos T5 Large model on cuda\n",
            "Model device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # Set random seed for Mac MPS device\n",
        "    if torch.backends.mps.is_available():\n",
        "        torch.mps.manual_seed(seed)\n",
        "    # Ensure deterministic behavior\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Add local path for importing modules from src\n",
        "sys.path.append(\"src\")\n",
        "\n",
        "from chronos import BaseChronosPipeline\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "try:\n",
        "    pipeline = BaseChronosPipeline.from_pretrained(\n",
        "        \"amazon/chronos-t5-large\",\n",
        "        device_map=\"auto\" if torch.cuda.is_available() else \"cpu\",\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "    )\n",
        "    print(f\"Successfully loaded Chronos T5 Large model on {device}\")\n",
        "\n",
        "    if hasattr(pipeline.model, 'device'):\n",
        "        print(f\"Model device: {pipeline.model.device}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load model: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhkaBvhNU3xb",
        "outputId": "fae00ea3-ad14-4926-ba93-c865dfdf45c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully!\n",
            "T4 GPU optimized batch size configuration:\n",
            "  Window 5: batch size = 2048\n",
            "  Window 21: batch size = 512\n",
            "  Window 252: batch size = 64\n",
            "  Window 512: batch size = 24\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "data_path = \"/content/drive/MyDrive/ERP Data/all_window_datasets_unscaled.npz\"\n",
        "if os.path.exists(data_path):\n",
        "    data = np.load(data_path, allow_pickle=True)\n",
        "    print(\"Data loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Data file not found: {data_path}\")\n",
        "    print(\"Please make sure all_window_datasets.npz is uploaded to the 'ERP Data' folder in your Google Drive.\")\n",
        "\n",
        "window_sizes = [5, 21, 252, 512]\n",
        "results = {}\n",
        "\n",
        "def get_batch_size(window_size):\n",
        "    \"\"\"\n",
        "    Batch size configuration optimized for T4 GPU (16GB).\n",
        "    \"\"\"\n",
        "    if window_size <= 5:\n",
        "        return 2048  # 4x increase\n",
        "    elif window_size <= 21:\n",
        "        return 512   # 2x increase\n",
        "    elif window_size <= 252:\n",
        "        return 64   # 4x increase\n",
        "    elif window_size <= 512:\n",
        "        return 24   # 4x increase\n",
        "    else:\n",
        "        return 32\n",
        "\n",
        "print(\"T4 GPU optimized batch size configuration:\")\n",
        "for ws in window_sizes:\n",
        "    batch_size = get_batch_size(ws)\n",
        "    print(f\"  Window {ws}: batch size = {batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Iel8AfvyU9rx"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 2: Prediction (T4 GPU optimized version)\n",
        "# ============================================================================\n",
        "\n",
        "def r2_zero(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute R² (zero-based, baseline is 0)\n",
        "    y_true: true values array (N,)\n",
        "    y_pred: predicted values array (N,)\n",
        "    \"\"\"\n",
        "    rss = np.sum((y_true - y_pred)**2)\n",
        "    tss = np.sum(y_true**2)\n",
        "    return 1 - rss / tss\n",
        "\n",
        "def calc_directional_metrics(y_true, y_pred, permnos=None):\n",
        "    \"\"\"Compute directional accuracy metrics (consistent with TimesFM)\"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "\n",
        "    if permnos is None:\n",
        "        s_true = np.sign(y_true)\n",
        "        s_pred = np.sign(y_pred)\n",
        "        mask = s_true != 0\n",
        "        s_true = s_true[mask]\n",
        "        s_pred = s_pred[mask]\n",
        "        overall_acc = np.mean(s_true == s_pred)\n",
        "        up_mask = s_true > 0\n",
        "        down_mask = s_true < 0\n",
        "        up_acc = np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else 0\n",
        "        down_acc = np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else 0\n",
        "    else:\n",
        "        df = pd.DataFrame({\"permno\": permnos, \"yt\": y_true, \"yp\": y_pred})\n",
        "        overall_accs = []\n",
        "        up_accs = []\n",
        "        down_accs = []\n",
        "        for _, g in df.groupby(\"permno\"):\n",
        "            s_true = np.sign(g[\"yt\"].values)\n",
        "            s_pred = np.sign(g[\"yp\"].values)\n",
        "            mask = s_true != 0\n",
        "            s_true = s_true[mask]\n",
        "            s_pred = s_pred[mask]\n",
        "            if len(s_true) == 0:\n",
        "                continue\n",
        "            overall_accs.append(np.mean(s_true == s_pred))\n",
        "            up_mask = s_true > 0\n",
        "            down_mask = s_true < 0\n",
        "            up_accs.append(np.mean(s_true[up_mask] == s_pred[up_mask]) if np.any(up_mask) else np.nan)\n",
        "            down_accs.append(np.mean(s_true[down_mask] == s_pred[down_mask]) if np.any(down_mask) else np.nan)\n",
        "        overall_acc = np.nanmean(overall_accs)\n",
        "        up_acc = np.nanmean(up_accs)\n",
        "        down_acc = np.nanmean(down_accs)\n",
        "    return overall_acc, up_acc, down_acc\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, permnos=None, meta=None):\n",
        "    \"\"\"Compute evaluation metrics (consistent with TimesFM)\"\"\"\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    r2 = r2_zero(y_true, y_pred)\n",
        "    dir_acc, up_acc, down_acc = calc_directional_metrics(y_true, y_pred, permnos)\n",
        "\n",
        "    metrics = {\n",
        "        \"R2\": r2,\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"Directional Accuracy\": dir_acc,\n",
        "        \"Up_Directional_Acc\": up_acc,\n",
        "        \"Down_Directional_Acc\": down_acc\n",
        "    }\n",
        "\n",
        "    # Market cap group metrics\n",
        "    if meta is not None and \"MKTCAP_PERCENTILE\" in meta:\n",
        "        top_mask = meta[\"MKTCAP_PERCENTILE\"] >= 0.75\n",
        "        bottom_mask = meta[\"MKTCAP_PERCENTILE\"] <= 0.25\n",
        "\n",
        "        if np.any(top_mask):\n",
        "            yt_top = y_true[top_mask]\n",
        "            yp_top = y_pred[top_mask]\n",
        "            perm_top = permnos[top_mask] if permnos is not None else None\n",
        "            r2_top = r2_zero(yt_top, yp_top)\n",
        "            mae_top = mean_absolute_error(yt_top, yp_top)\n",
        "            mse_top = mean_squared_error(yt_top, yp_top)\n",
        "            dir_top, up_top, down_top = calc_directional_metrics(yt_top, yp_top, perm_top)\n",
        "            metrics.update({\n",
        "                \"Top25_R2\": r2_top,\n",
        "                \"Top25_MAE\": mae_top,\n",
        "                \"Top25_MSE\": mse_top,\n",
        "                \"Top25_Dir_Acc\": dir_top,\n",
        "                \"Top25_Up_Acc\": up_top,\n",
        "                \"Top25_Down_Acc\": down_top\n",
        "            })\n",
        "\n",
        "        if np.any(bottom_mask):\n",
        "            yt_bot = y_true[bottom_mask]\n",
        "            yp_bot = y_pred[bottom_mask]\n",
        "            perm_bot = permnos[bottom_mask] if permnos is not None else None\n",
        "            r2_bot = r2_zero(yt_bot, yp_bot)\n",
        "            mae_bot = mean_absolute_error(yt_bot, yp_bot)\n",
        "            mse_bot = mean_squared_error(yt_bot, yp_bot)\n",
        "            dir_bot, up_bot, down_bot = calc_directional_metrics(yt_bot, yp_bot, perm_bot)\n",
        "            metrics.update({\n",
        "                \"Bottom25_R2\": r2_bot,\n",
        "                \"Bottom25_MAE\": mae_bot,\n",
        "                \"Bottom25_MSE\": mse_bot,\n",
        "                \"Bottom25_Dir_Acc\": dir_bot,\n",
        "                \"Bottom25_Up_Acc\": up_bot,\n",
        "                \"Bottom25_Down_Acc\": down_bot\n",
        "            })\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59xTtkW-VBXF",
        "outputId": "9b10c516-3529-4e5e-f24d-39cf0ac78deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting T4 GPU optimized prediction...\n",
            "Data file contains keys: ['X_train_5', 'y_train_5', 'meta_train_5', 'market_caps_train_5', 'X_test_5', 'y_test_5', 'meta_test_5', 'market_caps_test_5', 'X_train_21', 'y_train_21', 'meta_train_21', 'market_caps_train_21', 'X_test_21', 'y_test_21', 'meta_test_21', 'market_caps_test_21', 'X_train_252', 'y_train_252', 'meta_train_252', 'market_caps_train_252', 'X_test_252', 'y_test_252', 'meta_test_252', 'market_caps_test_252', 'X_train_512', 'y_train_512', 'meta_train_512', 'market_caps_train_512', 'X_test_512', 'y_test_512', 'meta_test_512', 'market_caps_test_512']\n",
            "\n",
            "=== Processing Window Size: 5 ===\n",
            "Test samples: 110,850\n",
            "Sequence length: 5\n",
            "Optimized batch size: 2048\n",
            "Starting GPU optimized inference with batch size: 2048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU Batch Inference: 100%|██████████| 55/55 [00:41<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference completed. Final batch size: 2048 (original: 2048)\n",
            "\n",
            "=== Directional Sanity Check ===\n",
            "Pos ratio (y_test): 0.5225259359494813\n",
            "Neg ratio (y_test): 0.47667117726657643\n",
            "Pred +1 ratio: 0.6125755525484889\n",
            "Pred -1 ratio: 0.38742444745151106\n",
            "      Pred+  Pred-\n",
            "+1 | [35149 22773]\n",
            "-1 | [32702 20137]\n",
            "\n",
            "Window 5 processing completed:\n",
            "Total time: 43.83 seconds\n",
            "Processing speed: 2529 samples/second\n",
            "\n",
            "Metrics for window 5:\n",
            "R2: -0.5388\n",
            "MAE: 0.0143\n",
            "MSE: 0.0004\n",
            "Directional Accuracy: 0.4991\n",
            "Up_Directional_Acc: 0.6065\n",
            "Down_Directional_Acc: 0.3806\n",
            "Top25_R2: -0.5422\n",
            "Top25_MAE: 0.0124\n",
            "Top25_MSE: 0.0003\n",
            "Top25_Dir_Acc: 0.4213\n",
            "Top25_Up_Acc: 0.5836\n",
            "Top25_Down_Acc: 0.3161\n",
            "Bottom25_R2: -0.5395\n",
            "Bottom25_MAE: 0.0187\n",
            "Bottom25_MSE: 0.0007\n",
            "Bottom25_Dir_Acc: 0.4992\n",
            "Bottom25_Up_Acc: 0.5923\n",
            "Bottom25_Down_Acc: 0.3913\n",
            "Predictions saved to chronos_t5_large_w5.csv\n",
            "\n",
            "=== Processing Window Size: 21 ===\n",
            "Test samples: 110,850\n",
            "Sequence length: 21\n",
            "Optimized batch size: 512\n",
            "Starting GPU optimized inference with batch size: 512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU Batch Inference: 100%|██████████| 217/217 [01:25<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference completed. Final batch size: 512 (original: 512)\n",
            "\n",
            "=== Directional Sanity Check ===\n",
            "Pos ratio (y_test): 0.5225259359494813\n",
            "Neg ratio (y_test): 0.47667117726657643\n",
            "Pred +1 ratio: 0.6544609833107803\n",
            "Pred -1 ratio: 0.34553901668921966\n",
            "      Pred+  Pred-\n",
            "+1 | [37670 20252]\n",
            "-1 | [34823 18016]\n",
            "\n",
            "Window 21 processing completed:\n",
            "Total time: 87.75 seconds\n",
            "Processing speed: 1263 samples/second\n",
            "\n",
            "Metrics for window 21:\n",
            "R2: -0.1211\n",
            "MAE: 0.0125\n",
            "MSE: 0.0003\n",
            "Directional Accuracy: 0.5028\n",
            "Up_Directional_Acc: 0.6495\n",
            "Down_Directional_Acc: 0.3402\n",
            "Top25_R2: -0.1217\n",
            "Top25_MAE: 0.0108\n",
            "Top25_MSE: 0.0002\n",
            "Top25_Dir_Acc: 0.4607\n",
            "Top25_Up_Acc: 0.6417\n",
            "Top25_Down_Acc: 0.2952\n",
            "Bottom25_R2: -0.1180\n",
            "Bottom25_MAE: 0.0163\n",
            "Bottom25_MSE: 0.0005\n",
            "Bottom25_Dir_Acc: 0.5016\n",
            "Bottom25_Up_Acc: 0.6144\n",
            "Bottom25_Down_Acc: 0.3693\n",
            "Predictions saved to chronos_t5_large_w21.csv\n",
            "\n",
            "=== Processing Window Size: 252 ===\n",
            "Test samples: 110,850\n",
            "Sequence length: 252\n",
            "Optimized batch size: 64\n",
            "Starting GPU optimized inference with batch size: 64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU Batch Inference: 100%|██████████| 1733/1733 [13:32<00:00,  2.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference completed. Final batch size: 64 (original: 64)\n",
            "\n",
            "=== Directional Sanity Check ===\n",
            "Pos ratio (y_test): 0.5225259359494813\n",
            "Neg ratio (y_test): 0.47667117726657643\n",
            "Pred +1 ratio: 0.6190617952187641\n",
            "Pred -1 ratio: 0.3809382047812359\n",
            "      Pred+  Pred-\n",
            "+1 | [35778 22144]\n",
            "-1 | [32787 20052]\n",
            "\n",
            "Window 252 processing completed:\n",
            "Total time: 819.23 seconds\n",
            "Processing speed: 135 samples/second\n",
            "\n",
            "Metrics for window 252:\n",
            "R2: -0.0182\n",
            "MAE: 0.0120\n",
            "MSE: 0.0003\n",
            "Directional Accuracy: 0.5041\n",
            "Up_Directional_Acc: 0.6161\n",
            "Down_Directional_Acc: 0.3778\n",
            "Top25_R2: -0.0177\n",
            "Top25_MAE: 0.0103\n",
            "Top25_MSE: 0.0002\n",
            "Top25_Dir_Acc: 0.5610\n",
            "Top25_Up_Acc: 0.6154\n",
            "Top25_Down_Acc: 0.4577\n",
            "Bottom25_R2: -0.0189\n",
            "Bottom25_MAE: 0.0156\n",
            "Bottom25_MSE: 0.0005\n",
            "Bottom25_Dir_Acc: 0.5062\n",
            "Bottom25_Up_Acc: 0.5588\n",
            "Bottom25_Down_Acc: 0.4436\n",
            "Predictions saved to chronos_t5_large_w252.csv\n",
            "\n",
            "=== Processing Window Size: 512 ===\n",
            "Test samples: 110,850\n",
            "Sequence length: 512\n",
            "Optimized batch size: 24\n",
            "Starting GPU optimized inference with batch size: 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU Batch Inference: 100%|██████████| 4619/4619 [31:12<00:00,  2.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference completed. Final batch size: 24 (original: 24)\n",
            "\n",
            "=== Directional Sanity Check ===\n",
            "Pos ratio (y_test): 0.5225259359494813\n",
            "Neg ratio (y_test): 0.47667117726657643\n",
            "Pred +1 ratio: 0.5976003608479927\n",
            "Pred -1 ratio: 0.4023996391520072\n",
            "      Pred+  Pred-\n",
            "+1 | [34638 23284]\n",
            "-1 | [31554 21285]\n",
            "\n",
            "Window 512 processing completed:\n",
            "Total time: 1880.45 seconds\n",
            "Processing speed: 59 samples/second\n",
            "\n",
            "Metrics for window 512:\n",
            "R2: -0.0167\n",
            "MAE: 0.0119\n",
            "MSE: 0.0003\n",
            "Directional Accuracy: 0.5049\n",
            "Up_Directional_Acc: 0.5962\n",
            "Down_Directional_Acc: 0.4010\n",
            "Top25_R2: -0.0153\n",
            "Top25_MAE: 0.0103\n",
            "Top25_MSE: 0.0002\n",
            "Top25_Dir_Acc: 0.5015\n",
            "Top25_Up_Acc: 0.5837\n",
            "Top25_Down_Acc: 0.4213\n",
            "Bottom25_R2: -0.0189\n",
            "Bottom25_MAE: 0.0155\n",
            "Bottom25_MSE: 0.0005\n",
            "Bottom25_Dir_Acc: 0.5043\n",
            "Bottom25_Up_Acc: 0.5441\n",
            "Bottom25_Down_Acc: 0.4501\n",
            "Predictions saved to chronos_t5_large_w512.csv\n",
            "\n",
            "=== All predictions completed! ===\n"
          ]
        }
      ],
      "source": [
        "def batch_predict_gpu_optimized(X_test_tensor, pipeline, batch_size=512):\n",
        "    \"\"\"\n",
        "    T4 GPU optimized batch inference function.\n",
        "    Input remains on CPU, pipeline handles token_ids transfer internally.\n",
        "    \"\"\"\n",
        "    all_predictions = []\n",
        "    original_batch_size = batch_size\n",
        "\n",
        "    print(f\"Starting GPU optimized inference with batch size: {batch_size}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(X_test_tensor), batch_size), desc=\"GPU Batch Inference\"):\n",
        "            try:\n",
        "                batch_end = min(i + batch_size, len(X_test_tensor))\n",
        "                batch_ctx = X_test_tensor[i:batch_end]\n",
        "\n",
        "                forecasts = pipeline.predict(\n",
        "                    context=batch_ctx,\n",
        "                    prediction_length=1,\n",
        "                    num_samples=10\n",
        "                )\n",
        "\n",
        "                predictions = np.array([float(f[0].mean()) for f in forecasts])\n",
        "                all_predictions.extend(predictions)\n",
        "\n",
        "                if i % (batch_size * 10) == 0 and torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    print(f\"\\nOOM detected. Reducing batch size from {batch_size} to {batch_size // 2}\")\n",
        "                    torch.cuda.empty_cache()\n",
        "                    batch_size = max(batch_size // 2, 1)\n",
        "\n",
        "                    batch_end = min(i + batch_size, len(X_test_tensor))\n",
        "                    batch_ctx = X_test_tensor[i:batch_end]\n",
        "\n",
        "                    _, mean = pipeline.predict_quantiles(\n",
        "                        context=batch_ctx,\n",
        "                        prediction_length=1,\n",
        "                        quantile_levels=[0.5]\n",
        "                    )\n",
        "                    predictions = mean.cpu().numpy().ravel()\n",
        "                    all_predictions.extend(predictions)\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\nInference completed. Final batch size: {batch_size} (original: {original_batch_size})\")\n",
        "    return np.array(all_predictions)\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/chronos_t5_large_project/chronos_t5_results\n",
        "!mkdir -p /content/drive/MyDrive/chronos_t5_large_project/chronos_t5_predictions\n",
        "\n",
        "print(\"Starting T4 GPU optimized prediction...\")\n",
        "print(f\"Data file contains keys: {list(data.keys())}\")\n",
        "\n",
        "for window_size in window_sizes:\n",
        "    print(f\"\\n=== Processing Window Size: {window_size} ===\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    X_test = data[f\"X_test_{window_size}\"]\n",
        "    y_test = data[f\"y_test_{window_size}\"]\n",
        "    meta_test = pd.DataFrame(data[f\"meta_test_{window_size}\"].item())\n",
        "\n",
        "    current_batch_size = get_batch_size(window_size)\n",
        "\n",
        "    print(f\"Test samples: {len(X_test):,}\")\n",
        "    print(f\"Sequence length: {X_test.shape[1]}\")\n",
        "    print(f\"Optimized batch size: {current_batch_size}\")\n",
        "\n",
        "    X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
        "    all_predictions = batch_predict_gpu_optimized(X_test_tensor, pipeline, current_batch_size)\n",
        "\n",
        "    permnos_test = meta_test[\"PERMNO\"].values\n",
        "    metrics = calculate_metrics(y_test, all_predictions, permnos_test, meta_test)\n",
        "\n",
        "    print(\"\\n=== Directional Sanity Check ===\")\n",
        "    print(\"Pos ratio (y_test):\", (y_test > 0).mean())\n",
        "    print(\"Neg ratio (y_test):\", (y_test < 0).mean())\n",
        "    sign_pred = np.sign(all_predictions)\n",
        "    print(\"Pred +1 ratio:\", (sign_pred > 0).mean())\n",
        "    print(\"Pred -1 ratio:\", (sign_pred < 0).mean())\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    conf = confusion_matrix(np.sign(y_test), sign_pred, labels=[1, -1])\n",
        "    print(\"      Pred+  Pred-\")\n",
        "    print(\"+1 |\", conf[0])\n",
        "    print(\"-1 |\", conf[1])\n",
        "\n",
        "    results[window_size] = {\n",
        "        'predictions': all_predictions,\n",
        "        'true_values': y_test,\n",
        "        'metrics': metrics,\n",
        "        'meta': meta_test\n",
        "    }\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    samples_per_second = len(X_test) / elapsed_time\n",
        "\n",
        "    print(f\"\\nWindow {window_size} processing completed:\")\n",
        "    print(f\"Total time: {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Processing speed: {samples_per_second:.0f} samples/second\")\n",
        "\n",
        "    print(f\"\\nMetrics for window {window_size}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        'PERMNO': meta_test['PERMNO'],\n",
        "        'y_true': y_test,\n",
        "        'y_pred': all_predictions\n",
        "    })\n",
        "    results_df.to_csv(f'/content/drive/MyDrive/chronos_t5_large_project/chronos_t5_predictions/chronos_t5_large_w{window_size}.csv', index=False)\n",
        "    print(f\"Predictions saved to chronos_t5_large_w{window_size}.csv\")\n",
        "\n",
        "    del X_test_tensor\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n=== All predictions completed! ===\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFgieCjgVMZ_",
        "outputId": "e823503c-51f1-456d-b7bc-0bcab46994a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to results_large.pkl\n",
            "Metrics saved to chronos_t5_large_metrics.csv\n",
            "\n",
            "=== Metrics Summary (Large) ===\n",
            "   Window      R2     MAE     MSE  Directional Accuracy  Up_Directional_Acc  \\\n",
            "0       5 -0.5388  0.0143  0.0004                0.4991              0.6065   \n",
            "1      21 -0.1211  0.0125  0.0003                0.5028              0.6495   \n",
            "2     252 -0.0182  0.0120  0.0003                0.5041              0.6161   \n",
            "3     512 -0.0167  0.0119  0.0003                0.5049              0.5962   \n",
            "\n",
            "   Down_Directional_Acc  Top25_R2  Top25_MAE  Top25_MSE  Top25_Dir_Acc  \\\n",
            "0                0.3806   -0.5422     0.0124     0.0003         0.4213   \n",
            "1                0.3402   -0.1217     0.0108     0.0002         0.4607   \n",
            "2                0.3778   -0.0177     0.0103     0.0002         0.5610   \n",
            "3                0.4010   -0.0153     0.0103     0.0002         0.5015   \n",
            "\n",
            "   Top25_Up_Acc  Top25_Down_Acc  Bottom25_R2  Bottom25_MAE  Bottom25_MSE  \\\n",
            "0        0.5836          0.3161      -0.5395        0.0187        0.0007   \n",
            "1        0.6417          0.2952      -0.1180        0.0163        0.0005   \n",
            "2        0.6154          0.4577      -0.0189        0.0156        0.0005   \n",
            "3        0.5837          0.4213      -0.0189        0.0155        0.0005   \n",
            "\n",
            "   Bottom25_Dir_Acc  Bottom25_Up_Acc  Bottom25_Down_Acc  \n",
            "0            0.4992           0.5923             0.3913  \n",
            "1            0.5016           0.6144             0.3693  \n",
            "2            0.5062           0.5588             0.4436  \n",
            "3            0.5043           0.5441             0.4501  \n",
            "\n",
            "=== All results (Large) saved to Google Drive ===\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Cell 3: Save results and generate visualizations\n",
        "# ============================================================================\n",
        "import joblib\n",
        "\n",
        "results_dict = {\n",
        "    'window_sizes': window_sizes,\n",
        "    'results': results,\n",
        "    'model_name': 'Chronos-T5-Large',\n",
        "    'model_version': 'T4_GPU_Optimized',\n",
        "    'model_params': {\n",
        "        'device': device,\n",
        "        'torch_dtype': 'float16' if torch.cuda.is_available() else 'float32',\n",
        "        'batch_sizes': {ws: get_batch_size(ws) for ws in window_sizes},\n",
        "        'gpu_optimized': True\n",
        "    }\n",
        "}\n",
        "joblib.dump(results_dict, \"/content/drive/MyDrive/chronos_t5_large_project/chronos_t5_results/results_large.pkl\")\n",
        "print(\"Results have been saved to results_large.pkl\")\n",
        "\n",
        "metrics_df = pd.DataFrame([\n",
        "    {**{\"Window\": window_size}, **results[window_size][\"metrics\"]}\n",
        "    for window_size in window_sizes\n",
        "])\n",
        "metrics_df.to_csv(\"/content/drive/MyDrive/chronos_t5_large_project/chronos_t5_results/chronos_t5_large_metrics.csv\", index=False)\n",
        "print(\"Metrics have been saved to chronos_t5_large_metrics.csv\")\n",
        "\n",
        "print(\"\\n=== Metrics Summary (Large) ===\")\n",
        "print(metrics_df.round(4))\n",
        "print(\"\\n=== All results (Large) have been saved to Google Drive ===\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (Chronos)",
      "language": "python",
      "name": "chronos"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0112748a28a14ab5985962738186ffe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b6d38fb9bf74b858f0257245c06662f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b97e54c97784287b95ac5f2d51efa6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aaaa3c3d022432e929bc2bb306f3871",
            "max": 2835915592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ff7767ae1614b60bbecc30425076cdb",
            "value": 2835915592
          }
        },
        "0c539af8e78a4f6780cd051c508b8956": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "16463d3e67df43ec8a3d7dfeb75b6f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16a93c967327441da3997f92ee71a20f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16cb3bc8012c48f99bcb9bdc92827538": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62da8eed91ad4d3c98fbda09dd0e2684",
            "placeholder": "​",
            "style": "IPY_MODEL_16463d3e67df43ec8a3d7dfeb75b6f1f",
            "value": " 1.12k/? [00:00&lt;00:00, 114kB/s]"
          }
        },
        "17e6ffc236754da7a2e799c611c9c3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f254a0ca04149ab8b387e67374707ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2889611abbf6449ab8772523aafce5ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aaaa3c3d022432e929bc2bb306f3871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2efefef56d4b407cb124948f0e8f1e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0b6906b782a426799ffb5694b61352f",
            "placeholder": "​",
            "style": "IPY_MODEL_ef30bd0b217e45149b4623dc0d04d5ee",
            "value": "model.safetensors: 100%"
          }
        },
        "2ff7767ae1614b60bbecc30425076cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "320543de3caf44188bdac1df29d80d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32abfa0e8bef42ffbff1ff1405578264": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41503e23b8c64ab1840afae42a0e7793": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596626123c76488089d5a856396610b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de5890497148458da8a518e04da24474",
            "placeholder": "​",
            "style": "IPY_MODEL_74a5174c03e94760bccfa7e660b7e1dd",
            "value": " 2.84G/2.84G [00:13&lt;00:00, 225MB/s]"
          }
        },
        "62da8eed91ad4d3c98fbda09dd0e2684": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a5174c03e94760bccfa7e660b7e1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b85653570384311839b0cc6b1bcb9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f254a0ca04149ab8b387e67374707ea",
            "placeholder": "​",
            "style": "IPY_MODEL_0112748a28a14ab5985962738186ffe0",
            "value": "config.json: "
          }
        },
        "7d5734ba84d34327906b511e9ab943f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7eb5f8e436864d4fa8bca870fa281c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a93c967327441da3997f92ee71a20f",
            "placeholder": "​",
            "style": "IPY_MODEL_320543de3caf44188bdac1df29d80d84",
            "value": "generation_config.json: 100%"
          }
        },
        "841716f0450a4e5baecba32d420adbbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2efefef56d4b407cb124948f0e8f1e68",
              "IPY_MODEL_0b97e54c97784287b95ac5f2d51efa6b",
              "IPY_MODEL_596626123c76488089d5a856396610b4"
            ],
            "layout": "IPY_MODEL_2889611abbf6449ab8772523aafce5ba"
          }
        },
        "95d4f01f163c4ec4af273923a88d20df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32abfa0e8bef42ffbff1ff1405578264",
            "placeholder": "​",
            "style": "IPY_MODEL_7d5734ba84d34327906b511e9ab943f3",
            "value": " 142/142 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "b1a8bc16b0004469aab3c0534fff9089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b34168fa9a5d494496d20911c1954d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d15934e85043df94fd384797bd9efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eb5f8e436864d4fa8bca870fa281c7c",
              "IPY_MODEL_c9b7da5e20d94a0f99907e4137fc3238",
              "IPY_MODEL_95d4f01f163c4ec4af273923a88d20df"
            ],
            "layout": "IPY_MODEL_b34168fa9a5d494496d20911c1954d67"
          }
        },
        "c9b7da5e20d94a0f99907e4137fc3238": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41503e23b8c64ab1840afae42a0e7793",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b6d38fb9bf74b858f0257245c06662f",
            "value": 142
          }
        },
        "de5890497148458da8a518e04da24474": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebdc20a0f14d4d849d6cd16bb52017d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b85653570384311839b0cc6b1bcb9a5",
              "IPY_MODEL_fcc1518998d646b3aefd76cae108597b",
              "IPY_MODEL_16cb3bc8012c48f99bcb9bdc92827538"
            ],
            "layout": "IPY_MODEL_17e6ffc236754da7a2e799c611c9c3c4"
          }
        },
        "ef30bd0b217e45149b4623dc0d04d5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0b6906b782a426799ffb5694b61352f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcc1518998d646b3aefd76cae108597b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c539af8e78a4f6780cd051c508b8956",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1a8bc16b0004469aab3c0534fff9089",
            "value": 1
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
